{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u1p2Rz6EjmL"
      },
      "source": [
        "#Deep Learning based Temporal Causal Discovery from Non-stationary Non-linear Time Series Data (FMRI Dataset)\n",
        "\n",
        "\n",
        "This notebook contains the proposed model. Here we have developed the proposed Causal Conv2D layer and the optimization function.\n",
        "\n",
        "The functions to visualize the predicted causal graph are available after the model training codes. The predicted graph is compared with ground truth using an adjacency matrix (array).   \n",
        "\n",
        "In this notebook, we applied the proposed model to the synthetic dataset-3 to generate a full causal graph and summary graph."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "M5Z6RQ1gO3ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/FMRI-Data.csv')\n",
        "#data"
      ],
      "metadata": {
        "id": "Fq81bAkvey0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_graph = np.zeros((5,5))\n",
        "true_graph[0,1]=1\n",
        "true_graph[0,4]=1\n",
        "true_graph[1,2]=1\n",
        "true_graph[2,3]=1\n",
        "true_graph[3,4]=1\n",
        "true_graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "112082dc-562f-41d3-f38c-c97970274506",
        "id": "FTAtm2bXgM_Y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "\n",
        "def signaltonoise(a, axis=0, ddof=0):\n",
        "    a = np.asanyarray(a)\n",
        "    m = a.mean(axis)\n",
        "    sd = a.std(axis=axis, ddof=ddof)\n",
        "    return np.where(sd == 0, 0, (m*m)/(sd*sd))\n",
        "\n"
      ],
      "metadata": {
        "id": "5wbvAZ0YJMz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_np = data.to_numpy()"
      ],
      "metadata": {
        "id": "zfJw775iJYWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snr1 = signaltonoise(data_np[:,0])\n",
        "snr2 = signaltonoise(data_np[:,1])\n",
        "snr3 = signaltonoise(data_np[:,2])\n",
        "snr4 = signaltonoise(data_np[:,3])"
      ],
      "metadata": {
        "id": "U3duiwVkJPiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snr1, snr2, snr3, snr4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynBRfnUoJmVF",
        "outputId": "379d0443-b48e-40c6-a824-a8a145aad9f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(1.23747245e-34),\n",
              " array(2.25060508e-35),\n",
              " array(4.1178919e-37),\n",
              " array(4.47097224e-35))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cdt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S9iW6BIFQsw",
        "outputId": "616e7900-fa6e-4b8b-a728-671bd96c6836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cdt\n",
            "  Downloading cdt-0.6.0-py3-none-any.whl (921 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m921.1/921.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cdt) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from cdt) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from cdt) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from cdt) (1.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from cdt) (2.0.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from cdt) (0.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from cdt) (3.3)\n",
            "Collecting skrebate (from cdt)\n",
            "  Downloading skrebate-0.62.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from cdt) (4.66.2)\n",
            "Collecting GPUtil (from cdt)\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from cdt) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->cdt) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->cdt) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->cdt) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->cdt) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->cdt) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->cdt) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->cdt) (2024.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->cdt) (3.4.0)\n",
            "Requirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->cdt) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->cdt) (24.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.4->statsmodels->cdt) (1.16.0)\n",
            "Building wheels for collected packages: GPUtil, skrebate\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7394 sha256=5452f74f463ca04ba912e6faa06c44bce754e9493b534b7a29d37b2e4d509fb8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "  Building wheel for skrebate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for skrebate: filename=skrebate-0.62-py3-none-any.whl size=29255 sha256=44927526fd8942a6ee91a98c797fd7fc1caacb69f9b1d60280b5ccec4e6dc701\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/67/40/683074a684607162bd0e34dcf7ccdfcab5861c3b2a83286f3a\n",
            "Successfully built GPUtil skrebate\n",
            "Installing collected packages: GPUtil, skrebate, cdt\n",
            "Successfully installed GPUtil-1.4.0 cdt-0.6.0 skrebate-0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cdt"
      ],
      "metadata": {
        "id": "9zOqtLmEFTV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "771e5557-870f-46c4-9b69-99078b58d267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No GPU automatically detected. Setting SETTINGS.GPU to 0, and SETTINGS.NJOBS to cpu_count.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Pre-processing"
      ],
      "metadata": {
        "id": "_c4DRyupElS3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxHRvk8yIDzd"
      },
      "outputs": [],
      "source": [
        "syn_data_np = data.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lpbabSPc8zL"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "syn_data_np_nor = scaler_X.fit_transform(syn_data_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhC-tTJmIKMB"
      },
      "outputs": [],
      "source": [
        "syn_data_np.shape, syn_data_np_nor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZHVzq1udKOU"
      },
      "outputs": [],
      "source": [
        "syn_data_np = syn_data_np_nor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84-afn1JIuwn"
      },
      "outputs": [],
      "source": [
        "syn_data_np_T= syn_data_np.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWq0FyHsH_FZ"
      },
      "outputs": [],
      "source": [
        "syn_data_pro = np.zeros((syn_data_np.shape[0]-2,5,3))\n",
        "for i in range(0, (syn_data_np.shape[0]-2)):\n",
        "  syn_data_pro[i,:,:]= syn_data_np_T[0:5, i:i+3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s86v5_DNH_FZ",
        "outputId": "60d2acf8-15fc-4156-dc8f-1b8185dfa0f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.37349215, 0.4442903 , 0.40493454],\n",
              "        [0.41572759, 0.46380577, 0.44884027],\n",
              "        [0.50517201, 0.38353911, 0.50146599],\n",
              "        [0.61441643, 0.69902813, 0.68356306],\n",
              "        [0.49689653, 0.61686047, 0.56051063]]),\n",
              " array([[0.37349215, 0.4442903 , 0.40493454],\n",
              "        [0.41572759, 0.46380577, 0.44884027],\n",
              "        [0.50517201, 0.38353911, 0.50146599],\n",
              "        [0.61441643, 0.69902813, 0.68356306],\n",
              "        [0.49689653, 0.61686047, 0.56051063]]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "syn_data_pro[0,:,:], syn_data_np_T[0:5,0:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6EkNT6yJVzQ",
        "outputId": "eeb54a92-f672-4eff-fe78-06aeab33ee2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2398, 5, 3, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "syn_data_2d = np.expand_dims(syn_data_pro, axis =-1)\n",
        "syn_data_2d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMsrqP9L9JbQ",
        "outputId": "2a969e76-6250-4c1f-aaab-a266a5e8e9d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2400, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "syn_data_np_4 = syn_data_np[:,0:5]\n",
        "syn_data_np_4.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWJF5A2-Ctea",
        "outputId": "6f8d033a-a863-4877-8787-8b3e331b70ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['S1', 'S2', 'S3', 'S4', 'S5'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YA5wOqVtC81J"
      },
      "outputs": [],
      "source": [
        "syn_data_4_df =pd.DataFrame(data = syn_data_np_4,\n",
        "                  columns = ['S1', 'S2', 'S3', 'S4', 'S5'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "i2ywJcarDPqv",
        "outputId": "eccb7f0b-4f37-4c63-91d4-041ca22844cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         S1        S2        S3        S4        S5\n",
              "0  0.373492  0.415728  0.505172  0.614416  0.496897\n",
              "1  0.444290  0.463806  0.383539  0.699028  0.616860\n",
              "2  0.404935  0.448840  0.501466  0.683563  0.560511\n",
              "3  0.698631  0.343690  0.488534  0.716959  0.443769\n",
              "4  0.753538  0.503854  0.637850  0.659428  0.501231"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fafbbc7-0936-4322-89af-ebe2fc2aca3a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S1</th>\n",
              "      <th>S2</th>\n",
              "      <th>S3</th>\n",
              "      <th>S4</th>\n",
              "      <th>S5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.373492</td>\n",
              "      <td>0.415728</td>\n",
              "      <td>0.505172</td>\n",
              "      <td>0.614416</td>\n",
              "      <td>0.496897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.444290</td>\n",
              "      <td>0.463806</td>\n",
              "      <td>0.383539</td>\n",
              "      <td>0.699028</td>\n",
              "      <td>0.616860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.404935</td>\n",
              "      <td>0.448840</td>\n",
              "      <td>0.501466</td>\n",
              "      <td>0.683563</td>\n",
              "      <td>0.560511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.698631</td>\n",
              "      <td>0.343690</td>\n",
              "      <td>0.488534</td>\n",
              "      <td>0.716959</td>\n",
              "      <td>0.443769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.753538</td>\n",
              "      <td>0.503854</td>\n",
              "      <td>0.637850</td>\n",
              "      <td>0.659428</td>\n",
              "      <td>0.501231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fafbbc7-0936-4322-89af-ebe2fc2aca3a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3fafbbc7-0936-4322-89af-ebe2fc2aca3a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3fafbbc7-0936-4322-89af-ebe2fc2aca3a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bf5db191-864e-4487-9fde-acc05cbd18fb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf5db191-864e-4487-9fde-acc05cbd18fb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bf5db191-864e-4487-9fde-acc05cbd18fb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"syn_data_4_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"S1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17731614018759992,\n        \"min\": 0.37349214734797503,\n        \"max\": 0.7535380182769473,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.44429030430699035,\n          0.7535380182769473,\n          0.40493454408530466\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.060147443602821926,\n        \"min\": 0.3436904917977409,\n        \"max\": 0.5038538350825981,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.4638057748455776,\n          0.5038538350825981,\n          0.44884026897845625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09037602431454327,\n        \"min\": 0.38353910613211695,\n        \"max\": 0.637850125219199,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.38353910613211695,\n          0.637850125219199,\n          0.5014659946268026\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.039760332231466765,\n        \"min\": 0.6144164255091362,\n        \"max\": 0.7169586788026774,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.699028129119285,\n          0.6594284131246534,\n          0.6835630567202989\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06641919710862616,\n        \"min\": 0.443768895213234,\n        \"max\": 0.6168604682003009,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6168604682003009,\n          0.5012310504198554,\n          0.5605106325395026\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "syn_data_4_df.iloc[:5,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CvHxTQArupm",
        "outputId": "5e6ce36d-82f0-4d6f-a01e-09ede5153425"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2400, 5), (2398, 5, 3, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "syn_data_np.shape, syn_data_2d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "510yT1YNJHlt",
        "outputId": "9d3174fb-7778-4f46-bec0-df6433942acd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2398, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "data_y_syn = syn_data_np[2:,:]\n",
        "data_y_syn.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KVllbLUkHjt"
      },
      "source": [
        "# Proposed Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyklufMFkH7O"
      },
      "outputs": [],
      "source": [
        "import keras,os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Dropout, AveragePooling2D, LSTM, Activation, ConvLSTM2D, TimeDistributed, Input, Reshape\n",
        "from keras.layers import UpSampling1D, Conv2DTranspose, UpSampling2D, Conv1D, AveragePooling1D, LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras import callbacks\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras.layers import concatenate\n",
        "from keras.regularizers import l1, l2\n",
        "from time import time\n",
        "\n",
        "keras.utils.set_random_seed(1001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalConv2D(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_outputs, counter, *args, **kwargs):\n",
        "        super(CausalConv2D, self).__init__()\n",
        "        self.conv2d = tf.keras.layers.Conv2D(*args, **kwargs)\n",
        "        self.num_outputs = num_outputs\n",
        "        self.counter = counter\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W=self.add_weight(name='kernel',\n",
        "                           shape=(input_shape[1], input_shape[2],input_shape[3], 1),\n",
        "                           initializer = tf.keras.initializers.glorot_uniform(seed=8),\n",
        "                           trainable=True)\n",
        "        self.mask = np.ones(shape=self.W.shape)\n",
        "        #print(self.W)\n",
        "        self.mask[self.counter,(input_shape[2]-1),...] = 0.0\n",
        "\n",
        "    def get_weights(self):\n",
        "        return super().get_weights()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        self.W.assign(tf.math.multiply(self.W, self.mask))\n",
        "        #self.conv2d._convolution_op = functools.partial(self.masked_convolution_op, mask=mask)\n",
        "        #return self.conv2d.call(x)\n",
        "        return self.conv2d.convolution_op(inputs, self.W)"
      ],
      "metadata": {
        "id": "z2o2-R2mFIm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D\n",
        "def get_model_2d(input_dims):\n",
        "    input_batch = Input(shape = input_dims)\n",
        "\n",
        "    conv_model = Sequential()\n",
        "    conv_model = Conv2D(filters=4, kernel_size=1, strides=(1,1), padding='valid', activation=\"linear\", name='conv1')(input_batch)\n",
        "    #conv_model = AveragePooling2D(pool_size=(1,1), strides=None, padding='valid', name='pool1')(conv_model) activation=LeakyReLU(0.05)\n",
        "    conv_model = tf.math.reduce_mean(conv_model, axis=-1)\n",
        "    conv_model = Reshape((5, 3, 1))(conv_model)\n",
        "    #conv_model = Flatten()(conv_model )\n",
        "    pooled_outputs = []\n",
        "    for i in range(0, 5):\n",
        "      #layer = CausalConv2D(num_outputs=1, counter=i, name=\"parr\"+str(i))(conv_model) # , kernel_regularizer = l1(0.2)\n",
        "      layer = CausalConv2D(filters=1, kernel_size=(5,3), num_outputs=1, counter=i, padding='valid', activation=\"tanh\",)(conv_model)\n",
        "      #den1 = layer(tf.ones([481, 30]))\n",
        "      #conv = Conv2D(1, kernel_size=filter_sizes[i], padding='valid', activation='relu')(conv_model)\n",
        "      pooled_outputs.append(layer)\n",
        "    output = concatenate(pooled_outputs)\n",
        "    output = Flatten()(output)\n",
        "\n",
        "    model = Model(inputs=input_batch, outputs=output, name='cpred')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "WwughzzGFJIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with gradient tape\n",
        "\n",
        "class CausalNNModel(object):\n",
        "    def __init__(self,\n",
        "                 dims,\n",
        "                 alpha=0.0,\n",
        "                 rho = 1.0,\n",
        "                 rho_max = 10e20,\n",
        "                 h_tol = 1e-8,\n",
        "                 init='glorot_uniform'):\n",
        "\n",
        "        super(CausalNNModel, self).__init__()\n",
        "\n",
        "        self.dims = dims\n",
        "        self.n_stacks = len(self.dims) - 1\n",
        "        self.alpha = alpha\n",
        "        self.rho = rho\n",
        "        self.h_p = np.Inf\n",
        "        self.rho_max = rho_max\n",
        "        self.h_tol = h_tol\n",
        "        self.model_2d = get_model_2d(self.dims)\n",
        "        print(\"====Model created=====\")\n",
        "\n",
        "        self.model = Model(inputs=self.model_2d.input, outputs=self.model_2d.output)\n",
        "\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        return self.model_cnn.predict(x)\n",
        "\n",
        "    def predict(self, x):  # predict cluster labels using the output of clustering layer\n",
        "        q = self.model.predict(x, verbose=0)[1]\n",
        "        return q.argmax(1)\n",
        "\n",
        "    def custom_loss_function(self, y_true, y_pred):\n",
        "      mse = keras.losses.mean_squared_error(y_true, y_pred)\n",
        "      h_val = self.causal_loss_h()\n",
        "      h_loss = 0.5 * self.rho * h_val * h_val + self.alpha * h_val\n",
        "      lambda1 = 0.1\n",
        "      adj_mat = self.get_mat()\n",
        "      sparse_loss = lambda1 * tf.math.reduce_sum(tf.abs(adj_mat))\n",
        "      #neg_weight = np.sum(adj_mat, where=adj_mat<0)\n",
        "      #neg_loss = 0.5 * tf.abs(neg_weight)\n",
        "      print('MSE Loss is: {}, h Loss is: {}, L1 loss: {}, Total Loss is: {}'.format(tf.reduce_mean(mse), h_loss, sparse_loss, tf.reduce_mean(mse)+h_loss))\n",
        "      return mse + h_loss + sparse_loss #+ neg_loss\n",
        "\n",
        "    def causal_loss_h(self):\n",
        "      mat = self.get_mat()\n",
        "      h_val = self.h_acy_1(mat[:, 10:])\n",
        "      return h_val\n",
        "\n",
        "    def get_mat(self):\n",
        "      w1_2d_s = self.model.get_layer(index=-7).get_weights()\n",
        "      w2_2d_s = self.model.get_layer(index=-6).get_weights()\n",
        "      w3_2d_s = self.model.get_layer(index=-5).get_weights()\n",
        "      w4_2d_s = self.model.get_layer(index=-4).get_weights()\n",
        "      w5_2d_s = self.model.get_layer(index=-3).get_weights()\n",
        "      arr1_2d_s = np.expand_dims(np.squeeze(np.array(w1_2d_s), axis=(0,3,4)).flatten('F'), axis=0)\n",
        "      arr2_2d_s = np.expand_dims(np.squeeze(np.array(w2_2d_s), axis=(0,3,4)).flatten('F'), axis=0)\n",
        "      arr3_2d_s = np.expand_dims(np.squeeze(np.array(w3_2d_s), axis=(0,3,4)).flatten('F'), axis=0)\n",
        "      arr4_2d_s = np.expand_dims(np.squeeze(np.array(w4_2d_s), axis=(0,3,4)).flatten('F'), axis=0)\n",
        "      arr5_2d_s = np.expand_dims(np.squeeze(np.array(w5_2d_s), axis=(0,3,4)).flatten('F'), axis=0)\n",
        "      mat_2d_s = np.concatenate((arr1_2d_s, arr2_2d_s, arr3_2d_s, arr4_2d_s, arr5_2d_s))\n",
        "      #print(mat_2d_s)\n",
        "      return mat_2d_s\n",
        "\n",
        "    def h_acy_1(self, A):\n",
        "      n_var = A.shape[0]\n",
        "      h = tf.linalg.trace(tf.linalg.expm(A * A)) - n_var\n",
        "      return h\n",
        "\n",
        "\n",
        "    def h_acy(self, A):\n",
        "      '''Calculate the constraint of A ensure that it's a DAG'''\n",
        "      #(Yu et al. 2019 DAG-GNN)\n",
        "      # h(w) = tr[(I + kA*A)^n_variables] - n_variables\n",
        "      n_var = A.shape[0]\n",
        "      M = tf.eye(n_var, num_columns = n_var) + A/n_var\n",
        "      E = M\n",
        "      for _ in range(n_var - 2):\n",
        "        E = tf.linalg.matmul(E, M)\n",
        "      h = tf.math.reduce_sum(tf.transpose(E) * M) - n_var\n",
        "      return h\n",
        "\n",
        "    def compile(self, optimizer='adam'):\n",
        "        self.model.compile(optimizer=optimizer, loss= self.custom_loss_function) # ['mse', self.causal_loss()])\n",
        "\n",
        "    def fit(self, x, y=None, maxiter=100, batch_size=512, save_dir='./results/temp'):\n",
        "        t1 = time()\n",
        "\n",
        "\n",
        "        # Step 2: deep clustering\n",
        "        # logging file\n",
        "        import csv\n",
        "        logfile = open(save_dir + '/causalnn_log.csv', 'w')\n",
        "        logwriter = csv.DictWriter(logfile, fieldnames=['iter','loss'])\n",
        "        logwriter.writeheader()\n",
        "        train_loader = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size)\n",
        "        optimizer = tf.keras.optimizers.Adam(1e-2)\n",
        "        w1_2d_s = self.model.get_layer(index=-6).get_weights()\n",
        "        arr1_2d_s = np.expand_dims(np.squeeze(np.array(w1_2d_s), axis=(0,3,4)).flatten('F'), axis=0)\n",
        "\n",
        "\n",
        "        for epoch in range(int(maxiter)):\n",
        "          print('Epoch: {}', epoch)\n",
        "          h_n = None\n",
        "          for (x, y) in train_loader:\n",
        "            #eval loss and compute gradients\n",
        "            with tf.GradientTape() as tape:\n",
        "              tape.watch(self.model.trainable_variables)\n",
        "              #passing through neural network\n",
        "              output = self.model(x)\n",
        "              #calculate loss\n",
        "              loss = self.custom_loss_function(y, output)\n",
        "              gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "              optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "              h_n = self.causal_loss_h()\n",
        "              #print('New h_val is :', h_n)\n",
        "              #if h_n > 0.25 * self.h_p:\n",
        "              #  self.rho = self.rho*10\n",
        "              #else:\n",
        "              #  break\n",
        "\n",
        "          if h_n > 0.25 * self.h_p:\n",
        "                self.rho = self.rho*1.1\n",
        "          self.h_p = h_n\n",
        "          print('New h_val is :', h_n)\n",
        "          self.alpha += self.rho * self.h_p\n",
        "\n",
        "          if self.h_p <= self.h_tol or self.rho >= self.rho_max:\n",
        "            print('Before the loop end # h_val is: {}, rho is: {}'.format(self.h_p, self.rho))\n",
        "            break\n",
        "\n",
        "        # save the trained model\n",
        "        logfile.close()\n",
        "        file_name  = \"/CausalNN_model_final_\" + str(round(time()))+ \".h5\"\n",
        "        print('saving model to:', save_dir + file_name)\n",
        "        self.model.save_weights(save_dir + file_name)\n",
        "\n",
        "        w1_2d_s_1 = self.model.get_layer(index=-6).get_weights()\n",
        "        arr1_2d_s_1 = np.expand_dims(np.squeeze(np.array(w1_2d_s_1), axis=(0,3,4)).flatten('F'), axis=0)\n",
        "\n",
        "        y_pred = self.model.predict(x)\n",
        "        adj_mat = self.get_mat()\n",
        "\n",
        "        print('The conv layer 1 weights before training :', arr1_2d_s)\n",
        "        print('The conv layer 1 weights after training :', arr1_2d_s_1)\n",
        "\n",
        "        return y_pred, adj_mat"
      ],
      "metadata": {
        "id": "HbY_kEfhJ2HV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model creation and training:"
      ],
      "metadata": {
        "id": "isjKFNbjhKDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.set_random_seed(1001)\n",
        "\n",
        "cnnmodel = CausalNNModel(dims=syn_data_2d.shape[1:])\n",
        "cnnmodel.model.summary()\n",
        "cnnmodel.compile()\n",
        "y_pred, mat = cnnmodel.fit(x=syn_data_2d, y=data_y_syn, maxiter=50, batch_size=128, save_dir='/content/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQOuTYC6y9yR",
        "outputId": "176647b1-0690-4aec-e60b-e5470194d151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====Model created=====\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 5, 3, 1)]            0         []                            \n",
            "                                                                                                  \n",
            " conv1 (Conv2D)              (None, 5, 3, 4)              8         ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_2 (TFO  (None, 5, 3)                 0         ['conv1[0][0]']               \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)         (None, 5, 3, 1)              0         ['tf.math.reduce_mean_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " causal_conv2d_10 (CausalCo  (None, 1, 1, 1)              15        ['reshape_2[0][0]']           \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " causal_conv2d_11 (CausalCo  (None, 1, 1, 1)              15        ['reshape_2[0][0]']           \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " causal_conv2d_12 (CausalCo  (None, 1, 1, 1)              15        ['reshape_2[0][0]']           \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " causal_conv2d_13 (CausalCo  (None, 1, 1, 1)              15        ['reshape_2[0][0]']           \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " causal_conv2d_14 (CausalCo  (None, 1, 1, 1)              15        ['reshape_2[0][0]']           \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 1, 1, 5)              0         ['causal_conv2d_10[0][0]',    \n",
            " )                                                                   'causal_conv2d_11[0][0]',    \n",
            "                                                                     'causal_conv2d_12[0][0]',    \n",
            "                                                                     'causal_conv2d_13[0][0]',    \n",
            "                                                                     'causal_conv2d_14[0][0]']    \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 5)                    0         ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 83 (332.00 Byte)\n",
            "Trainable params: 83 (332.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch: {} 0\n",
            "MSE Loss is: 0.34324127435684204, h Loss is: 9.107639198191464e-05, L1 loss: 1.274539828300476, Total Loss is: 0.34333235025405884\n",
            "MSE Loss is: 0.3377879858016968, h Loss is: 7.577426731586456e-05, L1 loss: 1.2625398635864258, Total Loss is: 0.3378637731075287\n",
            "MSE Loss is: 0.3220600485801697, h Loss is: 6.325464346446097e-05, L1 loss: 1.250569462776184, Total Loss is: 0.32212328910827637\n",
            "MSE Loss is: 0.299984335899353, h Loss is: 5.2943549235351384e-05, L1 loss: 1.2385777235031128, Total Loss is: 0.3000372648239136\n",
            "MSE Loss is: 0.2782270014286041, h Loss is: 4.4421347411116585e-05, L1 loss: 1.2265411615371704, Total Loss is: 0.2782714366912842\n",
            "MSE Loss is: 0.25999099016189575, h Loss is: 3.737675433512777e-05, L1 loss: 1.2240346670150757, Total Loss is: 0.2600283622741699\n",
            "MSE Loss is: 0.23228958249092102, h Loss is: 3.1554416636936367e-05, L1 loss: 1.2402265071868896, Total Loss is: 0.2323211431503296\n",
            "MSE Loss is: 0.20450881123542786, h Loss is: 2.677321754163131e-05, L1 loss: 1.2564972639083862, Total Loss is: 0.2045355886220932\n",
            "MSE Loss is: 0.1772284358739853, h Loss is: 2.288508585479576e-05, L1 loss: 1.2728384733200073, Total Loss is: 0.17725132405757904\n",
            "MSE Loss is: 0.14544638991355896, h Loss is: 1.977879219339229e-05, L1 loss: 1.289215326309204, Total Loss is: 0.1454661637544632\n",
            "MSE Loss is: 0.1140022724866867, h Loss is: 1.737351340125315e-05, L1 loss: 1.3055974245071411, Total Loss is: 0.11401964724063873\n",
            "MSE Loss is: 0.08721806854009628, h Loss is: 1.5618506949977018e-05, L1 loss: 1.3219058513641357, Total Loss is: 0.08723368495702744\n",
            "MSE Loss is: 0.06378094106912613, h Loss is: 1.4480723621090874e-05, L1 loss: 1.3379850387573242, Total Loss is: 0.06379542499780655\n",
            "MSE Loss is: 0.04352685436606407, h Loss is: 1.3961962395114824e-05, L1 loss: 1.3536409139633179, Total Loss is: 0.04354081675410271\n",
            "MSE Loss is: 0.03790561854839325, h Loss is: 1.4078112144488841e-05, L1 loss: 1.3756245374679565, Total Loss is: 0.03791969642043114\n",
            "MSE Loss is: 0.032260455191135406, h Loss is: 1.4860403098282404e-05, L1 loss: 1.400489330291748, Total Loss is: 0.03227531537413597\n",
            "MSE Loss is: 0.03581631928682327, h Loss is: 1.6351810700143687e-05, L1 loss: 1.4255770444869995, Total Loss is: 0.03583266958594322\n",
            "MSE Loss is: 0.03808260336518288, h Loss is: 1.8507316781324334e-05, L1 loss: 1.4461392164230347, Total Loss is: 0.038101110607385635\n",
            "MSE Loss is: 0.04776588827371597, h Loss is: 2.1173105778871104e-05, L1 loss: 1.4613239765167236, Total Loss is: 0.04778706282377243\n",
            "New h_val is : tf.Tensor(0.007074833, shape=(), dtype=float32)\n",
            "Epoch: {} 1\n",
            "MSE Loss is: 0.055154670029878616, h Loss is: 7.334002293646336e-05, L1 loss: 1.4726200103759766, Total Loss is: 0.055228009819984436\n",
            "MSE Loss is: 0.05800071358680725, h Loss is: 7.883205398684368e-05, L1 loss: 1.479777216911316, Total Loss is: 0.058079544454813004\n",
            "MSE Loss is: 0.057922180742025375, h Loss is: 8.291230915347114e-05, L1 loss: 1.4814518690109253, Total Loss is: 0.05800509452819824\n",
            "MSE Loss is: 0.051314424723386765, h Loss is: 8.519420953234658e-05, L1 loss: 1.478353500366211, Total Loss is: 0.05139961838722229\n",
            "MSE Loss is: 0.04025210440158844, h Loss is: 8.56123078847304e-05, L1 loss: 1.4713948965072632, Total Loss is: 0.04033771529793739\n",
            "MSE Loss is: 0.034513454884290695, h Loss is: 8.443092519883066e-05, L1 loss: 1.4615767002105713, Total Loss is: 0.034597884863615036\n",
            "MSE Loss is: 0.02902989648282528, h Loss is: 8.209415682358667e-05, L1 loss: 1.4509475231170654, Total Loss is: 0.029111990705132484\n",
            "MSE Loss is: 0.022642195224761963, h Loss is: 7.913465378805995e-05, L1 loss: 1.4403029680252075, Total Loss is: 0.02272132970392704\n",
            "MSE Loss is: 0.021190326660871506, h Loss is: 7.593860209453851e-05, L1 loss: 1.429791808128357, Total Loss is: 0.021266264840960503\n",
            "MSE Loss is: 0.02002653107047081, h Loss is: 7.284571620402858e-05, L1 loss: 1.420287013053894, Total Loss is: 0.020099377259612083\n",
            "MSE Loss is: 0.01859733834862709, h Loss is: 7.010325498413295e-05, L1 loss: 1.4124656915664673, Total Loss is: 0.018667440861463547\n",
            "MSE Loss is: 0.02202550694346428, h Loss is: 6.778915849281475e-05, L1 loss: 1.4057835340499878, Total Loss is: 0.02209329605102539\n",
            "MSE Loss is: 0.024932140484452248, h Loss is: 6.596611638087779e-05, L1 loss: 1.400283694267273, Total Loss is: 0.024998106062412262\n",
            "MSE Loss is: 0.024795228615403175, h Loss is: 6.463943282142282e-05, L1 loss: 1.3961365222930908, Total Loss is: 0.024859867990016937\n",
            "MSE Loss is: 0.0333416648209095, h Loss is: 6.380488048307598e-05, L1 loss: 1.3934177160263062, Total Loss is: 0.03340546786785126\n",
            "MSE Loss is: 0.03342458978295326, h Loss is: 6.342394044622779e-05, L1 loss: 1.392120122909546, Total Loss is: 0.033488012850284576\n",
            "MSE Loss is: 0.03420446068048477, h Loss is: 6.348737224470824e-05, L1 loss: 1.3921502828598022, Total Loss is: 0.03426794707775116\n",
            "MSE Loss is: 0.028493685647845268, h Loss is: 6.398928962880746e-05, L1 loss: 1.393388271331787, Total Loss is: 0.02855767495930195\n",
            "MSE Loss is: 0.027601538226008415, h Loss is: 6.485028279712424e-05, L1 loss: 1.3957046270370483, Total Loss is: 0.02766638807952404\n",
            "New h_val is : tf.Tensor(0.0064616203, shape=(), dtype=float32)\n",
            "Epoch: {} 2\n",
            "MSE Loss is: 0.027154620736837387, h Loss is: 0.00011362299846950918, L1 loss: 1.398580551147461, Total Loss is: 0.027268243953585625\n",
            "MSE Loss is: 0.02647191658616066, h Loss is: 0.00011589790665311739, L1 loss: 1.4021624326705933, Total Loss is: 0.02658781409263611\n",
            "MSE Loss is: 0.024835258722305298, h Loss is: 0.00011859514779644087, L1 loss: 1.4062566757202148, Total Loss is: 0.024953853338956833\n",
            "MSE Loss is: 0.021248912438750267, h Loss is: 0.00012162973871454597, L1 loss: 1.4112504720687866, Total Loss is: 0.0213705413043499\n",
            "MSE Loss is: 0.01745244488120079, h Loss is: 0.0001248212793143466, L1 loss: 1.4169927835464478, Total Loss is: 0.017577266320586205\n",
            "MSE Loss is: 0.019472483545541763, h Loss is: 0.0001279946300201118, L1 loss: 1.4225033521652222, Total Loss is: 0.019600478932261467\n",
            "MSE Loss is: 0.01969769224524498, h Loss is: 0.0001309906510869041, L1 loss: 1.42752206325531, Total Loss is: 0.019828682765364647\n",
            "MSE Loss is: 0.018847426399588585, h Loss is: 0.00013367790961638093, L1 loss: 1.4322084188461304, Total Loss is: 0.018981104716658592\n",
            "MSE Loss is: 0.020533950999379158, h Loss is: 0.00013589051377493888, L1 loss: 1.4362623691558838, Total Loss is: 0.02066984213888645\n",
            "MSE Loss is: 0.02059604786336422, h Loss is: 0.00013751426013186574, L1 loss: 1.4391525983810425, Total Loss is: 0.020733561366796494\n",
            "MSE Loss is: 0.01828084886074066, h Loss is: 0.00013854276039637625, L1 loss: 1.4407819509506226, Total Loss is: 0.01841939240694046\n",
            "MSE Loss is: 0.020314117893576622, h Loss is: 0.00013889683759771287, L1 loss: 1.441279649734497, Total Loss is: 0.020453015342354774\n",
            "MSE Loss is: 0.020314836874604225, h Loss is: 0.0001386822114000097, L1 loss: 1.4407055377960205, Total Loss is: 0.020453518256545067\n",
            "MSE Loss is: 0.018907543271780014, h Loss is: 0.00013794252299703658, L1 loss: 1.4390759468078613, Total Loss is: 0.01904548518359661\n",
            "MSE Loss is: 0.025010988116264343, h Loss is: 0.00013690468040294945, L1 loss: 1.436568260192871, Total Loss is: 0.02514789253473282\n",
            "MSE Loss is: 0.023911958560347557, h Loss is: 0.0001356986176688224, L1 loss: 1.4334678649902344, Total Loss is: 0.02404765784740448\n",
            "MSE Loss is: 0.024674225598573685, h Loss is: 0.00013448510435409844, L1 loss: 1.4300273656845093, Total Loss is: 0.02480871044099331\n",
            "MSE Loss is: 0.019655529409646988, h Loss is: 0.00013345511979423463, L1 loss: 1.4266139268875122, Total Loss is: 0.019788984209299088\n",
            "MSE Loss is: 0.020449219271540642, h Loss is: 0.0001326180063188076, L1 loss: 1.4233872890472412, Total Loss is: 0.020581837743520737\n",
            "New h_val is : tf.Tensor(0.0072698593, shape=(), dtype=float32)\n",
            "Epoch: {} 3\n",
            "MSE Loss is: 0.021243825554847717, h Loss is: 0.00019889356917701662, L1 loss: 1.420467734336853, Total Loss is: 0.0214427188038826\n",
            "MSE Loss is: 0.021767152473330498, h Loss is: 0.00019869665266014636, L1 loss: 1.4180580377578735, Total Loss is: 0.02196584828197956\n",
            "MSE Loss is: 0.022286705672740936, h Loss is: 0.00019912084098905325, L1 loss: 1.4163230657577515, Total Loss is: 0.022485826164484024\n",
            "MSE Loss is: 0.020272649824619293, h Loss is: 0.0002002581168198958, L1 loss: 1.4152320623397827, Total Loss is: 0.02047290839254856\n",
            "MSE Loss is: 0.017386125400662422, h Loss is: 0.00020200497237965465, L1 loss: 1.4147471189498901, Total Loss is: 0.01758813112974167\n",
            "MSE Loss is: 0.019481804221868515, h Loss is: 0.00020427367417141795, L1 loss: 1.4149020910263062, Total Loss is: 0.019686078652739525\n",
            "MSE Loss is: 0.019672464579343796, h Loss is: 0.00020706844225060195, L1 loss: 1.4156564474105835, Total Loss is: 0.019879532977938652\n",
            "MSE Loss is: 0.018352335318922997, h Loss is: 0.00021036367979831994, L1 loss: 1.4168227910995483, Total Loss is: 0.018562698736786842\n",
            "MSE Loss is: 0.019542546942830086, h Loss is: 0.00021399540128186345, L1 loss: 1.4183423519134521, Total Loss is: 0.019756542518734932\n",
            "MSE Loss is: 0.018884437158703804, h Loss is: 0.00021792124607600272, L1 loss: 1.4200981855392456, Total Loss is: 0.01910235919058323\n",
            "MSE Loss is: 0.016406483948230743, h Loss is: 0.00022200492094270885, L1 loss: 1.4219281673431396, Total Loss is: 0.016628488898277283\n",
            "MSE Loss is: 0.0181367676705122, h Loss is: 0.00022596689814236015, L1 loss: 1.4237467050552368, Total Loss is: 0.018362734466791153\n",
            "MSE Loss is: 0.018537471070885658, h Loss is: 0.00022972680744715035, L1 loss: 1.4253759384155273, Total Loss is: 0.01876719854772091\n",
            "MSE Loss is: 0.01726428233087063, h Loss is: 0.00023302972840610892, L1 loss: 1.4267266988754272, Total Loss is: 0.017497312277555466\n",
            "MSE Loss is: 0.02390015684068203, h Loss is: 0.00023588626936543733, L1 loss: 1.4276995658874512, Total Loss is: 0.024136042222380638\n",
            "MSE Loss is: 0.023304767906665802, h Loss is: 0.0002381811646046117, L1 loss: 1.428281307220459, Total Loss is: 0.023542949929833412\n",
            "MSE Loss is: 0.02429269254207611, h Loss is: 0.00023989421606529504, L1 loss: 1.4284242391586304, Total Loss is: 0.024532586336135864\n",
            "MSE Loss is: 0.01943647675216198, h Loss is: 0.0002411652239970863, L1 loss: 1.4281506538391113, Total Loss is: 0.019677642732858658\n",
            "MSE Loss is: 0.020216507837176323, h Loss is: 0.000241833200561814, L1 loss: 1.4275058507919312, Total Loss is: 0.020458340644836426\n",
            "New h_val is : tf.Tensor(0.008611679, shape=(), dtype=float32)\n",
            "Epoch: {} 4\n",
            "MSE Loss is: 0.020882731303572655, h Loss is: 0.0003452512319199741, L1 loss: 1.426625370979309, Total Loss is: 0.02122798189520836\n",
            "MSE Loss is: 0.021280433982610703, h Loss is: 0.00034542629146017134, L1 loss: 1.4255290031433105, Total Loss is: 0.021625859662890434\n",
            "MSE Loss is: 0.02155185118317604, h Loss is: 0.00034533877624198794, L1 loss: 1.4243698120117188, Total Loss is: 0.02189718931913376\n",
            "MSE Loss is: 0.019559349864721298, h Loss is: 0.00034536063321866095, L1 loss: 1.4231423139572144, Total Loss is: 0.019904710352420807\n",
            "MSE Loss is: 0.01657332107424736, h Loss is: 0.00034533877624198794, L1 loss: 1.4218809604644775, Total Loss is: 0.016918659210205078\n",
            "MSE Loss is: 0.01877988874912262, h Loss is: 0.000345295004080981, L1 loss: 1.4207385778427124, Total Loss is: 0.019125184044241905\n",
            "MSE Loss is: 0.019051125273108482, h Loss is: 0.0003454700345173478, L1 loss: 1.419805645942688, Total Loss is: 0.019396595656871796\n",
            "MSE Loss is: 0.017913205549120903, h Loss is: 0.00034617038909345865, L1 loss: 1.4190202951431274, Total Loss is: 0.018259376287460327\n",
            "MSE Loss is: 0.019151661545038223, h Loss is: 0.00034726536250673234, L1 loss: 1.4184772968292236, Total Loss is: 0.019498927518725395\n",
            "MSE Loss is: 0.01870403066277504, h Loss is: 0.0003489530645310879, L1 loss: 1.4182014465332031, Total Loss is: 0.019052984192967415\n",
            "MSE Loss is: 0.016305774450302124, h Loss is: 0.0003512573894113302, L1 loss: 1.418237328529358, Total Loss is: 0.016657032072544098\n",
            "MSE Loss is: 0.01802493818104267, h Loss is: 0.0003540269681252539, L1 loss: 1.4185409545898438, Total Loss is: 0.01837896555662155\n",
            "MSE Loss is: 0.018388893455266953, h Loss is: 0.0003572421846911311, L1 loss: 1.4189972877502441, Total Loss is: 0.018746135756373405\n",
            "MSE Loss is: 0.01712949015200138, h Loss is: 0.0003605742531362921, L1 loss: 1.4195746183395386, Total Loss is: 0.017490064725279808\n",
            "MSE Loss is: 0.0235934779047966, h Loss is: 0.0003642895899247378, L1 loss: 1.4201667308807373, Total Loss is: 0.023957766592502594\n",
            "MSE Loss is: 0.022920094430446625, h Loss is: 0.00036821322282776237, L1 loss: 1.4207595586776733, Total Loss is: 0.023288307711482048\n",
            "MSE Loss is: 0.02391137182712555, h Loss is: 0.00037207957939244807, L1 loss: 1.4212836027145386, Total Loss is: 0.024283451959490776\n",
            "MSE Loss is: 0.01912715658545494, h Loss is: 0.0003762673295568675, L1 loss: 1.4216843843460083, Total Loss is: 0.01950342394411564\n",
            "MSE Loss is: 0.019895687699317932, h Loss is: 0.00038010801654309034, L1 loss: 1.421950101852417, Total Loss is: 0.020275795832276344\n",
            "New h_val is : tf.Tensor(0.009451389, shape=(), dtype=float32)\n",
            "Epoch: {} 5\n",
            "MSE Loss is: 0.020641930401325226, h Loss is: 0.0005203056498430669, L1 loss: 1.4220407009124756, Total Loss is: 0.021162236109375954\n",
            "MSE Loss is: 0.021023795008659363, h Loss is: 0.000525046547409147, L1 loss: 1.4219801425933838, Total Loss is: 0.021548841148614883\n",
            "MSE Loss is: 0.021296175196766853, h Loss is: 0.0005295880255289376, L1 loss: 1.421838402748108, Total Loss is: 0.0218257624655962\n",
            "MSE Loss is: 0.019396182149648666, h Loss is: 0.0005340776988305151, L1 loss: 1.4215503931045532, Total Loss is: 0.019930260255932808\n",
            "MSE Loss is: 0.01645796373486519, h Loss is: 0.000538127962499857, L1 loss: 1.4210697412490845, Total Loss is: 0.016996091231703758\n",
            "MSE Loss is: 0.01857835426926613, h Loss is: 0.0005415277555584908, L1 loss: 1.4205092191696167, Total Loss is: 0.019119881093502045\n",
            "MSE Loss is: 0.018902406096458435, h Loss is: 0.0005446032155305147, L1 loss: 1.4199533462524414, Total Loss is: 0.01944701001048088\n",
            "MSE Loss is: 0.017728567123413086, h Loss is: 0.000547712086699903, L1 loss: 1.4193171262741089, Total Loss is: 0.018276279792189598\n",
            "MSE Loss is: 0.018893392756581306, h Loss is: 0.0005507347523234785, L1 loss: 1.4187246561050415, Total Loss is: 0.01944412663578987\n",
            "MSE Loss is: 0.018515247851610184, h Loss is: 0.0005540006677620113, L1 loss: 1.4182370901107788, Total Loss is: 0.0190692488104105\n",
            "MSE Loss is: 0.01612536981701851, h Loss is: 0.0005576307303272188, L1 loss: 1.417830228805542, Total Loss is: 0.016683001071214676\n",
            "MSE Loss is: 0.017829716205596924, h Loss is: 0.0005613859393633902, L1 loss: 1.4175728559494019, Total Loss is: 0.01839110255241394\n",
            "MSE Loss is: 0.01823793537914753, h Loss is: 0.0005655377171933651, L1 loss: 1.4174031019210815, Total Loss is: 0.018803473562002182\n",
            "MSE Loss is: 0.01701333560049534, h Loss is: 0.0005695450818166137, L1 loss: 1.4173401594161987, Total Loss is: 0.017582880333065987\n",
            "MSE Loss is: 0.023402521386742592, h Loss is: 0.0005739508778788149, L1 loss: 1.4173177480697632, Total Loss is: 0.02397647313773632\n",
            "MSE Loss is: 0.022746805101633072, h Loss is: 0.0005787570844404399, L1 loss: 1.4173654317855835, Total Loss is: 0.023325562477111816\n",
            "MSE Loss is: 0.0237028319388628, h Loss is: 0.0005834504845552146, L1 loss: 1.4174422025680542, Total Loss is: 0.024286283180117607\n",
            "MSE Loss is: 0.018960680812597275, h Loss is: 0.0005887894076295197, L1 loss: 1.4175136089324951, Total Loss is: 0.019549470394849777\n",
            "MSE Loss is: 0.01967833749949932, h Loss is: 0.0005938953254371881, L1 loss: 1.417580008506775, Total Loss is: 0.020272232592105865\n",
            "New h_val is : tf.Tensor(0.010704994, shape=(), dtype=float32)\n",
            "Epoch: {} 6\n",
            "MSE Loss is: 0.0204613134264946, h Loss is: 0.0007916147587820888, L1 loss: 1.4175653457641602, Total Loss is: 0.02125292830169201\n",
            "MSE Loss is: 0.020854663103818893, h Loss is: 0.0007983650430105627, L1 loss: 1.417523741722107, Total Loss is: 0.021653028205037117\n",
            "MSE Loss is: 0.021052496507763863, h Loss is: 0.000805205199867487, L1 loss: 1.417517066001892, Total Loss is: 0.021857701241970062\n",
            "MSE Loss is: 0.019195329397916794, h Loss is: 0.0008123733568936586, L1 loss: 1.4174474477767944, Total Loss is: 0.020007703453302383\n",
            "MSE Loss is: 0.016301535069942474, h Loss is: 0.0008191565284505486, L1 loss: 1.4172319173812866, Total Loss is: 0.017120691016316414\n",
            "MSE Loss is: 0.018431734293699265, h Loss is: 0.000825115479528904, L1 loss: 1.4169588088989258, Total Loss is: 0.019256848841905594\n",
            "MSE Loss is: 0.01872299611568451, h Loss is: 0.0008306049858219922, L1 loss: 1.4166911840438843, Total Loss is: 0.01955360174179077\n",
            "MSE Loss is: 0.01758982241153717, h Loss is: 0.0008363007218576968, L1 loss: 1.416312336921692, Total Loss is: 0.01842612400650978\n",
            "MSE Loss is: 0.01869277097284794, h Loss is: 0.0008418044890277088, L1 loss: 1.4159330129623413, Total Loss is: 0.019534574821591377\n",
            "MSE Loss is: 0.018376875668764114, h Loss is: 0.0008476747898384929, L1 loss: 1.4156039953231812, Total Loss is: 0.01922455057501793\n",
            "MSE Loss is: 0.015991896390914917, h Loss is: 0.0008539532427676022, L1 loss: 1.4152907133102417, Total Loss is: 0.01684585027396679\n",
            "MSE Loss is: 0.017668886110186577, h Loss is: 0.0008603208116255701, L1 loss: 1.415064811706543, Total Loss is: 0.01852920651435852\n",
            "MSE Loss is: 0.01808357983827591, h Loss is: 0.0008672997355461121, L1 loss: 1.4148622751235962, Total Loss is: 0.01895087957382202\n",
            "MSE Loss is: 0.01692228391766548, h Loss is: 0.0008738474571146071, L1 loss: 1.4147132635116577, Total Loss is: 0.01779613085091114\n",
            "MSE Loss is: 0.023209569975733757, h Loss is: 0.0008810089202597737, L1 loss: 1.4145594835281372, Total Loss is: 0.02409057877957821\n",
            "MSE Loss is: 0.022558927536010742, h Loss is: 0.0008887465810403228, L1 loss: 1.4144471883773804, Total Loss is: 0.0234476737678051\n",
            "MSE Loss is: 0.02349831536412239, h Loss is: 0.000896295765414834, L1 loss: 1.414350986480713, Total Loss is: 0.02439461089670658\n",
            "MSE Loss is: 0.018806081265211105, h Loss is: 0.0009049102081917226, L1 loss: 1.414249300956726, Total Loss is: 0.01971099153161049\n",
            "MSE Loss is: 0.019494352862238884, h Loss is: 0.0009130950784310699, L1 loss: 1.4141578674316406, Total Loss is: 0.02040744759142399\n",
            "New h_val is : tf.Tensor(0.012256622, shape=(), dtype=float32)\n",
            "Epoch: {} 7\n",
            "MSE Loss is: 0.020299572497606277, h Loss is: 0.0011991829378530383, L1 loss: 1.4140037298202515, Total Loss is: 0.021498754620552063\n",
            "MSE Loss is: 0.02067708596587181, h Loss is: 0.0012102521723136306, L1 loss: 1.4138563871383667, Total Loss is: 0.021887337788939476\n",
            "MSE Loss is: 0.020818445831537247, h Loss is: 0.0012216003378853202, L1 loss: 1.4137885570526123, Total Loss is: 0.022040046751499176\n",
            "MSE Loss is: 0.019015392288565636, h Loss is: 0.0012336461804807186, L1 loss: 1.4136948585510254, Total Loss is: 0.02024903893470764\n",
            "MSE Loss is: 0.01616491936147213, h Loss is: 0.001245085964910686, L1 loss: 1.4134798049926758, Total Loss is: 0.017410004511475563\n",
            "MSE Loss is: 0.018279746174812317, h Loss is: 0.001255288254469633, L1 loss: 1.4132295846939087, Total Loss is: 0.019535034894943237\n",
            "MSE Loss is: 0.01854388788342476, h Loss is: 0.0012646670220419765, L1 loss: 1.413004755973816, Total Loss is: 0.019808555021882057\n",
            "MSE Loss is: 0.0174531489610672, h Loss is: 0.0012742687249556184, L1 loss: 1.412674069404602, Total Loss is: 0.018727418035268784\n",
            "MSE Loss is: 0.01849878951907158, h Loss is: 0.0012834633234888315, L1 loss: 1.4123454093933105, Total Loss is: 0.019782252609729767\n",
            "MSE Loss is: 0.018238259479403496, h Loss is: 0.0012931966921314597, L1 loss: 1.412064552307129, Total Loss is: 0.019531456753611565\n",
            "MSE Loss is: 0.01586700975894928, h Loss is: 0.0013033656869083643, L1 loss: 1.4117882251739502, Total Loss is: 0.017170375213027\n",
            "MSE Loss is: 0.017508171498775482, h Loss is: 0.0013136552879586816, L1 loss: 1.411585807800293, Total Loss is: 0.018821826204657555\n",
            "MSE Loss is: 0.01794370636343956, h Loss is: 0.001324489014223218, L1 loss: 1.411385416984558, Total Loss is: 0.01926819607615471\n",
            "MSE Loss is: 0.016827015206217766, h Loss is: 0.0013345452025532722, L1 loss: 1.4112181663513184, Total Loss is: 0.018161561340093613\n",
            "MSE Loss is: 0.02302161231637001, h Loss is: 0.001345411641523242, L1 loss: 1.4110231399536133, Total Loss is: 0.02436702325940132\n",
            "MSE Loss is: 0.022380152717232704, h Loss is: 0.001357251312583685, L1 loss: 1.4108524322509766, Total Loss is: 0.023737404495477676\n",
            "MSE Loss is: 0.023296363651752472, h Loss is: 0.0013683127472177148, L1 loss: 1.4106842279434204, Total Loss is: 0.024664675816893578\n",
            "MSE Loss is: 0.01864819973707199, h Loss is: 0.0013812575489282608, L1 loss: 1.4105015993118286, Total Loss is: 0.020029457286000252\n",
            "MSE Loss is: 0.019311510026454926, h Loss is: 0.0013933713780716062, L1 loss: 1.4103285074234009, Total Loss is: 0.020704882219433784\n",
            "New h_val is : tf.Tensor(0.014131069, shape=(), dtype=float32)\n",
            "Epoch: {} 8\n",
            "MSE Loss is: 0.020139150321483612, h Loss is: 0.0018121208995580673, L1 loss: 1.4100929498672485, Total Loss is: 0.02195127122104168\n",
            "MSE Loss is: 0.020502371713519096, h Loss is: 0.0018286166014149785, L1 loss: 1.409873366355896, Total Loss is: 0.022330988198518753\n",
            "MSE Loss is: 0.020590942353010178, h Loss is: 0.0018458189442753792, L1 loss: 1.4097528457641602, Total Loss is: 0.022436760365962982\n",
            "MSE Loss is: 0.018840763717889786, h Loss is: 0.0018644812516868114, L1 loss: 1.409620761871338, Total Loss is: 0.020705245435237885\n",
            "MSE Loss is: 0.0160246342420578, h Loss is: 0.0018823571735993028, L1 loss: 1.4093738794326782, Total Loss is: 0.01790699176490307\n",
            "MSE Loss is: 0.018130846321582794, h Loss is: 0.0018982116598635912, L1 loss: 1.4091010093688965, Total Loss is: 0.020029058679938316\n",
            "MSE Loss is: 0.01837153360247612, h Loss is: 0.0019130626460537314, L1 loss: 1.4088659286499023, Total Loss is: 0.02028459683060646\n",
            "MSE Loss is: 0.017317581921815872, h Loss is: 0.001928551821038127, L1 loss: 1.4085302352905273, Total Loss is: 0.019246133044362068\n",
            "MSE Loss is: 0.018308227881789207, h Loss is: 0.001943376730196178, L1 loss: 1.408203125, Total Loss is: 0.020251603797078133\n",
            "MSE Loss is: 0.01810298301279545, h Loss is: 0.0019589790608733892, L1 loss: 1.4079302549362183, Total Loss is: 0.02006196230649948\n",
            "MSE Loss is: 0.01574469357728958, h Loss is: 0.0019754995591938496, L1 loss: 1.407663106918335, Total Loss is: 0.017720192670822144\n",
            "MSE Loss is: 0.01734970510005951, h Loss is: 0.0019921145867556334, L1 loss: 1.4074705839157104, Total Loss is: 0.01934181898832321\n",
            "MSE Loss is: 0.01780487224459648, h Loss is: 0.0020097228698432446, L1 loss: 1.407273292541504, Total Loss is: 0.019814595580101013\n",
            "MSE Loss is: 0.016734654083848, h Loss is: 0.002025906229391694, L1 loss: 1.4071019887924194, Total Loss is: 0.01876056008040905\n",
            "MSE Loss is: 0.022837022319436073, h Loss is: 0.0020431538578122854, L1 loss: 1.4068909883499146, Total Loss is: 0.024880176410079002\n",
            "MSE Loss is: 0.022205360233783722, h Loss is: 0.002061678795143962, L1 loss: 1.406694769859314, Total Loss is: 0.024267038330435753\n",
            "MSE Loss is: 0.023097718134522438, h Loss is: 0.0020791920833289623, L1 loss: 1.406491756439209, Total Loss is: 0.025176910683512688\n",
            "MSE Loss is: 0.018494486808776855, h Loss is: 0.0020992413628846407, L1 loss: 1.4062658548355103, Total Loss is: 0.020593728870153427\n",
            "MSE Loss is: 0.01913156732916832, h Loss is: 0.0021178617607802153, L1 loss: 1.4060449600219727, Total Loss is: 0.021249428391456604\n",
            "New h_val is : tf.Tensor(0.016386509, shape=(), dtype=float32)\n",
            "Epoch: {} 9\n",
            "MSE Loss is: 0.019981592893600464, h Loss is: 0.002738074865192175, L1 loss: 1.4057575464248657, Total Loss is: 0.022719668224453926\n",
            "MSE Loss is: 0.02032913640141487, h Loss is: 0.002763052936643362, L1 loss: 1.4054863452911377, Total Loss is: 0.02309218980371952\n",
            "MSE Loss is: 0.020365536212921143, h Loss is: 0.0027892200741916895, L1 loss: 1.4053233861923218, Total Loss is: 0.02315475605428219\n",
            "MSE Loss is: 0.018670134246349335, h Loss is: 0.0028179113287478685, L1 loss: 1.4051525592803955, Total Loss is: 0.021488046273589134\n",
            "MSE Loss is: 0.01588706113398075, h Loss is: 0.0028451443649828434, L1 loss: 1.404863715171814, Total Loss is: 0.018732205033302307\n",
            "MSE Loss is: 0.01798516884446144, h Loss is: 0.0028692223131656647, L1 loss: 1.4045498371124268, Total Loss is: 0.020854391157627106\n",
            "MSE Loss is: 0.018201112747192383, h Loss is: 0.0028917333111166954, L1 loss: 1.404279112815857, Total Loss is: 0.021092846989631653\n",
            "MSE Loss is: 0.017185572534799576, h Loss is: 0.0029151670169085264, L1 loss: 1.4039087295532227, Total Loss is: 0.02010073885321617\n",
            "MSE Loss is: 0.018121179193258286, h Loss is: 0.002937830751761794, L1 loss: 1.4035521745681763, Total Loss is: 0.021059010177850723\n",
            "MSE Loss is: 0.017970053479075432, h Loss is: 0.0029615990351885557, L1 loss: 1.4032562971115112, Total Loss is: 0.020931651815772057\n",
            "MSE Loss is: 0.015624471008777618, h Loss is: 0.0029869242571294308, L1 loss: 1.402970790863037, Total Loss is: 0.018611395731568336\n",
            "MSE Loss is: 0.017192337661981583, h Loss is: 0.0030124676413834095, L1 loss: 1.4027655124664307, Total Loss is: 0.020204804837703705\n",
            "MSE Loss is: 0.017668334767222404, h Loss is: 0.0030397577211260796, L1 loss: 1.4025541543960571, Total Loss is: 0.02070809155702591\n",
            "MSE Loss is: 0.016643963754177094, h Loss is: 0.0030645732767879963, L1 loss: 1.402368426322937, Total Loss is: 0.019708536565303802\n",
            "MSE Loss is: 0.022656138986349106, h Loss is: 0.0030913185328245163, L1 loss: 1.4021371603012085, Total Loss is: 0.025747457519173622\n",
            "MSE Loss is: 0.02203478291630745, h Loss is: 0.0031199119985103607, L1 loss: 1.4019170999526978, Total Loss is: 0.02515469491481781\n",
            "MSE Loss is: 0.02290261909365654, h Loss is: 0.003146836534142494, L1 loss: 1.4016859531402588, Total Loss is: 0.026049455627799034\n",
            "MSE Loss is: 0.018341079354286194, h Loss is: 0.003177427453920245, L1 loss: 1.401426911354065, Total Loss is: 0.021518506109714508\n",
            "MSE Loss is: 0.01895476132631302, h Loss is: 0.0032057147473096848, L1 loss: 1.4011708498001099, Total Loss is: 0.022160476073622704\n",
            "New h_val is : tf.Tensor(0.01903963, shape=(), dtype=float32)\n",
            "Epoch: {} 10\n",
            "MSE Loss is: 0.019826870411634445, h Loss is: 0.004127789754420519, L1 loss: 1.4008439779281616, Total Loss is: 0.023954659700393677\n",
            "MSE Loss is: 0.02015783078968525, h Loss is: 0.004165750928223133, L1 loss: 1.4005335569381714, Total Loss is: 0.024323582649230957\n",
            "MSE Loss is: 0.02014363929629326, h Loss is: 0.004205834120512009, L1 loss: 1.400338053703308, Total Loss is: 0.024349473416805267\n",
            "MSE Loss is: 0.018502138555049896, h Loss is: 0.00424942746758461, L1 loss: 1.4001359939575195, Total Loss is: 0.022751566022634506\n",
            "MSE Loss is: 0.01574944518506527, h Loss is: 0.004291027784347534, L1 loss: 1.399810552597046, Total Loss is: 0.020040472969412804\n",
            "MSE Loss is: 0.017841462045907974, h Loss is: 0.004327629692852497, L1 loss: 1.3994569778442383, Total Loss is: 0.022169090807437897\n",
            "MSE Loss is: 0.018033737316727638, h Loss is: 0.004361978732049465, L1 loss: 1.399148941040039, Total Loss is: 0.02239571511745453\n",
            "MSE Loss is: 0.017055664211511612, h Loss is: 0.0043976460583508015, L1 loss: 1.3987401723861694, Total Loss is: 0.021453309804201126\n",
            "MSE Loss is: 0.017937324941158295, h Loss is: 0.004431976471096277, L1 loss: 1.3983477354049683, Total Loss is: 0.022369300946593285\n",
            "MSE Loss is: 0.017839189618825912, h Loss is: 0.004468091763556004, L1 loss: 1.398021936416626, Total Loss is: 0.02230728045105934\n",
            "MSE Loss is: 0.015505601651966572, h Loss is: 0.004506811499595642, L1 loss: 1.397709846496582, Total Loss is: 0.02001241222023964\n",
            "MSE Loss is: 0.017035195603966713, h Loss is: 0.0045458232052624226, L1 loss: 1.3974835872650146, Total Loss is: 0.021581018343567848\n",
            "MSE Loss is: 0.017533516511321068, h Loss is: 0.004587688948959112, L1 loss: 1.3972506523132324, Total Loss is: 0.022121205925941467\n",
            "MSE Loss is: 0.016554201021790504, h Loss is: 0.004625660367310047, L1 loss: 1.3970437049865723, Total Loss is: 0.021179862320423126\n",
            "MSE Loss is: 0.02247815579175949, h Loss is: 0.0046662576496601105, L1 loss: 1.3967868089675903, Total Loss is: 0.0271444134414196\n",
            "MSE Loss is: 0.021868735551834106, h Loss is: 0.00470984261482954, L1 loss: 1.3965383768081665, Total Loss is: 0.02657857909798622\n",
            "MSE Loss is: 0.022710232064127922, h Loss is: 0.004750574007630348, L1 loss: 1.3962759971618652, Total Loss is: 0.02746080607175827\n",
            "MSE Loss is: 0.018188858404755592, h Loss is: 0.004796651192009449, L1 loss: 1.3959827423095703, Total Loss is: 0.022985510528087616\n",
            "MSE Loss is: 0.018779894337058067, h Loss is: 0.004839400760829449, L1 loss: 1.3958016633987427, Total Loss is: 0.02361929416656494\n",
            "New h_val is : tf.Tensor(0.022154331, shape=(), dtype=float32)\n",
            "Epoch: {} 11\n",
            "MSE Loss is: 0.019674403592944145, h Loss is: 0.006213658954948187, L1 loss: 1.395537257194519, Total Loss is: 0.02588806301355362\n",
            "MSE Loss is: 0.0199880413711071, h Loss is: 0.006270395591855049, L1 loss: 1.3952932357788086, Total Loss is: 0.02625843696296215\n",
            "MSE Loss is: 0.0199239831417799, h Loss is: 0.006330921780318022, L1 loss: 1.3951669931411743, Total Loss is: 0.02625490538775921\n",
            "MSE Loss is: 0.01833585649728775, h Loss is: 0.006396887823939323, L1 loss: 1.3950461149215698, Total Loss is: 0.024732744321227074\n",
            "MSE Loss is: 0.015611067414283752, h Loss is: 0.006459254305809736, L1 loss: 1.3947957754135132, Total Loss is: 0.022070322185754776\n",
            "MSE Loss is: 0.017699742689728737, h Loss is: 0.006514282431453466, L1 loss: 1.394524335861206, Total Loss is: 0.02421402558684349\n",
            "MSE Loss is: 0.017867911607027054, h Loss is: 0.006565963849425316, L1 loss: 1.3942888975143433, Total Loss is: 0.02443387545645237\n",
            "MSE Loss is: 0.016927512362599373, h Loss is: 0.006619507446885109, L1 loss: 1.3939608335494995, Total Loss is: 0.023547019809484482\n",
            "MSE Loss is: 0.017755810171365738, h Loss is: 0.006671033799648285, L1 loss: 1.3936418294906616, Total Loss is: 0.024426843971014023\n",
            "MSE Loss is: 0.017709948122501373, h Loss is: 0.006725624203681946, L1 loss: 1.3933970928192139, Total Loss is: 0.02443557232618332\n",
            "MSE Loss is: 0.015387577936053276, h Loss is: 0.006784189958125353, L1 loss: 1.3931611776351929, Total Loss is: 0.02217176742851734\n",
            "MSE Loss is: 0.016877785325050354, h Loss is: 0.006843446753919125, L1 loss: 1.3930248022079468, Total Loss is: 0.023721233010292053\n",
            "MSE Loss is: 0.017399486154317856, h Loss is: 0.006906855385750532, L1 loss: 1.3931280374526978, Total Loss is: 0.024306342005729675\n",
            "MSE Loss is: 0.016465462744235992, h Loss is: 0.006964494939893484, L1 loss: 1.3934043645858765, Total Loss is: 0.023429958149790764\n",
            "MSE Loss is: 0.022302422672510147, h Loss is: 0.007025992497801781, L1 loss: 1.3935664892196655, Total Loss is: 0.029328415170311928\n",
            "MSE Loss is: 0.0217061098664999, h Loss is: 0.00709196925163269, L1 loss: 1.393731713294983, Total Loss is: 0.02879807911813259\n",
            "MSE Loss is: 0.022519711405038834, h Loss is: 0.0071533676236867905, L1 loss: 1.3939611911773682, Total Loss is: 0.029673079028725624\n",
            "MSE Loss is: 0.018036581575870514, h Loss is: 0.007222897373139858, L1 loss: 1.3942312002182007, Total Loss is: 0.025259479880332947\n",
            "MSE Loss is: 0.01860634982585907, h Loss is: 0.007286931853741407, L1 loss: 1.3944815397262573, Total Loss is: 0.025893282145261765\n",
            "New h_val is : tf.Tensor(0.025788784, shape=(), dtype=float32)\n",
            "Epoch: {} 12\n",
            "MSE Loss is: 0.019523339346051216, h Loss is: 0.00933574978262186, L1 loss: 1.3946584463119507, Total Loss is: 0.02885909005999565\n",
            "MSE Loss is: 0.019818782806396484, h Loss is: 0.00942035112529993, L1 loss: 1.3948575258255005, Total Loss is: 0.02923913300037384\n",
            "MSE Loss is: 0.019705232232809067, h Loss is: 0.009511001408100128, L1 loss: 1.3952463865280151, Total Loss is: 0.029216233640909195\n",
            "MSE Loss is: 0.018170291557908058, h Loss is: 0.00961021613329649, L1 loss: 1.3956525325775146, Total Loss is: 0.027780506759881973\n",
            "MSE Loss is: 0.015471315942704678, h Loss is: 0.009703855030238628, L1 loss: 1.3959039449691772, Total Loss is: 0.025175170972943306\n",
            "MSE Loss is: 0.017559058964252472, h Loss is: 0.009786132723093033, L1 loss: 1.3961230516433716, Total Loss is: 0.027345191687345505\n",
            "MSE Loss is: 0.017702609300613403, h Loss is: 0.009863339364528656, L1 loss: 1.396410584449768, Total Loss is: 0.02756594866514206\n",
            "MSE Loss is: 0.016800321638584137, h Loss is: 0.009942961856722832, L1 loss: 1.3965559005737305, Total Loss is: 0.02674328349530697\n",
            "MSE Loss is: 0.017575537785887718, h Loss is: 0.010020188987255096, L1 loss: 1.3966630697250366, Total Loss is: 0.027595726773142815\n",
            "MSE Loss is: 0.01758139580488205, h Loss is: 0.010101767256855965, L1 loss: 1.3968623876571655, Total Loss is: 0.027683163061738014\n",
            "MSE Loss is: 0.015269558876752853, h Loss is: 0.010189645923674107, L1 loss: 1.3970909118652344, Total Loss is: 0.025459203869104385\n",
            "MSE Loss is: 0.016718963161110878, h Loss is: 0.010278820060193539, L1 loss: 1.3974359035491943, Total Loss is: 0.026997782289981842\n",
            "MSE Loss is: 0.017265506088733673, h Loss is: 0.010373949073255062, L1 loss: 1.3977431058883667, Total Loss is: 0.02763945609331131\n",
            "MSE Loss is: 0.01637709140777588, h Loss is: 0.010461466386914253, L1 loss: 1.3981279134750366, Total Loss is: 0.026838557794690132\n",
            "MSE Loss is: 0.02212786301970482, h Loss is: 0.010553199797868729, L1 loss: 1.398396372795105, Total Loss is: 0.03268106281757355\n",
            "MSE Loss is: 0.02154598943889141, h Loss is: 0.010652480646967888, L1 loss: 1.3986705541610718, Total Loss is: 0.0321984700858593\n",
            "MSE Loss is: 0.02232983708381653, h Loss is: 0.010744514875113964, L1 loss: 1.3989218473434448, Total Loss is: 0.03307435289025307\n",
            "MSE Loss is: 0.017883216962218285, h Loss is: 0.010848421603441238, L1 loss: 1.3991650342941284, Total Loss is: 0.028731638565659523\n",
            "MSE Loss is: 0.01843305118381977, h Loss is: 0.010943700559437275, L1 loss: 1.399387240409851, Total Loss is: 0.02937675267457962\n",
            "New h_val is : tf.Tensor(0.03000927, shape=(), dtype=float32)\n",
            "Epoch: {} 13\n",
            "MSE Loss is: 0.01937265507876873, h Loss is: 0.013995898887515068, L1 loss: 1.3995336294174194, Total Loss is: 0.0333685539662838\n",
            "MSE Loss is: 0.0196489579975605, h Loss is: 0.014121497049927711, L1 loss: 1.3997032642364502, Total Loss is: 0.03377045691013336\n",
            "MSE Loss is: 0.019485997036099434, h Loss is: 0.014256869442760944, L1 loss: 1.4000707864761353, Total Loss is: 0.03374286741018295\n",
            "MSE Loss is: 0.018004292622208595, h Loss is: 0.01440452877432108, L1 loss: 1.4004563093185425, Total Loss is: 0.03240882232785225\n",
            "MSE Loss is: 0.015329068526625633, h Loss is: 0.014544054865837097, L1 loss: 1.4006801843643188, Total Loss is: 0.02987312339246273\n",
            "MSE Loss is: 0.0174185149371624, h Loss is: 0.01466676127165556, L1 loss: 1.4008692502975464, Total Loss is: 0.03208527714014053\n",
            "MSE Loss is: 0.017536737024784088, h Loss is: 0.01478147879242897, L1 loss: 1.4011274576187134, Total Loss is: 0.03231821581721306\n",
            "MSE Loss is: 0.016673218458890915, h Loss is: 0.014900065027177334, L1 loss: 1.4013248682022095, Total Loss is: 0.03157328441739082\n",
            "MSE Loss is: 0.017395226284861565, h Loss is: 0.015014350414276123, L1 loss: 1.4015640020370483, Total Loss is: 0.03240957856178284\n",
            "MSE Loss is: 0.017452657222747803, h Loss is: 0.015136736445128918, L1 loss: 1.4019228219985962, Total Loss is: 0.032589394599199295\n",
            "MSE Loss is: 0.015150726772844791, h Loss is: 0.015267506241798401, L1 loss: 1.4023064374923706, Total Loss is: 0.030418232083320618\n",
            "MSE Loss is: 0.01655767112970352, h Loss is: 0.015401214361190796, L1 loss: 1.4027798175811768, Total Loss is: 0.03195888549089432\n",
            "MSE Loss is: 0.01713070645928383, h Loss is: 0.015544112771749496, L1 loss: 1.4033162593841553, Total Loss is: 0.032674819231033325\n",
            "MSE Loss is: 0.016288504004478455, h Loss is: 0.01567474752664566, L1 loss: 1.4039052724838257, Total Loss is: 0.031963251531124115\n",
            "MSE Loss is: 0.021953344345092773, h Loss is: 0.015812084078788757, L1 loss: 1.404410719871521, Total Loss is: 0.03776542842388153\n",
            "MSE Loss is: 0.02138729952275753, h Loss is: 0.01595991849899292, L1 loss: 1.4049171209335327, Total Loss is: 0.0373472198843956\n",
            "MSE Loss is: 0.0221392922103405, h Loss is: 0.016096698120236397, L1 loss: 1.4054032564163208, Total Loss is: 0.038235992193222046\n",
            "MSE Loss is: 0.017727810889482498, h Loss is: 0.01625104993581772, L1 loss: 1.4058810472488403, Total Loss is: 0.03397886082530022\n",
            "MSE Loss is: 0.018258891999721527, h Loss is: 0.016392311081290245, L1 loss: 1.4063674211502075, Total Loss is: 0.03465120494365692\n",
            "New h_val is : tf.Tensor(0.03489542, shape=(), dtype=float32)\n",
            "Epoch: {} 14\n",
            "MSE Loss is: 0.01922127977013588, h Loss is: 0.020932001993060112, L1 loss: 1.406782627105713, Total Loss is: 0.04015327990055084\n",
            "MSE Loss is: 0.01947740837931633, h Loss is: 0.02111772447824478, L1 loss: 1.4072399139404297, Total Loss is: 0.04059513285756111\n",
            "MSE Loss is: 0.01926477625966072, h Loss is: 0.021317943930625916, L1 loss: 1.407812476158142, Total Loss is: 0.040582720190286636\n",
            "MSE Loss is: 0.017836784943938255, h Loss is: 0.021538104861974716, L1 loss: 1.4084266424179077, Total Loss is: 0.03937488794326782\n",
            "MSE Loss is: 0.015183445066213608, h Loss is: 0.02174469269812107, L1 loss: 1.408920168876648, Total Loss is: 0.03692813962697983\n",
            "MSE Loss is: 0.017277158796787262, h Loss is: 0.021926524117588997, L1 loss: 1.4093583822250366, Total Loss is: 0.03920368105173111\n",
            "MSE Loss is: 0.017369210720062256, h Loss is: 0.022096531465649605, L1 loss: 1.409827470779419, Total Loss is: 0.03946574032306671\n",
            "MSE Loss is: 0.016545366495847702, h Loss is: 0.022271856665611267, L1 loss: 1.4102107286453247, Total Loss is: 0.03881722316145897\n",
            "MSE Loss is: 0.017213594168424606, h Loss is: 0.022441361099481583, L1 loss: 1.4105473756790161, Total Loss is: 0.03965495526790619\n",
            "MSE Loss is: 0.0173228420317173, h Loss is: 0.022623222321271896, L1 loss: 1.4109976291656494, Total Loss is: 0.0399460643529892\n",
            "MSE Loss is: 0.01503029651939869, h Loss is: 0.022817805409431458, L1 loss: 1.4114654064178467, Total Loss is: 0.037848100066185\n",
            "MSE Loss is: 0.016392916440963745, h Loss is: 0.023017164319753647, L1 loss: 1.4120230674743652, Total Loss is: 0.03941008076071739\n",
            "MSE Loss is: 0.01699424907565117, h Loss is: 0.02322997897863388, L1 loss: 1.4125412702560425, Total Loss is: 0.04022422805428505\n",
            "MSE Loss is: 0.016199173405766487, h Loss is: 0.023424826562404633, L1 loss: 1.4131133556365967, Total Loss is: 0.03962399810552597\n",
            "MSE Loss is: 0.021777760237455368, h Loss is: 0.02362832985818386, L1 loss: 1.4135979413986206, Total Loss is: 0.04540608823299408\n",
            "MSE Loss is: 0.021228928118944168, h Loss is: 0.023848261684179306, L1 loss: 1.41408109664917, Total Loss is: 0.045077189803123474\n",
            "MSE Loss is: 0.021946784108877182, h Loss is: 0.024050801992416382, L1 loss: 1.4145426750183105, Total Loss is: 0.045997586101293564\n",
            "MSE Loss is: 0.017569366842508316, h Loss is: 0.024278871715068817, L1 loss: 1.4149948358535767, Total Loss is: 0.04184823855757713\n",
            "MSE Loss is: 0.0180828794836998, h Loss is: 0.02448725327849388, L1 loss: 1.4154553413391113, Total Loss is: 0.04257013276219368\n",
            "New h_val is : tf.Tensor(0.040531635, shape=(), dtype=float32)\n",
            "Epoch: {} 15\n",
            "MSE Loss is: 0.0190681554377079, h Loss is: 0.03122364915907383, L1 loss: 1.4158443212509155, Total Loss is: 0.05029180645942688\n",
            "MSE Loss is: 0.01930306665599346, h Loss is: 0.03149642422795296, L1 loss: 1.4162763357162476, Total Loss is: 0.05079948902130127\n",
            "MSE Loss is: 0.019040193408727646, h Loss is: 0.03179230913519859, L1 loss: 1.4168285131454468, Total Loss is: 0.05083250254392624\n",
            "MSE Loss is: 0.01766679435968399, h Loss is: 0.03211750090122223, L1 loss: 1.417423129081726, Total Loss is: 0.04978429526090622\n",
            "MSE Loss is: 0.015033656731247902, h Loss is: 0.032422490417957306, L1 loss: 1.417892336845398, Total Loss is: 0.04745614528656006\n",
            "MSE Loss is: 0.017134126275777817, h Loss is: 0.0326908715069294, L1 loss: 1.4183040857315063, Total Loss is: 0.049824997782707214\n",
            "MSE Loss is: 0.017199039459228516, h Loss is: 0.03294249251484871, L1 loss: 1.4187453985214233, Total Loss is: 0.050141531974077225\n",
            "MSE Loss is: 0.01641603372991085, h Loss is: 0.033200569450855255, L1 loss: 1.419097900390625, Total Loss is: 0.049616605043411255\n",
            "MSE Loss is: 0.01702946238219738, h Loss is: 0.033449579030275345, L1 loss: 1.4194023609161377, Total Loss is: 0.050479039549827576\n",
            "MSE Loss is: 0.017191126942634583, h Loss is: 0.033719394356012344, L1 loss: 1.4198253154754639, Total Loss is: 0.05091052129864693\n",
            "MSE Loss is: 0.014907583594322205, h Loss is: 0.03400681912899017, L1 loss: 1.420267939567566, Total Loss is: 0.04891440272331238\n",
            "MSE Loss is: 0.0162238460034132, h Loss is: 0.034302063286304474, L1 loss: 1.4208046197891235, Total Loss is: 0.050525911152362823\n",
            "MSE Loss is: 0.016855407506227493, h Loss is: 0.03461751341819763, L1 loss: 1.4213004112243652, Total Loss is: 0.051472920924425125\n",
            "MSE Loss is: 0.016108624637126923, h Loss is: 0.034907907247543335, L1 loss: 1.421852469444275, Total Loss is: 0.05101653188467026\n",
            "MSE Loss is: 0.021600112318992615, h Loss is: 0.03520864248275757, L1 loss: 1.4223124980926514, Total Loss is: 0.05680875480175018\n",
            "MSE Loss is: 0.021069850772619247, h Loss is: 0.03553340211510658, L1 loss: 1.4227694272994995, Total Loss is: 0.05660325288772583\n",
            "MSE Loss is: 0.021751131862401962, h Loss is: 0.03583218902349472, L1 loss: 1.4232038259506226, Total Loss is: 0.05758332088589668\n",
            "MSE Loss is: 0.017407061532139778, h Loss is: 0.03616834804415703, L1 loss: 1.423627257347107, Total Loss is: 0.053575411438941956\n",
            "MSE Loss is: 0.017904194071888924, h Loss is: 0.0364743247628212, L1 loss: 1.4240597486495972, Total Loss is: 0.05437851697206497\n",
            "New h_val is : tf.Tensor(0.047016144, shape=(), dtype=float32)\n",
            "Epoch: {} 16\n",
            "MSE Loss is: 0.01891232654452324, h Loss is: 0.04644237831234932, L1 loss: 1.4244197607040405, Total Loss is: 0.06535470485687256\n",
            "MSE Loss is: 0.019125018268823624, h Loss is: 0.04684124141931534, L1 loss: 1.4248247146606445, Total Loss is: 0.06596626341342926\n",
            "MSE Loss is: 0.01881110854446888, h Loss is: 0.047276534140110016, L1 loss: 1.4253536462783813, Total Loss is: 0.06608764082193375\n",
            "MSE Loss is: 0.017493538558483124, h Loss is: 0.04775414243340492, L1 loss: 1.4259254932403564, Total Loss is: 0.06524768471717834\n",
            "MSE Loss is: 0.01487908698618412, h Loss is: 0.048202306032180786, L1 loss: 1.4263676404953003, Total Loss is: 0.06308139115571976\n",
            "MSE Loss is: 0.016988683491945267, h Loss is: 0.04859685152769089, L1 loss: 1.4267504215240479, Total Loss is: 0.06558553874492645\n",
            "MSE Loss is: 0.017025399953126907, h Loss is: 0.04896683990955353, L1 loss: 1.4271608591079712, Total Loss is: 0.06599223613739014\n",
            "MSE Loss is: 0.016284629702568054, h Loss is: 0.04934568330645561, L1 loss: 1.4275014400482178, Total Loss is: 0.06563031673431396\n",
            "MSE Loss is: 0.016841821372509003, h Loss is: 0.04971139132976532, L1 loss: 1.427872657775879, Total Loss is: 0.06655321270227432\n",
            "MSE Loss is: 0.017056819051504135, h Loss is: 0.050108011811971664, L1 loss: 1.4283849000930786, Total Loss is: 0.0671648308634758\n",
            "MSE Loss is: 0.01478204783052206, h Loss is: 0.05053092911839485, L1 loss: 1.4289098978042603, Total Loss is: 0.06531297415494919\n",
            "MSE Loss is: 0.016049809753894806, h Loss is: 0.05096815899014473, L1 loss: 1.4295039176940918, Total Loss is: 0.06701797246932983\n",
            "MSE Loss is: 0.016713611781597137, h Loss is: 0.05143452063202858, L1 loss: 1.4300557374954224, Total Loss is: 0.06814813613891602\n",
            "MSE Loss is: 0.016016487032175064, h Loss is: 0.05186412110924721, L1 loss: 1.430662751197815, Total Loss is: 0.06788060814142227\n",
            "MSE Loss is: 0.021419592201709747, h Loss is: 0.05230598896741867, L1 loss: 1.431165099143982, Total Loss is: 0.07372558116912842\n",
            "MSE Loss is: 0.02090921625494957, h Loss is: 0.05278296023607254, L1 loss: 1.4316548109054565, Total Loss is: 0.07369217276573181\n",
            "MSE Loss is: 0.02155132405459881, h Loss is: 0.053221963346004486, L1 loss: 1.4321558475494385, Total Loss is: 0.07477328926324844\n",
            "MSE Loss is: 0.01724027283489704, h Loss is: 0.0537126362323761, L1 loss: 1.432693362236023, Total Loss is: 0.07095290720462799\n",
            "MSE Loss is: 0.017722265794873238, h Loss is: 0.0541604645550251, L1 loss: 1.4332267045974731, Total Loss is: 0.07188273221254349\n",
            "New h_val is : tf.Tensor(0.054452896, shape=(), dtype=float32)\n",
            "Epoch: {} 17\n",
            "MSE Loss is: 0.01875300705432892, h Loss is: 0.06886527687311172, L1 loss: 1.43370521068573, Total Loss is: 0.08761828392744064\n",
            "MSE Loss is: 0.018942570313811302, h Loss is: 0.06944536417722702, L1 loss: 1.4342494010925293, Total Loss is: 0.08838793635368347\n",
            "MSE Loss is: 0.018576689064502716, h Loss is: 0.07008212804794312, L1 loss: 1.4348734617233276, Total Loss is: 0.08865881711244583\n",
            "MSE Loss is: 0.01731649786233902, h Loss is: 0.07077980041503906, L1 loss: 1.435570240020752, Total Loss is: 0.08809629827737808\n",
            "MSE Loss is: 0.014719365164637566, h Loss is: 0.07143457978963852, L1 loss: 1.4361506700515747, Total Loss is: 0.08615394681692123\n",
            "MSE Loss is: 0.016840294003486633, h Loss is: 0.07201085239648819, L1 loss: 1.4366346597671509, Total Loss is: 0.08885114639997482\n",
            "MSE Loss is: 0.016847733408212662, h Loss is: 0.07255443930625916, L1 loss: 1.4371458292007446, Total Loss is: 0.08940216898918152\n",
            "MSE Loss is: 0.01615077629685402, h Loss is: 0.07310541719198227, L1 loss: 1.437620997428894, Total Loss is: 0.08925619721412659\n",
            "MSE Loss is: 0.016649922356009483, h Loss is: 0.07364100217819214, L1 loss: 1.4380182027816772, Total Loss is: 0.09029092639684677\n",
            "MSE Loss is: 0.016919411718845367, h Loss is: 0.07422226667404175, L1 loss: 1.4385584592819214, Total Loss is: 0.09114167839288712\n",
            "MSE Loss is: 0.014653350226581097, h Loss is: 0.07484196126461029, L1 loss: 1.439111351966858, Total Loss is: 0.08949530869722366\n",
            "MSE Loss is: 0.015870437026023865, h Loss is: 0.075485460460186, L1 loss: 1.4397389888763428, Total Loss is: 0.09135589748620987\n",
            "MSE Loss is: 0.016568513587117195, h Loss is: 0.0761697068810463, L1 loss: 1.4403512477874756, Total Loss is: 0.09273821860551834\n",
            "MSE Loss is: 0.01592254266142845, h Loss is: 0.07680368423461914, L1 loss: 1.4410074949264526, Total Loss is: 0.09272623062133789\n",
            "MSE Loss is: 0.021235650405287743, h Loss is: 0.07744872570037842, L1 loss: 1.441576600074768, Total Loss is: 0.09868437796831131\n",
            "MSE Loss is: 0.020746365189552307, h Loss is: 0.07814487814903259, L1 loss: 1.442142367362976, Total Loss is: 0.0988912433385849\n",
            "MSE Loss is: 0.021346621215343475, h Loss is: 0.07878714799880981, L1 loss: 1.442643404006958, Total Loss is: 0.10013376921415329\n",
            "MSE Loss is: 0.01706864684820175, h Loss is: 0.0795024037361145, L1 loss: 1.4431465864181519, Total Loss is: 0.09657105058431625\n",
            "MSE Loss is: 0.0175368320196867, h Loss is: 0.08015277981758118, L1 loss: 1.4436448812484741, Total Loss is: 0.09768961369991302\n",
            "New h_val is : tf.Tensor(0.06294918, shape=(), dtype=float32)\n",
            "Epoch: {} 18\n",
            "MSE Loss is: 0.018589619547128677, h Loss is: 0.10176458954811096, L1 loss: 1.4440892934799194, Total Loss is: 0.12035420536994934\n",
            "MSE Loss is: 0.018755309283733368, h Loss is: 0.10260319709777832, L1 loss: 1.4446009397506714, Total Loss is: 0.12135850638151169\n",
            "MSE Loss is: 0.01833648420870304, h Loss is: 0.10352790355682373, L1 loss: 1.4451936483383179, Total Loss is: 0.12186438590288162\n",
            "MSE Loss is: 0.01713547296822071, h Loss is: 0.10454418510198593, L1 loss: 1.4458597898483276, Total Loss is: 0.12167965620756149\n",
            "MSE Loss is: 0.014554406516253948, h Loss is: 0.10549391061067581, L1 loss: 1.4464057683944702, Total Loss is: 0.12004831433296204\n",
            "MSE Loss is: 0.016688654199242592, h Loss is: 0.10633238404989243, L1 loss: 1.4468530416488647, Total Loss is: 0.12302103638648987\n",
            "MSE Loss is: 0.016665764153003693, h Loss is: 0.10712411254644394, L1 loss: 1.447325587272644, Total Loss is: 0.12378987669944763\n",
            "MSE Loss is: 0.016014333814382553, h Loss is: 0.10792367160320282, L1 loss: 1.4477604627609253, Total Loss is: 0.12393800914287567\n",
            "MSE Loss is: 0.01645331084728241, h Loss is: 0.10870024561882019, L1 loss: 1.4481145143508911, Total Loss is: 0.1251535564661026\n",
            "MSE Loss is: 0.0167786106467247, h Loss is: 0.10955067723989487, L1 loss: 1.4486174583435059, Total Loss is: 0.12632928788661957\n",
            "MSE Loss is: 0.014521362259984016, h Loss is: 0.1104537844657898, L1 loss: 1.4491347074508667, Total Loss is: 0.12497514486312866\n",
            "MSE Loss is: 0.015685677528381348, h Loss is: 0.11139258742332458, L1 loss: 1.4497302770614624, Total Loss is: 0.12707826495170593\n",
            "MSE Loss is: 0.016420001164078712, h Loss is: 0.11239392310380936, L1 loss: 1.4503109455108643, Total Loss is: 0.12881392240524292\n",
            "MSE Loss is: 0.015826735645532608, h Loss is: 0.11332260072231293, L1 loss: 1.4509382247924805, Total Loss is: 0.12914933264255524\n",
            "MSE Loss is: 0.021048054099082947, h Loss is: 0.11426125466823578, L1 loss: 1.451474905014038, Total Loss is: 0.13530930876731873\n",
            "MSE Loss is: 0.02058091014623642, h Loss is: 0.11527309566736221, L1 loss: 1.452006220817566, Total Loss is: 0.13585400581359863\n",
            "MSE Loss is: 0.02113659679889679, h Loss is: 0.116204172372818, L1 loss: 1.452469825744629, Total Loss is: 0.13734076917171478\n",
            "MSE Loss is: 0.01689213141798973, h Loss is: 0.11724074184894562, L1 loss: 1.4529352188110352, Total Loss is: 0.13413287699222565\n",
            "MSE Loss is: 0.017348000779747963, h Loss is: 0.11817983537912369, L1 loss: 1.4533947706222534, Total Loss is: 0.1355278342962265\n",
            "New h_val is : tf.Tensor(0.07262182, shape=(), dtype=float32)\n",
            "Epoch: {} 19\n",
            "MSE Loss is: 0.01842183619737625, h Loss is: 0.14980550110340118, L1 loss: 1.4538015127182007, Total Loss is: 0.16822734475135803\n",
            "MSE Loss is: 0.01856314390897751, h Loss is: 0.15101340413093567, L1 loss: 1.4542769193649292, Total Loss is: 0.16957655549049377\n",
            "MSE Loss is: 0.018090486526489258, h Loss is: 0.15234751999378204, L1 loss: 1.4548346996307373, Total Loss is: 0.1704380065202713\n",
            "MSE Loss is: 0.01695062220096588, h Loss is: 0.15381594002246857, L1 loss: 1.45546555519104, Total Loss is: 0.17076656222343445\n",
            "MSE Loss is: 0.014384446665644646, h Loss is: 0.1551845222711563, L1 loss: 1.4559730291366577, Total Loss is: 0.1695689707994461\n",
            "MSE Loss is: 0.016533738002181053, h Loss is: 0.15639834105968475, L1 loss: 1.456379771232605, Total Loss is: 0.17293207347393036\n",
            "MSE Loss is: 0.01647956296801567, h Loss is: 0.15754619240760803, L1 loss: 1.456809401512146, Total Loss is: 0.174025759100914\n",
            "MSE Loss is: 0.01587543450295925, h Loss is: 0.15869763493537903, L1 loss: 1.457200050354004, Total Loss is: 0.17457306385040283\n",
            "MSE Loss is: 0.016251903027296066, h Loss is: 0.15981988608837128, L1 loss: 1.4575064182281494, Total Loss is: 0.17607179284095764\n",
            "MSE Loss is: 0.01663435809314251, h Loss is: 0.1610528528690338, L1 loss: 1.4579681158065796, Total Loss is: 0.17768721282482147\n",
            "MSE Loss is: 0.014386208727955818, h Loss is: 0.16236189007759094, L1 loss: 1.45844566822052, Total Loss is: 0.1767480969429016\n",
            "MSE Loss is: 0.01549582276493311, h Loss is: 0.16372540593147278, L1 loss: 1.4590214490890503, Total Loss is: 0.1792212277650833\n",
            "MSE Loss is: 0.016268253326416016, h Loss is: 0.16517873108386993, L1 loss: 1.459702491760254, Total Loss is: 0.18144698441028595\n",
            "MSE Loss is: 0.01572917215526104, h Loss is: 0.1665341854095459, L1 loss: 1.4603878259658813, Total Loss is: 0.1822633594274521\n",
            "MSE Loss is: 0.02085692621767521, h Loss is: 0.16789154708385468, L1 loss: 1.4610060453414917, Total Loss is: 0.18874847888946533\n",
            "MSE Loss is: 0.02041274681687355, h Loss is: 0.16935011744499207, L1 loss: 1.4616020917892456, Total Loss is: 0.18976286053657532\n",
            "MSE Loss is: 0.020921168848872185, h Loss is: 0.17069488763809204, L1 loss: 1.4621071815490723, Total Loss is: 0.19161605834960938\n",
            "MSE Loss is: 0.01671101152896881, h Loss is: 0.17218206822872162, L1 loss: 1.4625953435897827, Total Loss is: 0.18889307975769043\n",
            "MSE Loss is: 0.017156267538666725, h Loss is: 0.17353078722953796, L1 loss: 1.4630807638168335, Total Loss is: 0.19068706035614014\n",
            "New h_val is : tf.Tensor(0.08357954, shape=(), dtype=float32)\n",
            "Epoch: {} 20\n",
            "MSE Loss is: 0.018249623477458954, h Loss is: 0.21958844363689423, L1 loss: 1.4635363817214966, Total Loss is: 0.23783805966377258\n",
            "MSE Loss is: 0.018366321921348572, h Loss is: 0.22131042182445526, L1 loss: 1.464067816734314, Total Loss is: 0.23967674374580383\n",
            "MSE Loss is: 0.017839165404438972, h Loss is: 0.22322490811347961, L1 loss: 1.464675784111023, Total Loss is: 0.24106407165527344\n",
            "MSE Loss is: 0.016762498766183853, h Loss is: 0.2253299206495285, L1 loss: 1.465469241142273, Total Loss is: 0.24209241569042206\n",
            "MSE Loss is: 0.014210060238838196, h Loss is: 0.22729013860225677, L1 loss: 1.4661636352539062, Total Loss is: 0.24150019884109497\n",
            "MSE Loss is: 0.016375817358493805, h Loss is: 0.22903013229370117, L1 loss: 1.466799020767212, Total Loss is: 0.24540594220161438\n",
            "MSE Loss is: 0.01628955453634262, h Loss is: 0.2306835800409317, L1 loss: 1.4674230813980103, Total Loss is: 0.24697312712669373\n",
            "MSE Loss is: 0.015734491869807243, h Loss is: 0.23232926428318024, L1 loss: 1.4680217504501343, Total Loss is: 0.24806375801563263\n",
            "MSE Loss is: 0.01604599878191948, h Loss is: 0.233936607837677, L1 loss: 1.4685410261154175, Total Loss is: 0.24998261034488678\n",
            "MSE Loss is: 0.01648685522377491, h Loss is: 0.23571282625198364, L1 loss: 1.46921968460083, Total Loss is: 0.2521996796131134\n",
            "MSE Loss is: 0.014248263090848923, h Loss is: 0.2375958263874054, L1 loss: 1.4699394702911377, Total Loss is: 0.2518440783023834\n",
            "MSE Loss is: 0.01530155073851347, h Loss is: 0.23956650495529175, L1 loss: 1.4707183837890625, Total Loss is: 0.2548680603504181\n",
            "MSE Loss is: 0.016113724559545517, h Loss is: 0.2416643351316452, L1 loss: 1.4714752435684204, Total Loss is: 0.2577780485153198\n",
            "MSE Loss is: 0.015630153939127922, h Loss is: 0.24362395703792572, L1 loss: 1.4722533226013184, Total Loss is: 0.2592540979385376\n",
            "MSE Loss is: 0.020662769675254822, h Loss is: 0.24557086825370789, L1 loss: 1.4729318618774414, Total Loss is: 0.2662336230278015\n",
            "MSE Loss is: 0.020242102444171906, h Loss is: 0.24766364693641663, L1 loss: 1.473598837852478, Total Loss is: 0.26790574193000793\n",
            "MSE Loss is: 0.020700648427009583, h Loss is: 0.24958239495754242, L1 loss: 1.474234700202942, Total Loss is: 0.270283043384552\n",
            "MSE Loss is: 0.01652594283223152, h Loss is: 0.25170785188674927, L1 loss: 1.4748542308807373, Total Loss is: 0.2682338058948517\n",
            "MSE Loss is: 0.01696254312992096, h Loss is: 0.2536250054836273, L1 loss: 1.4755322933197021, Total Loss is: 0.2705875635147095\n",
            "New h_val is : tf.Tensor(0.09592724, shape=(), dtype=float32)\n",
            "Epoch: {} 21\n",
            "MSE Loss is: 0.01807323843240738, h Loss is: 0.32032495737075806, L1 loss: 1.4761509895324707, Total Loss is: 0.33839818835258484\n",
            "MSE Loss is: 0.018165454268455505, h Loss is: 0.322762131690979, L1 loss: 1.4768544435501099, Total Loss is: 0.3409276008605957\n",
            "MSE Loss is: 0.017583481967449188, h Loss is: 0.3254808187484741, L1 loss: 1.4775631427764893, Total Loss is: 0.3430643081665039\n",
            "MSE Loss is: 0.016572052612900734, h Loss is: 0.32847511768341064, L1 loss: 1.4783562421798706, Total Loss is: 0.3450471758842468\n",
            "MSE Loss is: 0.014032168313860893, h Loss is: 0.33125951886177063, L1 loss: 1.4790750741958618, Total Loss is: 0.3452916741371155\n",
            "MSE Loss is: 0.01621546410024166, h Loss is: 0.33373814821243286, L1 loss: 1.4797337055206299, Total Loss is: 0.34995362162590027\n",
            "MSE Loss is: 0.016096536070108414, h Loss is: 0.33609479665756226, L1 loss: 1.480384349822998, Total Loss is: 0.35219132900238037\n",
            "MSE Loss is: 0.01559219416230917, h Loss is: 0.33842775225639343, L1 loss: 1.4810377359390259, Total Loss is: 0.3540199398994446\n",
            "MSE Loss is: 0.015836307778954506, h Loss is: 0.34071218967437744, L1 loss: 1.4815905094146729, Total Loss is: 0.3565484881401062\n",
            "MSE Loss is: 0.01633656769990921, h Loss is: 0.3432501256465912, L1 loss: 1.4823102951049805, Total Loss is: 0.3595866858959198\n",
            "MSE Loss is: 0.014108158648014069, h Loss is: 0.3459416329860687, L1 loss: 1.4830025434494019, Total Loss is: 0.3600497841835022\n",
            "MSE Loss is: 0.015103899873793125, h Loss is: 0.3487642705440521, L1 loss: 1.4837381839752197, Total Loss is: 0.36386817693710327\n",
            "MSE Loss is: 0.015957169234752655, h Loss is: 0.351766437292099, L1 loss: 1.4844509363174438, Total Loss is: 0.36772361397743225\n",
            "MSE Loss is: 0.015530150383710861, h Loss is: 0.3545811176300049, L1 loss: 1.4851865768432617, Total Loss is: 0.37011125683784485\n",
            "MSE Loss is: 0.020466472953557968, h Loss is: 0.3573533296585083, L1 loss: 1.4858193397521973, Total Loss is: 0.37781980633735657\n",
            "MSE Loss is: 0.02006952092051506, h Loss is: 0.36032170057296753, L1 loss: 1.4864376783370972, Total Loss is: 0.3803912103176117\n",
            "MSE Loss is: 0.020475726574659348, h Loss is: 0.3630427420139313, L1 loss: 1.4870235919952393, Total Loss is: 0.3835184574127197\n",
            "MSE Loss is: 0.01633792370557785, h Loss is: 0.366044282913208, L1 loss: 1.4875924587249756, Total Loss is: 0.38238221406936646\n",
            "MSE Loss is: 0.016768135130405426, h Loss is: 0.36874598264694214, L1 loss: 1.4882210493087769, Total Loss is: 0.38551411032676697\n",
            "New h_val is : tf.Tensor(0.1097517, shape=(), dtype=float32)\n",
            "Epoch: {} 22\n",
            "MSE Loss is: 0.017893249168992043, h Loss is: 0.46472445130348206, L1 loss: 1.4887914657592773, Total Loss is: 0.48261770606040955\n",
            "MSE Loss is: 0.01796148531138897, h Loss is: 0.46813833713531494, L1 loss: 1.4894490242004395, Total Loss is: 0.48609980940818787\n",
            "MSE Loss is: 0.017324883490800858, h Loss is: 0.47196900844573975, L1 loss: 1.4901100397109985, Total Loss is: 0.4892939031124115\n",
            "MSE Loss is: 0.01638060435652733, h Loss is: 0.47618037462234497, L1 loss: 1.4908546209335327, Total Loss is: 0.4925609827041626\n",
            "MSE Loss is: 0.013852013275027275, h Loss is: 0.4800950288772583, L1 loss: 1.4915236234664917, Total Loss is: 0.49394702911376953\n",
            "MSE Loss is: 0.01605355739593506, h Loss is: 0.48358702659606934, L1 loss: 1.492133378982544, Total Loss is: 0.4996405839920044\n",
            "MSE Loss is: 0.015901653096079826, h Loss is: 0.48691585659980774, L1 loss: 1.4927321672439575, Total Loss is: 0.5028175115585327\n",
            "MSE Loss is: 0.01544949784874916, h Loss is: 0.49019259214401245, L1 loss: 1.493332028388977, Total Loss is: 0.5056421160697937\n",
            "MSE Loss is: 0.01562394481152296, h Loss is: 0.49340811371803284, L1 loss: 1.4938279390335083, Total Loss is: 0.5090320706367493\n",
            "MSE Loss is: 0.016184218227863312, h Loss is: 0.49700093269348145, L1 loss: 1.4944967031478882, Total Loss is: 0.5131851434707642\n",
            "MSE Loss is: 0.013966758735477924, h Loss is: 0.5008132457733154, L1 loss: 1.4951374530792236, Total Loss is: 0.5147799849510193\n",
            "MSE Loss is: 0.014904259704053402, h Loss is: 0.5048167109489441, L1 loss: 1.4958239793777466, Total Loss is: 0.5197209715843201\n",
            "MSE Loss is: 0.015799593180418015, h Loss is: 0.5090817213058472, L1 loss: 1.4964865446090698, Total Loss is: 0.5248813033103943\n",
            "MSE Loss is: 0.015429778024554253, h Loss is: 0.5130895376205444, L1 loss: 1.4971736669540405, Total Loss is: 0.528519332408905\n",
            "MSE Loss is: 0.02026928961277008, h Loss is: 0.5169966816902161, L1 loss: 1.4977540969848633, Total Loss is: 0.537265956401825\n",
            "MSE Loss is: 0.019895851612091064, h Loss is: 0.5211707353591919, L1 loss: 1.4983174800872803, Total Loss is: 0.541066586971283\n",
            "MSE Loss is: 0.02024747058749199, h Loss is: 0.5249866843223572, L1 loss: 1.4988471269607544, Total Loss is: 0.5452341437339783\n",
            "MSE Loss is: 0.016148293390870094, h Loss is: 0.5291852951049805, L1 loss: 1.4993587732315063, Total Loss is: 0.5453335642814636\n",
            "MSE Loss is: 0.01657470501959324, h Loss is: 0.5329457521438599, L1 loss: 1.4999314546585083, Total Loss is: 0.5495204329490662\n",
            "New h_val is : tf.Tensor(0.12511921, shape=(), dtype=float32)\n",
            "Epoch: {} 23\n",
            "MSE Loss is: 0.017710525542497635, h Loss is: 0.670054018497467, L1 loss: 1.5004476308822632, Total Loss is: 0.6877645254135132\n",
            "MSE Loss is: 0.01775568723678589, h Loss is: 0.674774169921875, L1 loss: 1.5010532140731812, Total Loss is: 0.6925298571586609\n",
            "MSE Loss is: 0.0170652586966753, h Loss is: 0.680102527141571, L1 loss: 1.5016601085662842, Total Loss is: 0.6971678137779236\n",
            "MSE Loss is: 0.01618981547653675, h Loss is: 0.6859712600708008, L1 loss: 1.5023499727249146, Total Loss is: 0.7021610736846924\n",
            "MSE Loss is: 0.01367112249135971, h Loss is: 0.6914092302322388, L1 loss: 1.5029628276824951, Total Loss is: 0.7050803303718567\n",
            "MSE Loss is: 0.015891244634985924, h Loss is: 0.696282684803009, L1 loss: 1.503517508506775, Total Loss is: 0.7121739387512207\n",
            "MSE Loss is: 0.015706339851021767, h Loss is: 0.7009276747703552, L1 loss: 1.5040582418441772, Total Loss is: 0.7166340351104736\n",
            "MSE Loss is: 0.015307572670280933, h Loss is: 0.7054874897003174, L1 loss: 1.5045982599258423, Total Loss is: 0.7207950353622437\n",
            "MSE Loss is: 0.015410390682518482, h Loss is: 0.7099617719650269, L1 loss: 1.5050305128097534, Total Loss is: 0.7253721356391907\n",
            "MSE Loss is: 0.01603074185550213, h Loss is: 0.7150033116340637, L1 loss: 1.5056424140930176, Total Loss is: 0.7310340404510498\n",
            "MSE Loss is: 0.013825129717588425, h Loss is: 0.7203366756439209, L1 loss: 1.5062254667282104, Total Loss is: 0.7341617941856384\n",
            "MSE Loss is: 0.014704320579767227, h Loss is: 0.7259714603424072, L1 loss: 1.5068563222885132, Total Loss is: 0.7406758069992065\n",
            "MSE Loss is: 0.015642229467630386, h Loss is: 0.7319626808166504, L1 loss: 1.5074623823165894, Total Loss is: 0.7476049065589905\n",
            "MSE Loss is: 0.015329781919717789, h Loss is: 0.737606942653656, L1 loss: 1.5080944299697876, Total Loss is: 0.7529367208480835\n",
            "MSE Loss is: 0.020072786137461662, h Loss is: 0.7430676817893982, L1 loss: 1.50861656665802, Total Loss is: 0.7631404399871826\n",
            "MSE Loss is: 0.0197222251445055, h Loss is: 0.7488659024238586, L1 loss: 1.5091184377670288, Total Loss is: 0.768588125705719\n",
            "MSE Loss is: 0.020017266273498535, h Loss is: 0.7541524171829224, L1 loss: 1.5095851421356201, Total Loss is: 0.7741696834564209\n",
            "MSE Loss is: 0.015958668664097786, h Loss is: 0.7599509954452515, L1 loss: 1.5100327730178833, Total Loss is: 0.7759096622467041\n",
            "MSE Loss is: 0.016384195536375046, h Loss is: 0.7651164531707764, L1 loss: 1.5105427503585815, Total Loss is: 0.7815006375312805\n",
            "New h_val is : tf.Tensor(0.14205837, shape=(), dtype=float32)\n",
            "Epoch: {} 24\n",
            "MSE Loss is: 0.01752617210149765, h Loss is: 0.9593630433082581, L1 loss: 1.510998249053955, Total Loss is: 0.9768891930580139\n",
            "MSE Loss is: 0.017549589276313782, h Loss is: 0.9658073782920837, L1 loss: 1.5115455389022827, Total Loss is: 0.9833569526672363\n",
            "MSE Loss is: 0.016806848347187042, h Loss is: 0.9731312394142151, L1 loss: 1.5120924711227417, Total Loss is: 0.9899380803108215\n",
            "MSE Loss is: 0.016001591458916664, h Loss is: 0.9812067747116089, L1 loss: 1.5127205848693848, Total Loss is: 0.9972083568572998\n",
            "MSE Loss is: 0.013491231948137283, h Loss is: 0.9886801242828369, L1 loss: 1.5132712125778198, Total Loss is: 1.0021713972091675\n",
            "MSE Loss is: 0.015729907900094986, h Loss is: 0.9953858256340027, L1 loss: 1.5137650966644287, Total Loss is: 1.0111157894134521\n",
            "MSE Loss is: 0.015512252226471901, h Loss is: 1.001793622970581, L1 loss: 1.514241337776184, Total Loss is: 1.017305850982666\n",
            "MSE Loss is: 0.015167748555541039, h Loss is: 1.0080516338348389, L1 loss: 1.514715552330017, Total Loss is: 1.023219347000122\n",
            "MSE Loss is: 0.015197431668639183, h Loss is: 1.0142128467559814, L1 loss: 1.5150775909423828, Total Loss is: 1.0294102430343628\n",
            "MSE Loss is: 0.015877263620495796, h Loss is: 1.0211955308914185, L1 loss: 1.515626072883606, Total Loss is: 1.037072777748108\n",
            "MSE Loss is: 0.013684483245015144, h Loss is: 1.028588891029358, L1 loss: 1.51614511013031, Total Loss is: 1.0422734022140503\n",
            "MSE Loss is: 0.014505992643535137, h Loss is: 1.0364265441894531, L1 loss: 1.5167919397354126, Total Loss is: 1.05093252658844\n",
            "MSE Loss is: 0.015486440621316433, h Loss is: 1.0447601079940796, L1 loss: 1.517431616783142, Total Loss is: 1.0602465867996216\n",
            "MSE Loss is: 0.015230974182486534, h Loss is: 1.052628755569458, L1 loss: 1.518060564994812, Total Loss is: 1.0678597688674927\n",
            "MSE Loss is: 0.019878758117556572, h Loss is: 1.060145378112793, L1 loss: 1.5185915231704712, Total Loss is: 1.0800241231918335\n",
            "MSE Loss is: 0.019549958407878876, h Loss is: 1.0681085586547852, L1 loss: 1.519088864326477, Total Loss is: 1.0876585245132446\n",
            "MSE Loss is: 0.019786745309829712, h Loss is: 1.075331211090088, L1 loss: 1.5195266008377075, Total Loss is: 1.0951179265975952\n",
            "MSE Loss is: 0.01577085256576538, h Loss is: 1.0832308530807495, L1 loss: 1.5199260711669922, Total Loss is: 1.0990016460418701\n",
            "MSE Loss is: 0.016198735684156418, h Loss is: 1.0902222394943237, L1 loss: 1.5204087495803833, Total Loss is: 1.1064209938049316\n",
            "New h_val is : tf.Tensor(0.16055632, shape=(), dtype=float32)\n",
            "Epoch: {} 25\n",
            "MSE Loss is: 0.017341509461402893, h Loss is: 1.3628835678100586, L1 loss: 1.520835280418396, Total Loss is: 1.3802250623703003\n",
            "MSE Loss is: 0.017344895750284195, h Loss is: 1.3715513944625854, L1 loss: 1.5213602781295776, Total Loss is: 1.3888963460922241\n",
            "MSE Loss is: 0.01655212976038456, h Loss is: 1.3814656734466553, L1 loss: 1.5218597650527954, Total Loss is: 1.3980177640914917\n",
            "MSE Loss is: 0.015817979350686073, h Loss is: 1.3924391269683838, L1 loss: 1.522477149963379, Total Loss is: 1.4082571268081665\n",
            "MSE Loss is: 0.013314194977283478, h Loss is: 1.4025638103485107, L1 loss: 1.5231398344039917, Total Loss is: 1.4158780574798584\n",
            "MSE Loss is: 0.015571078285574913, h Loss is: 1.4116714000701904, L1 loss: 1.5237795114517212, Total Loss is: 1.4272425174713135\n",
            "MSE Loss is: 0.015321162529289722, h Loss is: 1.4203964471817017, L1 loss: 1.5243473052978516, Total Loss is: 1.4357175827026367\n",
            "MSE Loss is: 0.015031427145004272, h Loss is: 1.4288758039474487, L1 loss: 1.524945616722107, Total Loss is: 1.4439072608947754\n",
            "MSE Loss is: 0.014987057074904442, h Loss is: 1.437233805656433, L1 loss: 1.525464415550232, Total Loss is: 1.4522209167480469\n",
            "MSE Loss is: 0.015725011005997658, h Loss is: 1.446797251701355, L1 loss: 1.526142954826355, Total Loss is: 1.462522268295288\n",
            "MSE Loss is: 0.01354611199349165, h Loss is: 1.456925868988037, L1 loss: 1.5267695188522339, Total Loss is: 1.470471978187561\n",
            "MSE Loss is: 0.014311311766505241, h Loss is: 1.467702031135559, L1 loss: 1.527416706085205, Total Loss is: 1.4820133447647095\n",
            "MSE Loss is: 0.015333645045757294, h Loss is: 1.4791460037231445, L1 loss: 1.528041124343872, Total Loss is: 1.4944796562194824\n",
            "MSE Loss is: 0.015134181827306747, h Loss is: 1.489971399307251, L1 loss: 1.528671145439148, Total Loss is: 1.5051056146621704\n",
            "MSE Loss is: 0.01968911662697792, h Loss is: 1.5002073049545288, L1 loss: 1.5291540622711182, Total Loss is: 1.519896388053894\n",
            "MSE Loss is: 0.019380494952201843, h Loss is: 1.510977029800415, L1 loss: 1.529614806175232, Total Loss is: 1.5303574800491333\n",
            "MSE Loss is: 0.019557680934667587, h Loss is: 1.5206869840621948, L1 loss: 1.5300546884536743, Total Loss is: 1.540244698524475\n",
            "MSE Loss is: 0.015586734749376774, h Loss is: 1.531273365020752, L1 loss: 1.5304691791534424, Total Loss is: 1.5468600988388062\n",
            "MSE Loss is: 0.01602049358189106, h Loss is: 1.5405761003494263, L1 loss: 1.5310333967208862, Total Loss is: 1.5565966367721558\n",
            "New h_val is : tf.Tensor(0.18054914, shape=(), dtype=float32)\n",
            "Epoch: {} 26\n",
            "MSE Loss is: 0.017157966271042824, h Loss is: 1.919400930404663, L1 loss: 1.5315254926681519, Total Loss is: 1.9365588426589966\n",
            "MSE Loss is: 0.017143409699201584, h Loss is: 1.9308706521987915, L1 loss: 1.5320994853973389, Total Loss is: 1.9480140209197998\n",
            "MSE Loss is: 0.016303662210702896, h Loss is: 1.9440933465957642, L1 loss: 1.5326385498046875, Total Loss is: 1.9603970050811768\n",
            "MSE Loss is: 0.015641022473573685, h Loss is: 1.95878005027771, L1 loss: 1.5332831144332886, Total Loss is: 1.9744210243225098\n",
            "MSE Loss is: 0.013141868636012077, h Loss is: 1.9723047018051147, L1 loss: 1.5338743925094604, Total Loss is: 1.985446572303772\n",
            "MSE Loss is: 0.015416359528899193, h Loss is: 1.9844967126846313, L1 loss: 1.5344427824020386, Total Loss is: 1.9999130964279175\n",
            "MSE Loss is: 0.015134829096496105, h Loss is: 1.9961990118026733, L1 loss: 1.5349327325820923, Total Loss is: 2.01133394241333\n",
            "MSE Loss is: 0.01489998959004879, h Loss is: 2.0075440406799316, L1 loss: 1.5354512929916382, Total Loss is: 2.022444009780884\n",
            "MSE Loss is: 0.014781346544623375, h Loss is: 2.018742799758911, L1 loss: 1.5358864068984985, Total Loss is: 2.0335240364074707\n",
            "MSE Loss is: 0.015575244091451168, h Loss is: 2.0316672325134277, L1 loss: 1.536483883857727, Total Loss is: 2.0472424030303955\n",
            "MSE Loss is: 0.013411298394203186, h Loss is: 2.045348644256592, L1 loss: 1.5370279550552368, Total Loss is: 2.058759927749634\n",
            "MSE Loss is: 0.01412229798734188, h Loss is: 2.059968948364258, L1 loss: 1.5375924110412598, Total Loss is: 2.0740911960601807\n",
            "MSE Loss is: 0.015185191296041012, h Loss is: 2.075497627258301, L1 loss: 1.5381314754486084, Total Loss is: 2.0906827449798584\n",
            "MSE Loss is: 0.01504018809646368, h Loss is: 2.09018611907959, L1 loss: 1.5386768579483032, Total Loss is: 2.1052262783050537\n",
            "MSE Loss is: 0.019505750387907028, h Loss is: 2.103902578353882, L1 loss: 1.5390708446502686, Total Loss is: 2.123408317565918\n",
            "MSE Loss is: 0.019215261563658714, h Loss is: 2.1182467937469482, L1 loss: 1.5394400358200073, Total Loss is: 2.1374621391296387\n",
            "MSE Loss is: 0.019331883639097214, h Loss is: 2.131063938140869, L1 loss: 1.5397889614105225, Total Loss is: 2.1503958702087402\n",
            "MSE Loss is: 0.01540814246982336, h Loss is: 2.1450157165527344, L1 loss: 1.5401129722595215, Total Loss is: 2.160423755645752\n",
            "MSE Loss is: 0.01585155725479126, h Loss is: 2.157137155532837, L1 loss: 1.540594220161438, Total Loss is: 2.1729886531829834\n",
            "New h_val is : tf.Tensor(0.20191622, shape=(), dtype=float32)\n",
            "Epoch: {} 27\n",
            "MSE Loss is: 0.016976989805698395, h Loss is: 2.677638053894043, L1 loss: 1.5410064458847046, Total Loss is: 2.694615125656128\n",
            "MSE Loss is: 0.016946911811828613, h Loss is: 2.6925079822540283, L1 loss: 1.54150390625, Total Loss is: 2.7094550132751465\n",
            "MSE Loss is: 0.016063887625932693, h Loss is: 2.709872245788574, L1 loss: 1.5419658422470093, Total Loss is: 2.7259361743927\n",
            "MSE Loss is: 0.015472612343728542, h Loss is: 2.7292394638061523, L1 loss: 1.5425333976745605, Total Loss is: 2.7447121143341064\n",
            "MSE Loss is: 0.012975990772247314, h Loss is: 2.747034788131714, L1 loss: 1.5430468320846558, Total Loss is: 2.7600107192993164\n",
            "MSE Loss is: 0.01526731438934803, h Loss is: 2.7631213665008545, L1 loss: 1.5435384511947632, Total Loss is: 2.778388738632202\n",
            "MSE Loss is: 0.014954876154661179, h Loss is: 2.778597831726074, L1 loss: 1.543944001197815, Total Loss is: 2.7935526371002197\n",
            "MSE Loss is: 0.01477471087127924, h Loss is: 2.793545722961426, L1 loss: 1.5443753004074097, Total Loss is: 2.8083205223083496\n",
            "MSE Loss is: 0.014582322910428047, h Loss is: 2.80832576751709, L1 loss: 1.5447187423706055, Total Loss is: 2.8229081630706787\n",
            "MSE Loss is: 0.015429167076945305, h Loss is: 2.8255603313446045, L1 loss: 1.5452276468276978, Total Loss is: 2.840989589691162\n",
            "MSE Loss is: 0.013281228952109814, h Loss is: 2.8438143730163574, L1 loss: 1.5456807613372803, Total Loss is: 2.857095718383789\n",
            "MSE Loss is: 0.01394084095954895, h Loss is: 2.863370180130005, L1 loss: 1.546154260635376, Total Loss is: 2.8773109912872314\n",
            "MSE Loss is: 0.015042242594063282, h Loss is: 2.884133815765381, L1 loss: 1.5465998649597168, Total Loss is: 2.8991761207580566\n",
            "MSE Loss is: 0.014949675649404526, h Loss is: 2.903782367706299, L1 loss: 1.5470529794692993, Total Loss is: 2.918731927871704\n",
            "MSE Loss is: 0.01933041214942932, h Loss is: 2.9218711853027344, L1 loss: 1.5473512411117554, Total Loss is: 2.941201686859131\n",
            "MSE Loss is: 0.019055582582950592, h Loss is: 2.940629720687866, L1 loss: 1.5476220846176147, Total Loss is: 2.9596853256225586\n",
            "MSE Loss is: 0.019111059606075287, h Loss is: 2.9572274684906006, L1 loss: 1.5479484796524048, Total Loss is: 2.9763386249542236\n",
            "MSE Loss is: 0.01523668970912695, h Loss is: 2.975222587585449, L1 loss: 1.5482910871505737, Total Loss is: 2.9904592037200928\n",
            "MSE Loss is: 0.015693776309490204, h Loss is: 2.9907004833221436, L1 loss: 1.5487521886825562, Total Loss is: 3.006394147872925\n",
            "New h_val is : tf.Tensor(0.22448015, shape=(), dtype=float32)\n",
            "Epoch: {} 28\n",
            "MSE Loss is: 0.016799937933683395, h Loss is: 3.6973483562469482, L1 loss: 1.5491422414779663, Total Loss is: 3.7141482830047607\n",
            "MSE Loss is: 0.0167570561170578, h Loss is: 3.71626353263855, L1 loss: 1.5496127605438232, Total Loss is: 3.733020544052124\n",
            "MSE Loss is: 0.015834946185350418, h Loss is: 3.7386653423309326, L1 loss: 1.5500612258911133, Total Loss is: 3.754500389099121\n",
            "MSE Loss is: 0.015314333140850067, h Loss is: 3.763833999633789, L1 loss: 1.5506280660629272, Total Loss is: 3.7791483402252197\n",
            "MSE Loss is: 0.012818077579140663, h Loss is: 3.7869062423706055, L1 loss: 1.5511374473571777, Total Loss is: 3.7997243404388428\n",
            "MSE Loss is: 0.015125353820621967, h Loss is: 3.807807445526123, L1 loss: 1.5515912771224976, Total Loss is: 3.822932720184326\n",
            "MSE Loss is: 0.014782693237066269, h Loss is: 3.8279776573181152, L1 loss: 1.5519951581954956, Total Loss is: 3.8427603244781494\n",
            "MSE Loss is: 0.014656664803624153, h Loss is: 3.8474063873291016, L1 loss: 1.5524286031723022, Total Loss is: 3.86206316947937\n",
            "MSE Loss is: 0.0143918227404356, h Loss is: 3.8666348457336426, L1 loss: 1.5527944564819336, Total Loss is: 3.8810267448425293\n",
            "MSE Loss is: 0.015287830494344234, h Loss is: 3.889267921447754, L1 loss: 1.553314447402954, Total Loss is: 3.9045557975769043\n",
            "MSE Loss is: 0.013156900182366371, h Loss is: 3.913259983062744, L1 loss: 1.5537723302841187, Total Loss is: 3.9264168739318848\n",
            "MSE Loss is: 0.013768557459115982, h Loss is: 3.939072847366333, L1 loss: 1.5542668104171753, Total Loss is: 3.9528415203094482\n",
            "MSE Loss is: 0.01490568183362484, h Loss is: 3.966400146484375, L1 loss: 1.5547441244125366, Total Loss is: 3.9813058376312256\n",
            "MSE Loss is: 0.01486318837851286, h Loss is: 3.9922330379486084, L1 loss: 1.5552152395248413, Total Loss is: 4.007096290588379\n",
            "MSE Loss is: 0.019164590165019035, h Loss is: 4.0156474113464355, L1 loss: 1.555528998374939, Total Loss is: 4.034811973571777\n",
            "MSE Loss is: 0.018902553245425224, h Loss is: 4.039699554443359, L1 loss: 1.5558154582977295, Total Loss is: 4.058602333068848\n",
            "MSE Loss is: 0.018896736204624176, h Loss is: 4.060708999633789, L1 loss: 1.5560733079910278, Total Loss is: 4.079605579376221\n",
            "MSE Loss is: 0.01507364772260189, h Loss is: 4.0834479331970215, L1 loss: 1.5563132762908936, Total Loss is: 4.098521709442139\n",
            "MSE Loss is: 0.015548618510365486, h Loss is: 4.102736473083496, L1 loss: 1.556714653968811, Total Loss is: 4.118285179138184\n",
            "New h_val is : tf.Tensor(0.24801254, shape=(), dtype=float32)\n",
            "Epoch: {} 29\n",
            "MSE Loss is: 0.016627971082925797, h Loss is: 5.05007791519165, L1 loss: 1.557032585144043, Total Loss is: 5.066705703735352\n",
            "MSE Loss is: 0.016575269401073456, h Loss is: 5.07365083694458, L1 loss: 1.5574681758880615, Total Loss is: 5.090226173400879\n",
            "MSE Loss is: 0.015618537552654743, h Loss is: 5.102107524871826, L1 loss: 1.5578231811523438, Total Loss is: 5.117725849151611\n",
            "MSE Loss is: 0.015167358331382275, h Loss is: 5.134337425231934, L1 loss: 1.5583851337432861, Total Loss is: 5.149504661560059\n",
            "MSE Loss is: 0.012669339776039124, h Loss is: 5.163820266723633, L1 loss: 1.5591140985488892, Total Loss is: 5.17648983001709\n",
            "MSE Loss is: 0.014991620555520058, h Loss is: 5.190621852874756, L1 loss: 1.5597929954528809, Total Loss is: 5.205613613128662\n",
            "MSE Loss is: 0.014619369059801102, h Loss is: 5.216531753540039, L1 loss: 1.560404658317566, Total Loss is: 5.231151103973389\n",
            "MSE Loss is: 0.014546658843755722, h Loss is: 5.241419792175293, L1 loss: 1.5609915256500244, Total Loss is: 5.255966663360596\n",
            "MSE Loss is: 0.014211342670023441, h Loss is: 5.26607084274292, L1 loss: 1.5615400075912476, Total Loss is: 5.280282020568848\n",
            "MSE Loss is: 0.015152045525610447, h Loss is: 5.295358180999756, L1 loss: 1.5622437000274658, Total Loss is: 5.310510158538818\n",
            "MSE Loss is: 0.013039055280387402, h Loss is: 5.326395511627197, L1 loss: 1.5628467798233032, Total Loss is: 5.339434623718262\n",
            "MSE Loss is: 0.013606715947389603, h Loss is: 5.359881401062012, L1 loss: 1.5634405612945557, Total Loss is: 5.373487949371338\n",
            "MSE Loss is: 0.014776078052818775, h Loss is: 5.395288467407227, L1 loss: 1.5639821290969849, Total Loss is: 5.410064697265625\n",
            "MSE Loss is: 0.014781107194721699, h Loss is: 5.428638458251953, L1 loss: 1.5645493268966675, Total Loss is: 5.443419456481934\n",
            "MSE Loss is: 0.01900945045053959, h Loss is: 5.458352088928223, L1 loss: 1.5648757219314575, Total Loss is: 5.477361679077148\n",
            "MSE Loss is: 0.01875697262585163, h Loss is: 5.488540172576904, L1 loss: 1.5651978254318237, Total Loss is: 5.507297039031982\n",
            "MSE Loss is: 0.01869015023112297, h Loss is: 5.51447057723999, L1 loss: 1.5656338930130005, Total Loss is: 5.53316068649292\n",
            "MSE Loss is: 0.01491982489824295, h Loss is: 5.542573928833008, L1 loss: 1.5661541223526, Total Loss is: 5.557493686676025\n",
            "MSE Loss is: 0.01541705708950758, h Loss is: 5.56604528427124, L1 loss: 1.5669454336166382, Total Loss is: 5.581462383270264\n",
            "New h_val is : tf.Tensor(0.27224445, shape=(), dtype=float32)\n",
            "Epoch: {} 30\n",
            "MSE Loss is: 0.016461975872516632, h Loss is: 6.819634437561035, L1 loss: 1.5675629377365112, Total Loss is: 6.836096286773682\n",
            "MSE Loss is: 0.016402656212449074, h Loss is: 6.8484063148498535, L1 loss: 1.5683287382125854, Total Loss is: 6.864809036254883\n",
            "MSE Loss is: 0.015415821224451065, h Loss is: 6.883967399597168, L1 loss: 1.568933367729187, Total Loss is: 6.899383068084717\n",
            "MSE Loss is: 0.015032410621643066, h Loss is: 6.924707412719727, L1 loss: 1.5696319341659546, Total Loss is: 6.93973970413208\n",
            "MSE Loss is: 0.012530657462775707, h Loss is: 6.961928367614746, L1 loss: 1.5703328847885132, Total Loss is: 6.974459171295166\n",
            "MSE Loss is: 0.014866864308714867, h Loss is: 6.995817184448242, L1 loss: 1.5709798336029053, Total Loss is: 7.010684013366699\n",
            "MSE Loss is: 0.014465677551925182, h Loss is: 7.028648376464844, L1 loss: 1.571563959121704, Total Loss is: 7.043114185333252\n",
            "MSE Loss is: 0.014445168897509575, h Loss is: 7.060092926025391, L1 loss: 1.5721668004989624, Total Loss is: 7.074538230895996\n",
            "MSE Loss is: 0.014041956514120102, h Loss is: 7.091179847717285, L1 loss: 1.572693109512329, Total Loss is: 7.105221748352051\n",
            "MSE Loss is: 0.015022368170320988, h Loss is: 7.128454208374023, L1 loss: 1.5733717679977417, Total Loss is: 7.143476486206055\n",
            "MSE Loss is: 0.01292815525084734, h Loss is: 7.167953968048096, L1 loss: 1.5739377737045288, Total Loss is: 7.180881977081299\n",
            "MSE Loss is: 0.013456183485686779, h Loss is: 7.210667610168457, L1 loss: 1.5744707584381104, Total Loss is: 7.224123954772949\n",
            "MSE Loss is: 0.014653715305030346, h Loss is: 7.255725383758545, L1 loss: 1.5749562978744507, Total Loss is: 7.270379066467285\n",
            "MSE Loss is: 0.014703640714287758, h Loss is: 7.2979278564453125, L1 loss: 1.575464129447937, Total Loss is: 7.312631607055664\n",
            "MSE Loss is: 0.01886579394340515, h Loss is: 7.334852695465088, L1 loss: 1.5757449865341187, Total Loss is: 7.353718280792236\n",
            "MSE Loss is: 0.018619293347001076, h Loss is: 7.37192440032959, L1 loss: 1.5759788751602173, Total Loss is: 7.390543460845947\n",
            "MSE Loss is: 0.018492192029953003, h Loss is: 7.403085231781006, L1 loss: 1.5763089656829834, Total Loss is: 7.421577453613281\n",
            "MSE Loss is: 0.01477554440498352, h Loss is: 7.43698787689209, L1 loss: 1.5767310857772827, Total Loss is: 7.45176362991333\n",
            "MSE Loss is: 0.015299485996365547, h Loss is: 7.464835166931152, L1 loss: 1.577435851097107, Total Loss is: 7.4801344871521\n",
            "New h_val is : tf.Tensor(0.2968831, shape=(), dtype=float32)\n",
            "Epoch: {} 31\n",
            "MSE Loss is: 0.01630255952477455, h Loss is: 9.101943016052246, L1 loss: 1.5779658555984497, Total Loss is: 9.118245124816895\n",
            "MSE Loss is: 0.016239933669567108, h Loss is: 9.136449813842773, L1 loss: 1.5786484479904175, Total Loss is: 9.152689933776855\n",
            "MSE Loss is: 0.01522745005786419, h Loss is: 9.180295944213867, L1 loss: 1.579162359237671, Total Loss is: 9.195523262023926\n",
            "MSE Loss is: 0.014909770339727402, h Loss is: 9.231245994567871, L1 loss: 1.5797653198242188, Total Loss is: 9.246155738830566\n",
            "MSE Loss is: 0.012402546592056751, h Loss is: 9.277654647827148, L1 loss: 1.5803645849227905, Total Loss is: 9.290057182312012\n",
            "MSE Loss is: 0.014751367270946503, h Loss is: 9.319991111755371, L1 loss: 1.5809030532836914, Total Loss is: 9.334742546081543\n",
            "MSE Loss is: 0.014322062954306602, h Loss is: 9.361018180847168, L1 loss: 1.5813692808151245, Total Loss is: 9.375340461730957\n",
            "MSE Loss is: 0.014352287165820599, h Loss is: 9.40011215209961, L1 loss: 1.5818506479263306, Total Loss is: 9.414463996887207\n",
            "MSE Loss is: 0.013884257525205612, h Loss is: 9.43862247467041, L1 loss: 1.582251787185669, Total Loss is: 9.452507019042969\n",
            "MSE Loss is: 0.014899112284183502, h Loss is: 9.485262870788574, L1 loss: 1.5828074216842651, Total Loss is: 9.500162124633789\n",
            "MSE Loss is: 0.01282442081719637, h Loss is: 9.534603118896484, L1 loss: 1.5832513570785522, Total Loss is: 9.5474271774292\n",
            "MSE Loss is: 0.013317462056875229, h Loss is: 9.588057518005371, L1 loss: 1.5836642980575562, Total Loss is: 9.601374626159668\n",
            "MSE Loss is: 0.014538689516484737, h Loss is: 9.64428997039795, L1 loss: 1.584032416343689, Total Loss is: 9.658828735351562\n",
            "MSE Loss is: 0.01463080570101738, h Loss is: 9.696714401245117, L1 loss: 1.584428310394287, Total Loss is: 9.711345672607422\n",
            "MSE Loss is: 0.018734034150838852, h Loss is: 9.741571426391602, L1 loss: 1.5845987796783447, Total Loss is: 9.760305404663086\n",
            "MSE Loss is: 0.01848962903022766, h Loss is: 9.7860746383667, L1 loss: 1.5847232341766357, Total Loss is: 9.804564476013184\n",
            "MSE Loss is: 0.018303364515304565, h Loss is: 9.822587966918945, L1 loss: 1.5849504470825195, Total Loss is: 9.840890884399414\n",
            "MSE Loss is: 0.01464075967669487, h Loss is: 9.862587928771973, L1 loss: 1.5852768421173096, Total Loss is: 9.877228736877441\n",
            "MSE Loss is: 0.015195691958069801, h Loss is: 9.894840240478516, L1 loss: 1.5858964920043945, Total Loss is: 9.910036087036133\n",
            "New h_val is : tf.Tensor(0.32162905, shape=(), dtype=float32)\n",
            "Epoch: {} 32\n",
            "MSE Loss is: 0.016150115057826042, h Loss is: 12.004920959472656, L1 loss: 1.5863392353057861, Total Loss is: 12.021071434020996\n",
            "MSE Loss is: 0.016087383031845093, h Loss is: 12.045626640319824, L1 loss: 1.586936354637146, Total Loss is: 12.061714172363281\n",
            "MSE Loss is: 0.015053654089570045, h Loss is: 12.099164962768555, L1 loss: 1.5873565673828125, Total Loss is: 12.114218711853027\n",
            "MSE Loss is: 0.0147993303835392, h Loss is: 12.16225814819336, L1 loss: 1.5878595113754272, Total Loss is: 12.177057266235352\n",
            "MSE Loss is: 0.012285141274333, h Loss is: 12.219484329223633, L1 loss: 1.5883511304855347, Total Loss is: 12.231769561767578\n",
            "MSE Loss is: 0.014644932001829147, h Loss is: 12.271719932556152, L1 loss: 1.5887740850448608, Total Loss is: 12.286364555358887\n",
            "MSE Loss is: 0.014188641682267189, h Loss is: 12.3222074508667, L1 loss: 1.5891156196594238, Total Loss is: 12.336396217346191\n",
            "MSE Loss is: 0.01426774077117443, h Loss is: 12.370034217834473, L1 loss: 1.5894702672958374, Total Loss is: 12.384302139282227\n",
            "MSE Loss is: 0.01373840682208538, h Loss is: 12.416802406311035, L1 loss: 1.58974289894104, Total Loss is: 12.430541038513184\n",
            "MSE Loss is: 0.014782440848648548, h Loss is: 12.47398567199707, L1 loss: 1.5901743173599243, Total Loss is: 12.488768577575684\n",
            "MSE Loss is: 0.012727893888950348, h Loss is: 12.534406661987305, L1 loss: 1.5904979705810547, Total Loss is: 12.547134399414062\n",
            "MSE Loss is: 0.013190699741244316, h Loss is: 12.600052833557129, L1 loss: 1.5907951593399048, Total Loss is: 12.613243103027344\n",
            "MSE Loss is: 0.014430958777666092, h Loss is: 12.668915748596191, L1 loss: 1.5910513401031494, Total Loss is: 12.68334674835205\n",
            "MSE Loss is: 0.014562400989234447, h Loss is: 12.73279857635498, L1 loss: 1.5913416147232056, Total Loss is: 12.747361183166504\n",
            "MSE Loss is: 0.01861417107284069, h Loss is: 12.786202430725098, L1 loss: 1.5914078950881958, Total Loss is: 12.804816246032715\n",
            "MSE Loss is: 0.018367817625403404, h Loss is: 12.838452339172363, L1 loss: 1.5914288759231567, Total Loss is: 12.856820106506348\n",
            "MSE Loss is: 0.01812378317117691, h Loss is: 12.880158424377441, L1 loss: 1.591557502746582, Total Loss is: 12.898282051086426\n",
            "MSE Loss is: 0.01451527327299118, h Loss is: 12.926443099975586, L1 loss: 1.5917905569076538, Total Loss is: 12.940958023071289\n",
            "MSE Loss is: 0.015104924328625202, h Loss is: 12.963005065917969, L1 loss: 1.5923253297805786, Total Loss is: 12.978110313415527\n",
            "New h_val is : tf.Tensor(0.34620285, shape=(), dtype=float32)\n",
            "Epoch: {} 33\n",
            "MSE Loss is: 0.01600492373108864, h Loss is: 15.648161888122559, L1 loss: 1.5926800966262817, Total Loss is: 15.664166450500488\n",
            "MSE Loss is: 0.015944812446832657, h Loss is: 15.6956205368042, L1 loss: 1.59319007396698, Total Loss is: 15.711565017700195\n",
            "MSE Loss is: 0.014894280582666397, h Loss is: 15.760361671447754, L1 loss: 1.593512773513794, Total Loss is: 15.775256156921387\n",
            "MSE Loss is: 0.014700616709887981, h Loss is: 15.837766647338867, L1 loss: 1.5939120054244995, Total Loss is: 15.85246753692627\n",
            "MSE Loss is: 0.012178183533251286, h Loss is: 15.907633781433105, L1 loss: 1.5942915678024292, Total Loss is: 15.919812202453613\n",
            "MSE Loss is: 0.014547034166753292, h Loss is: 15.971163749694824, L1 loss: 1.5945943593978882, Total Loss is: 15.985711097717285\n",
            "MSE Loss is: 0.014065203256905079, h Loss is: 16.032272338867188, L1 loss: 1.5948485136032104, Total Loss is: 16.046337127685547\n",
            "MSE Loss is: 0.014190963469445705, h Loss is: 16.089601516723633, L1 loss: 1.5951712131500244, Total Loss is: 16.103792190551758\n",
            "MSE Loss is: 0.013604214414954185, h Loss is: 16.145132064819336, L1 loss: 1.5954233407974243, Total Loss is: 16.158737182617188\n",
            "MSE Loss is: 0.014672446995973587, h Loss is: 16.213829040527344, L1 loss: 1.5958207845687866, Total Loss is: 16.22850227355957\n",
            "MSE Loss is: 0.012638484127819538, h Loss is: 16.286317825317383, L1 loss: 1.5961154699325562, Total Loss is: 16.2989559173584\n",
            "MSE Loss is: 0.013075719587504864, h Loss is: 16.365467071533203, L1 loss: 1.596398115158081, Total Loss is: 16.378541946411133\n",
            "MSE Loss is: 0.014330350793898106, h Loss is: 16.44839859008789, L1 loss: 1.5966545343399048, Total Loss is: 16.46272850036621\n",
            "MSE Loss is: 0.014498035423457623, h Loss is: 16.524911880493164, L1 loss: 1.5969555377960205, Total Loss is: 16.539409637451172\n",
            "MSE Loss is: 0.018505819141864777, h Loss is: 16.587398529052734, L1 loss: 1.5970467329025269, Total Loss is: 16.60590362548828\n",
            "MSE Loss is: 0.01825358159840107, h Loss is: 16.647615432739258, L1 loss: 1.5971057415008545, Total Loss is: 16.665868759155273\n",
            "MSE Loss is: 0.017953306436538696, h Loss is: 16.694198608398438, L1 loss: 1.5972131490707397, Total Loss is: 16.7121524810791\n",
            "MSE Loss is: 0.01439894363284111, h Loss is: 16.746753692626953, L1 loss: 1.5974292755126953, Total Loss is: 16.761152267456055\n",
            "MSE Loss is: 0.015026054345071316, h Loss is: 16.787538528442383, L1 loss: 1.597847819328308, Total Loss is: 16.80256462097168\n",
            "New h_val is : tf.Tensor(0.3703475, shape=(), dtype=float32)\n",
            "Epoch: {} 34\n",
            "MSE Loss is: 0.015867169946432114, h Loss is: 20.162683486938477, L1 loss: 1.5980857610702515, Total Loss is: 20.178550720214844\n",
            "MSE Loss is: 0.01581164449453354, h Loss is: 20.217391967773438, L1 loss: 1.5984736680984497, Total Loss is: 20.233203887939453\n",
            "MSE Loss is: 0.014748804271221161, h Loss is: 20.295007705688477, L1 loss: 1.5987108945846558, Total Loss is: 20.309757232666016\n",
            "MSE Loss is: 0.014612827450037003, h Loss is: 20.38913345336914, L1 loss: 1.5990880727767944, Total Loss is: 20.403745651245117\n",
            "MSE Loss is: 0.012081063352525234, h Loss is: 20.473407745361328, L1 loss: 1.5994446277618408, Total Loss is: 20.485488891601562\n",
            "MSE Loss is: 0.014457067474722862, h Loss is: 20.549442291259766, L1 loss: 1.5996912717819214, Total Loss is: 20.563899993896484\n",
            "MSE Loss is: 0.013951240107417107, h Loss is: 20.621973037719727, L1 loss: 1.5999178886413574, Total Loss is: 20.635923385620117\n",
            "MSE Loss is: 0.014121253043413162, h Loss is: 20.68922233581543, L1 loss: 1.6001675128936768, Total Loss is: 20.703344345092773\n",
            "MSE Loss is: 0.013481219299137592, h Loss is: 20.75360679626465, L1 loss: 1.6003636121749878, Total Loss is: 20.767087936401367\n",
            "MSE Loss is: 0.014569135382771492, h Loss is: 20.834428787231445, L1 loss: 1.6006996631622314, Total Loss is: 20.848997116088867\n",
            "MSE Loss is: 0.012555958703160286, h Loss is: 20.919910430908203, L1 loss: 1.6009422540664673, Total Loss is: 20.932466506958008\n",
            "MSE Loss is: 0.012972019612789154, h Loss is: 21.013784408569336, L1 loss: 1.601175308227539, Total Loss is: 21.026756286621094\n",
            "MSE Loss is: 0.014236528426408768, h Loss is: 21.112171173095703, L1 loss: 1.6013902425765991, Total Loss is: 21.126407623291016\n",
            "MSE Loss is: 0.014437251724302769, h Loss is: 21.202667236328125, L1 loss: 1.601619005203247, Total Loss is: 21.217103958129883\n",
            "MSE Loss is: 0.018408309668302536, h Loss is: 21.27466583251953, L1 loss: 1.6016076803207397, Total Loss is: 21.293073654174805\n",
            "MSE Loss is: 0.018146619200706482, h Loss is: 21.34308433532715, L1 loss: 1.6015619039535522, Total Loss is: 21.361230850219727\n",
            "MSE Loss is: 0.017791610211133957, h Loss is: 21.39401626586914, L1 loss: 1.6015652418136597, Total Loss is: 21.411808013916016\n",
            "MSE Loss is: 0.01429169625043869, h Loss is: 21.452795028686523, L1 loss: 1.6016815900802612, Total Loss is: 21.467086791992188\n",
            "MSE Loss is: 0.014957762323319912, h Loss is: 21.497432708740234, L1 loss: 1.6020067930221558, Total Loss is: 21.51239013671875\n",
            "New h_val is : tf.Tensor(0.39384794, shape=(), dtype=float32)\n",
            "Epoch: {} 35\n",
            "MSE Loss is: 0.0157368965446949, h Loss is: 25.690690994262695, L1 loss: 1.6021511554718018, Total Loss is: 25.70642852783203\n",
            "MSE Loss is: 0.01568709686398506, h Loss is: 25.753042221069336, L1 loss: 1.6024502515792847, Total Loss is: 25.76873016357422\n",
            "MSE Loss is: 0.0146163459867239, h Loss is: 25.84536361694336, L1 loss: 1.602594017982483, Total Loss is: 25.8599796295166\n",
            "MSE Loss is: 0.01453491672873497, h Loss is: 25.95860481262207, L1 loss: 1.6028791666030884, Total Loss is: 25.9731388092041\n",
            "MSE Loss is: 0.011992955580353737, h Loss is: 26.058881759643555, L1 loss: 1.60313880443573, Total Loss is: 26.07087516784668\n",
            "MSE Loss is: 0.014374557882547379, h Loss is: 26.148393630981445, L1 loss: 1.6032800674438477, Total Loss is: 26.16276741027832\n",
            "MSE Loss is: 0.013846001587808132, h Loss is: 26.232702255249023, L1 loss: 1.6033977270126343, Total Loss is: 26.24654769897461\n",
            "MSE Loss is: 0.014057900756597519, h Loss is: 26.309921264648438, L1 loss: 1.6035407781600952, Total Loss is: 26.323978424072266\n",
            "MSE Loss is: 0.013368725776672363, h Loss is: 26.382761001586914, L1 loss: 1.6036310195922852, Total Loss is: 26.396129608154297\n",
            "MSE Loss is: 0.014472370967268944, h Loss is: 26.476089477539062, L1 loss: 1.6038646697998047, Total Loss is: 26.490562438964844\n",
            "MSE Loss is: 0.012479932978749275, h Loss is: 26.575288772583008, L1 loss: 1.6040102243423462, Total Loss is: 26.5877685546875\n",
            "MSE Loss is: 0.012878846377134323, h Loss is: 26.68524932861328, L1 loss: 1.6041465997695923, Total Loss is: 26.69812774658203\n",
            "MSE Loss is: 0.014149026945233345, h Loss is: 26.800832748413086, L1 loss: 1.6042670011520386, Total Loss is: 26.81498146057129\n",
            "MSE Loss is: 0.014379672706127167, h Loss is: 26.90677261352539, L1 loss: 1.6044012308120728, Total Loss is: 26.921152114868164\n",
            "MSE Loss is: 0.018320832401514053, h Loss is: 26.988948822021484, L1 loss: 1.6042931079864502, Total Loss is: 27.00726890563965\n",
            "MSE Loss is: 0.018046636134386063, h Loss is: 27.06562042236328, L1 loss: 1.6041473150253296, Total Loss is: 27.083667755126953\n",
            "MSE Loss is: 0.017638321965932846, h Loss is: 27.12017250061035, L1 loss: 1.604050636291504, Total Loss is: 27.1378116607666\n",
            "MSE Loss is: 0.014193366281688213, h Loss is: 27.18484115600586, L1 loss: 1.6040714979171753, Total Loss is: 27.199033737182617\n",
            "MSE Loss is: 0.014898734167218208, h Loss is: 27.232772827148438, L1 loss: 1.6043083667755127, Total Loss is: 27.247671127319336\n",
            "New h_val is : tf.Tensor(0.41652298, shape=(), dtype=float32)\n",
            "Epoch: {} 36\n",
            "MSE Loss is: 0.01561395637691021, h Loss is: 32.3853759765625, L1 loss: 1.6043633222579956, Total Loss is: 32.4009895324707\n",
            "MSE Loss is: 0.015570437535643578, h Loss is: 32.45561599731445, L1 loss: 1.6045783758163452, Total Loss is: 32.471187591552734\n",
            "MSE Loss is: 0.014495810493826866, h Loss is: 32.564266204833984, L1 loss: 1.6046346426010132, Total Loss is: 32.57876205444336\n",
            "MSE Loss is: 0.01446574181318283, h Loss is: 32.69923782348633, L1 loss: 1.6048344373703003, Total Loss is: 32.71370315551758\n",
            "MSE Loss is: 0.01191293727606535, h Loss is: 32.81702423095703, L1 loss: 1.605002760887146, Total Loss is: 32.82893753051758\n",
            "MSE Loss is: 0.0142991803586483, h Loss is: 32.920555114746094, L1 loss: 1.6050443649291992, Total Loss is: 32.934852600097656\n",
            "MSE Loss is: 0.013748615980148315, h Loss is: 33.016693115234375, L1 loss: 1.6050589084625244, Total Loss is: 33.03044128417969\n",
            "MSE Loss is: 0.014000264927744865, h Loss is: 33.103389739990234, L1 loss: 1.6051024198532104, Total Loss is: 33.11738967895508\n",
            "MSE Loss is: 0.013265874236822128, h Loss is: 33.18403244018555, L1 loss: 1.605093002319336, Total Loss is: 33.19729995727539\n",
            "MSE Loss is: 0.01438186690211296, h Loss is: 33.2901611328125, L1 loss: 1.6052324771881104, Total Loss is: 33.304542541503906\n",
            "MSE Loss is: 0.01240992546081543, h Loss is: 33.403900146484375, L1 loss: 1.6052879095077515, Total Loss is: 33.41630935668945\n",
            "MSE Loss is: 0.012795318849384785, h Loss is: 33.531551361083984, L1 loss: 1.6053364276885986, Total Loss is: 33.54434585571289\n",
            "MSE Loss is: 0.014067355543375015, h Loss is: 33.66620635986328, L1 loss: 1.6053694486618042, Total Loss is: 33.680274963378906\n",
            "MSE Loss is: 0.014325078576803207, h Loss is: 33.789459228515625, L1 loss: 1.605416178703308, Total Loss is: 33.80378341674805\n",
            "MSE Loss is: 0.018242571502923965, h Loss is: 33.88243865966797, L1 loss: 1.6052178144454956, Total Loss is: 33.90068054199219\n",
            "MSE Loss is: 0.017953278496861458, h Loss is: 33.96738815307617, L1 loss: 1.6049779653549194, Total Loss is: 33.9853401184082\n",
            "MSE Loss is: 0.017493046820163727, h Loss is: 34.02422332763672, L1 loss: 1.6047872304916382, Total Loss is: 34.041717529296875\n",
            "MSE Loss is: 0.014103526249527931, h Loss is: 34.09416198730469, L1 loss: 1.6047182083129883, Total Loss is: 34.1082649230957\n",
            "MSE Loss is: 0.014847754500806332, h Loss is: 34.14448165893555, L1 loss: 1.6048723459243774, Total Loss is: 34.15932846069336\n",
            "New h_val is : tf.Tensor(0.4382372, shape=(), dtype=float32)\n",
            "Epoch: {} 37\n",
            "MSE Loss is: 0.015498058870434761, h Loss is: 40.411277770996094, L1 loss: 1.6048444509506226, Total Loss is: 40.42677688598633\n",
            "MSE Loss is: 0.015461152419447899, h Loss is: 40.48938751220703, L1 loss: 1.604982614517212, Total Loss is: 40.50484848022461\n",
            "MSE Loss is: 0.014386099763214588, h Loss is: 40.6160888671875, L1 loss: 1.604958415031433, Total Loss is: 40.63047409057617\n",
            "MSE Loss is: 0.014404194429516792, h Loss is: 40.7754020690918, L1 loss: 1.605080246925354, Total Loss is: 40.7898063659668\n",
            "MSE Loss is: 0.01184007152915001, h Loss is: 40.91223907470703, L1 loss: 1.6051653623580933, Total Loss is: 40.92407989501953\n",
            "MSE Loss is: 0.01423061266541481, h Loss is: 41.030067443847656, L1 loss: 1.6051177978515625, Total Loss is: 41.04429626464844\n",
            "MSE Loss is: 0.01365822646766901, h Loss is: 41.137577056884766, L1 loss: 1.6050809621810913, Total Loss is: 41.1512336730957\n",
            "MSE Loss is: 0.013947760686278343, h Loss is: 41.233192443847656, L1 loss: 1.6050726175308228, Total Loss is: 41.24713897705078\n",
            "MSE Loss is: 0.01317175105214119, h Loss is: 41.3206901550293, L1 loss: 1.6049903631210327, Total Loss is: 41.3338623046875\n",
            "MSE Loss is: 0.014297259971499443, h Loss is: 41.43985366821289, L1 loss: 1.6050246953964233, Total Loss is: 41.45415115356445\n",
            "MSE Loss is: 0.012345444411039352, h Loss is: 41.56911087036133, L1 loss: 1.6049810647964478, Total Loss is: 41.58145523071289\n",
            "MSE Loss is: 0.012720547616481781, h Loss is: 41.716339111328125, L1 loss: 1.6049559116363525, Total Loss is: 41.729061126708984\n",
            "MSE Loss is: 0.013991095125675201, h Loss is: 41.87250900268555, L1 loss: 1.6049379110336304, Total Loss is: 41.88650131225586\n",
            "MSE Loss is: 0.014273364096879959, h Loss is: 42.01494216918945, L1 loss: 1.6049190759658813, Total Loss is: 42.02921676635742\n",
            "MSE Loss is: 0.018172740936279297, h Loss is: 42.119407653808594, L1 loss: 1.6047102212905884, Total Loss is: 42.13758087158203\n",
            "MSE Loss is: 0.01786613091826439, h Loss is: 42.21232604980469, L1 loss: 1.604509711265564, Total Loss is: 42.23019027709961\n",
            "MSE Loss is: 0.017355401068925858, h Loss is: 42.26983642578125, L1 loss: 1.6043163537979126, Total Loss is: 42.287193298339844\n",
            "MSE Loss is: 0.01402154378592968, h Loss is: 42.343936920166016, L1 loss: 1.6042969226837158, Total Loss is: 42.35795974731445\n",
            "MSE Loss is: 0.014803738333284855, h Loss is: 42.3951530456543, L1 loss: 1.6044336557388306, Total Loss is: 42.40995788574219\n",
            "New h_val is : tf.Tensor(0.45888996, shape=(), dtype=float32)\n",
            "Epoch: {} 38\n",
            "MSE Loss is: 0.015388881787657738, h Loss is: 49.94489669799805, L1 loss: 1.6045233011245728, Total Loss is: 49.96028518676758\n",
            "MSE Loss is: 0.015358876436948776, h Loss is: 50.03081130981445, L1 loss: 1.6047295331954956, Total Loss is: 50.04616928100586\n",
            "MSE Loss is: 0.014286227524280548, h Loss is: 50.1774787902832, L1 loss: 1.6048341989517212, Total Loss is: 50.19176483154297\n",
            "MSE Loss is: 0.014349276199936867, h Loss is: 50.36430358886719, L1 loss: 1.6049648523330688, Total Loss is: 50.37865447998047\n",
            "MSE Loss is: 0.011773482896387577, h Loss is: 50.521568298339844, L1 loss: 1.60503351688385, Total Loss is: 50.53334045410156\n",
            "MSE Loss is: 0.014168458059430122, h Loss is: 50.65398025512695, L1 loss: 1.6050230264663696, Total Loss is: 50.668148040771484\n",
            "MSE Loss is: 0.013574083335697651, h Loss is: 50.77216720581055, L1 loss: 1.604965090751648, Total Loss is: 50.78573989868164\n",
            "MSE Loss is: 0.013899844139814377, h Loss is: 50.87565994262695, L1 loss: 1.604915976524353, Total Loss is: 50.88956069946289\n",
            "MSE Loss is: 0.013085495680570602, h Loss is: 50.968692779541016, L1 loss: 1.60476553440094, Total Loss is: 50.98177719116211\n",
            "MSE Loss is: 0.01421818882226944, h Loss is: 51.10102844238281, L1 loss: 1.6047013998031616, Total Loss is: 51.1152458190918\n",
            "MSE Loss is: 0.012286057695746422, h Loss is: 51.24702835083008, L1 loss: 1.6045572757720947, Total Loss is: 51.259315490722656\n",
            "MSE Loss is: 0.01265367865562439, h Loss is: 51.41608810424805, L1 loss: 1.6044422388076782, Total Loss is: 51.428741455078125\n",
            "MSE Loss is: 0.013919912278652191, h Loss is: 51.59639358520508, L1 loss: 1.6043905019760132, Total Loss is: 51.610313415527344\n",
            "MSE Loss is: 0.014224485494196415, h Loss is: 51.76045608520508, L1 loss: 1.6043754816055298, Total Loss is: 51.774681091308594\n",
            "MSE Loss is: 0.018110621720552444, h Loss is: 51.876949310302734, L1 loss: 1.6041717529296875, Total Loss is: 51.89506149291992\n",
            "MSE Loss is: 0.017784763127565384, h Loss is: 51.97709274291992, L1 loss: 1.604008674621582, Total Loss is: 51.994876861572266\n",
            "MSE Loss is: 0.01722501590847969, h Loss is: 52.032962799072266, L1 loss: 1.60379159450531, Total Loss is: 52.05018615722656\n",
            "MSE Loss is: 0.013946713879704475, h Loss is: 52.10942459106445, L1 loss: 1.6037333011627197, Total Loss is: 52.12337112426758\n",
            "MSE Loss is: 0.014765704981982708, h Loss is: 52.15977096557617, L1 loss: 1.6037895679473877, Total Loss is: 52.174537658691406\n",
            "New h_val is : tf.Tensor(0.47842407, shape=(), dtype=float32)\n",
            "Epoch: {} 39\n",
            "MSE Loss is: 0.015286136418581009, h Loss is: 61.17655563354492, L1 loss: 1.6038029193878174, Total Loss is: 61.19184112548828\n",
            "MSE Loss is: 0.015263288281857967, h Loss is: 61.269893646240234, L1 loss: 1.603938102722168, Total Loss is: 61.28515625\n",
            "MSE Loss is: 0.014195296913385391, h Loss is: 61.4387321472168, L1 loss: 1.6039732694625854, Total Loss is: 61.45292663574219\n",
            "MSE Loss is: 0.014300125651061535, h Loss is: 61.656551361083984, L1 loss: 1.6040347814559937, Total Loss is: 61.67085266113281\n",
            "MSE Loss is: 0.011712415143847466, h Loss is: 61.83616638183594, L1 loss: 1.6040287017822266, Total Loss is: 61.847877502441406\n",
            "MSE Loss is: 0.01411224715411663, h Loss is: 61.98309326171875, L1 loss: 1.603937029838562, Total Loss is: 61.9972038269043\n",
            "MSE Loss is: 0.013495571911334991, h Loss is: 62.11091232299805, L1 loss: 1.603795051574707, Total Loss is: 62.12440872192383\n",
            "MSE Loss is: 0.013856015168130398, h Loss is: 62.220970153808594, L1 loss: 1.6036657094955444, Total Loss is: 62.234825134277344\n",
            "MSE Loss is: 0.01300633605569601, h Loss is: 62.317901611328125, L1 loss: 1.603434443473816, Total Loss is: 62.330909729003906\n",
            "MSE Loss is: 0.01414433028548956, h Loss is: 62.46359634399414, L1 loss: 1.6032934188842773, Total Loss is: 62.47774124145508\n",
            "MSE Loss is: 0.012231394648551941, h Loss is: 62.627662658691406, L1 loss: 1.6030769348144531, Total Loss is: 62.639892578125\n",
            "MSE Loss is: 0.012593928724527359, h Loss is: 62.821311950683594, L1 loss: 1.6028903722763062, Total Loss is: 62.83390426635742\n",
            "MSE Loss is: 0.013853510841727257, h Loss is: 63.02892303466797, L1 loss: 1.6027694940567017, Total Loss is: 63.04277801513672\n",
            "MSE Loss is: 0.014178427867591381, h Loss is: 63.216957092285156, L1 loss: 1.6026840209960938, Total Loss is: 63.231136322021484\n",
            "MSE Loss is: 0.01805553212761879, h Loss is: 63.346004486083984, L1 loss: 1.6024051904678345, Total Loss is: 63.36405944824219\n",
            "MSE Loss is: 0.017708785831928253, h Loss is: 63.452266693115234, L1 loss: 1.6021636724472046, Total Loss is: 63.469974517822266\n",
            "MSE Loss is: 0.017101574689149857, h Loss is: 63.50320816040039, L1 loss: 1.6018640995025635, Total Loss is: 63.52030944824219\n",
            "MSE Loss is: 0.013878371566534042, h Loss is: 63.579734802246094, L1 loss: 1.601728081703186, Total Loss is: 63.59361267089844\n",
            "MSE Loss is: 0.014732809737324715, h Loss is: 63.62708282470703, L1 loss: 1.6017109155654907, Total Loss is: 63.641815185546875\n",
            "New h_val is : tf.Tensor(0.49681282, shape=(), dtype=float32)\n",
            "Epoch: {} 40\n",
            "MSE Loss is: 0.01518955733627081, h Loss is: 74.31121826171875, L1 loss: 1.6016558408737183, Total Loss is: 74.32640838623047\n",
            "MSE Loss is: 0.015174067579209805, h Loss is: 74.4118423461914, L1 loss: 1.6017286777496338, Total Loss is: 74.42701721191406\n",
            "MSE Loss is: 0.014112446457147598, h Loss is: 74.60574340820312, L1 loss: 1.6017025709152222, Total Loss is: 74.61985778808594\n",
            "MSE Loss is: 0.01425599679350853, h Loss is: 74.85860443115234, L1 loss: 1.6017035245895386, Total Loss is: 74.87286376953125\n",
            "MSE Loss is: 0.011656258255243301, h Loss is: 75.06249237060547, L1 loss: 1.6016308069229126, Total Loss is: 75.07415008544922\n",
            "MSE Loss is: 0.014061487279832363, h Loss is: 75.22384643554688, L1 loss: 1.601464867591858, Total Loss is: 75.23790740966797\n",
            "MSE Loss is: 0.013422178104519844, h Loss is: 75.35958862304688, L1 loss: 1.6012461185455322, Total Loss is: 75.37300872802734\n",
            "MSE Loss is: 0.013815859332680702, h Loss is: 75.474365234375, L1 loss: 1.601043939590454, Total Loss is: 75.4881820678711\n",
            "MSE Loss is: 0.012933585792779922, h Loss is: 75.5733413696289, L1 loss: 1.6007397174835205, Total Loss is: 75.58627319335938\n",
            "MSE Loss is: 0.014075400307774544, h Loss is: 75.73246765136719, L1 loss: 1.600529670715332, Total Loss is: 75.74654388427734\n",
            "MSE Loss is: 0.012181125581264496, h Loss is: 75.91645812988281, L1 loss: 1.6002492904663086, Total Loss is: 75.92864227294922\n",
            "MSE Loss is: 0.012540584430098534, h Loss is: 76.1375961303711, L1 loss: 1.600000023841858, Total Loss is: 76.15013885498047\n",
            "MSE Loss is: 0.013791628181934357, h Loss is: 76.37631225585938, L1 loss: 1.5998183488845825, Total Loss is: 76.39010620117188\n",
            "MSE Loss is: 0.014135198667645454, h Loss is: 76.59102630615234, L1 loss: 1.5996702909469604, Total Loss is: 76.60516357421875\n",
            "MSE Loss is: 0.018006879836320877, h Loss is: 76.73295593261719, L1 loss: 1.5993236303329468, Total Loss is: 76.75096130371094\n",
            "MSE Loss is: 0.017637861892580986, h Loss is: 76.84376525878906, L1 loss: 1.5990103483200073, Total Loss is: 76.86140441894531\n",
            "MSE Loss is: 0.01698479801416397, h Loss is: 76.8857192993164, L1 loss: 1.598635196685791, Total Loss is: 76.90270233154297\n",
            "MSE Loss is: 0.013815941289067268, h Loss is: 76.95942687988281, L1 loss: 1.5984280109405518, Total Loss is: 76.9732437133789\n",
            "MSE Loss is: 0.01470433920621872, h Loss is: 77.00091552734375, L1 loss: 1.5983457565307617, Total Loss is: 77.01561737060547\n",
            "New h_val is : tf.Tensor(0.5140557, shape=(), dtype=float32)\n",
            "Epoch: {} 41\n",
            "MSE Loss is: 0.015098880045115948, h Loss is: 89.57085418701172, L1 loss: 1.5982297658920288, Total Loss is: 89.58595275878906\n",
            "MSE Loss is: 0.01509089209139347, h Loss is: 89.67877197265625, L1 loss: 1.5982486009597778, Total Loss is: 89.69386291503906\n",
            "MSE Loss is: 0.014036877080798149, h Loss is: 89.90076446533203, L1 loss: 1.5981695652008057, Total Loss is: 89.91480255126953\n",
            "MSE Loss is: 0.014216259121894836, h Loss is: 90.19380950927734, L1 loss: 1.5981186628341675, Total Loss is: 90.20802307128906\n",
            "MSE Loss is: 0.011604515835642815, h Loss is: 90.42420196533203, L1 loss: 1.5979868173599243, Total Loss is: 90.43580627441406\n",
            "MSE Loss is: 0.014015723019838333, h Loss is: 90.59935760498047, L1 loss: 1.5977535247802734, Total Loss is: 90.61337280273438\n",
            "MSE Loss is: 0.013353478163480759, h Loss is: 90.74098205566406, L1 loss: 1.5974647998809814, Total Loss is: 90.75433349609375\n",
            "MSE Loss is: 0.013779042288661003, h Loss is: 90.8580322265625, L1 loss: 1.5971966981887817, Total Loss is: 90.87181091308594\n",
            "MSE Loss is: 0.012866633012890816, h Loss is: 90.95653533935547, L1 loss: 1.5968273878097534, Total Loss is: 90.96939849853516\n",
            "MSE Loss is: 0.014011133462190628, h Loss is: 91.129150390625, L1 loss: 1.5965564250946045, Total Loss is: 91.14315795898438\n",
            "MSE Loss is: 0.012134955264627934, h Loss is: 91.33512115478516, L1 loss: 1.5962212085723877, Total Loss is: 91.34725952148438\n",
            "MSE Loss is: 0.01249300129711628, h Loss is: 91.58746337890625, L1 loss: 1.5959175825119019, Total Loss is: 91.5999526977539\n",
            "MSE Loss is: 0.013734024949371815, h Loss is: 91.86141204833984, L1 loss: 1.5956833362579346, Total Loss is: 91.8751449584961\n",
            "MSE Loss is: 0.014094818383455276, h Loss is: 92.10619354248047, L1 loss: 1.5954798460006714, Total Loss is: 92.12028503417969\n",
            "MSE Loss is: 0.017964117228984833, h Loss is: 92.26117706298828, L1 loss: 1.5950860977172852, Total Loss is: 92.27914428710938\n",
            "MSE Loss is: 0.01757170632481575, h Loss is: 92.37418365478516, L1 loss: 1.5947693586349487, Total Loss is: 92.39175415039062\n",
            "MSE Loss is: 0.016874443739652634, h Loss is: 92.4019546508789, L1 loss: 1.594406008720398, Total Loss is: 92.41883087158203\n",
            "MSE Loss is: 0.01375893410295248, h Loss is: 92.46923828125, L1 loss: 1.594218134880066, Total Loss is: 92.48299407958984\n",
            "MSE Loss is: 0.014679688960313797, h Loss is: 92.50171661376953, L1 loss: 1.5942232608795166, Total Loss is: 92.51639556884766\n",
            "New h_val is : tf.Tensor(0.53017044, shape=(), dtype=float32)\n",
            "Epoch: {} 42\n",
            "MSE Loss is: 0.01501383911818266, h Loss is: 107.1951675415039, L1 loss: 1.5941693782806396, Total Loss is: 107.2101821899414\n",
            "MSE Loss is: 0.015013445168733597, h Loss is: 107.31076049804688, L1 loss: 1.5942437648773193, Total Loss is: 107.32577514648438\n",
            "MSE Loss is: 0.013967864215373993, h Loss is: 107.56501770019531, L1 loss: 1.5942054986953735, Total Loss is: 107.57898712158203\n",
            "MSE Loss is: 0.014180393889546394, h Loss is: 107.90415954589844, L1 loss: 1.5941637754440308, Total Loss is: 107.91834259033203\n",
            "MSE Loss is: 0.011556758545339108, h Loss is: 108.16341400146484, L1 loss: 1.5940189361572266, Total Loss is: 108.17497253417969\n",
            "MSE Loss is: 0.013974550180137157, h Loss is: 108.3514404296875, L1 loss: 1.593803882598877, Total Loss is: 108.36541748046875\n",
            "MSE Loss is: 0.013289106078445911, h Loss is: 108.49567413330078, L1 loss: 1.5934661626815796, Total Loss is: 108.50896453857422\n",
            "MSE Loss is: 0.013745298609137535, h Loss is: 108.61204528808594, L1 loss: 1.5931651592254639, Total Loss is: 108.62579345703125\n",
            "MSE Loss is: 0.012804941274225712, h Loss is: 108.70692443847656, L1 loss: 1.5927565097808838, Total Loss is: 108.7197265625\n",
            "MSE Loss is: 0.013951292261481285, h Loss is: 108.8932113647461, L1 loss: 1.5924748182296753, Total Loss is: 108.90716552734375\n",
            "MSE Loss is: 0.012092610821127892, h Loss is: 109.12359619140625, L1 loss: 1.5921354293823242, Total Loss is: 109.13568878173828\n",
            "MSE Loss is: 0.012450600042939186, h Loss is: 109.41211700439453, L1 loss: 1.5918364524841309, Total Loss is: 109.42456817626953\n",
            "MSE Loss is: 0.013680489733815193, h Loss is: 109.72618103027344, L1 loss: 1.591605305671692, Total Loss is: 109.73986053466797\n",
            "MSE Loss is: 0.014057298190891743, h Loss is: 110.00428009033203, L1 loss: 1.5914394855499268, Total Loss is: 110.01834106445312\n",
            "MSE Loss is: 0.017926765605807304, h Loss is: 110.17205810546875, L1 loss: 1.591048002243042, Total Loss is: 110.18998718261719\n",
            "MSE Loss is: 0.017510073259472847, h Loss is: 110.28441619873047, L1 loss: 1.5907810926437378, Total Loss is: 110.30192565917969\n",
            "MSE Loss is: 0.01677028462290764, h Loss is: 110.29193878173828, L1 loss: 1.5904321670532227, Total Loss is: 110.30870819091797\n",
            "MSE Loss is: 0.01370692066848278, h Loss is: 110.34791564941406, L1 loss: 1.5902831554412842, Total Loss is: 110.36162567138672\n",
            "MSE Loss is: 0.014658350497484207, h Loss is: 110.3680191040039, L1 loss: 1.5902669429779053, Total Loss is: 110.38267517089844\n",
            "New h_val is : tf.Tensor(0.5451832, shape=(), dtype=float32)\n",
            "Epoch: {} 43\n",
            "MSE Loss is: 0.01493417751044035, h Loss is: 127.44363403320312, L1 loss: 1.5902496576309204, Total Loss is: 127.45856475830078\n",
            "MSE Loss is: 0.014941436238586903, h Loss is: 127.5678482055664, L1 loss: 1.5903314352035522, Total Loss is: 127.5827865600586\n",
            "MSE Loss is: 0.01390477828681469, h Loss is: 127.85951232910156, L1 loss: 1.5903425216674805, Total Loss is: 127.87342071533203\n",
            "MSE Loss is: 0.014147968962788582, h Loss is: 128.25143432617188, L1 loss: 1.5903412103652954, Total Loss is: 128.2655792236328\n",
            "MSE Loss is: 0.011512616649270058, h Loss is: 128.54183959960938, L1 loss: 1.5902254581451416, Total Loss is: 128.5533447265625\n",
            "MSE Loss is: 0.013937591575086117, h Loss is: 128.74136352539062, L1 loss: 1.5900546312332153, Total Loss is: 128.7552947998047\n",
            "MSE Loss is: 0.013228744268417358, h Loss is: 128.88400268554688, L1 loss: 1.5897560119628906, Total Loss is: 128.89723205566406\n",
            "MSE Loss is: 0.013714399188756943, h Loss is: 128.99542236328125, L1 loss: 1.589520812034607, Total Loss is: 129.00914001464844\n",
            "MSE Loss is: 0.012748041190207005, h Loss is: 129.08297729492188, L1 loss: 1.5891236066818237, Total Loss is: 129.09571838378906\n",
            "MSE Loss is: 0.013895643875002861, h Loss is: 129.28317260742188, L1 loss: 1.588860034942627, Total Loss is: 129.2970733642578\n",
            "MSE Loss is: 0.012053849175572395, h Loss is: 129.54164123535156, L1 loss: 1.5885591506958008, Total Loss is: 129.55369567871094\n",
            "MSE Loss is: 0.012412858195602894, h Loss is: 129.87173461914062, L1 loss: 1.5883091688156128, Total Loss is: 129.88414001464844\n",
            "MSE Loss is: 0.013630824163556099, h Loss is: 130.2322540283203, L1 loss: 1.5881478786468506, Total Loss is: 130.24588012695312\n",
            "MSE Loss is: 0.014022637158632278, h Loss is: 130.5476837158203, L1 loss: 1.5880529880523682, Total Loss is: 130.56170654296875\n",
            "MSE Loss is: 0.017894376069307327, h Loss is: 130.72767639160156, L1 loss: 1.5877541303634644, Total Loss is: 130.74557495117188\n",
            "MSE Loss is: 0.01745273917913437, h Loss is: 130.83474731445312, L1 loss: 1.587478518486023, Total Loss is: 130.85220336914062\n",
            "MSE Loss is: 0.01667211577296257, h Loss is: 130.8144073486328, L1 loss: 1.5870662927627563, Total Loss is: 130.83108520507812\n",
            "MSE Loss is: 0.013659510761499405, h Loss is: 130.85342407226562, L1 loss: 1.5868597030639648, Total Loss is: 130.86708068847656\n",
            "MSE Loss is: 0.014639896340668201, h Loss is: 130.8568878173828, L1 loss: 1.5867942571640015, Total Loss is: 130.87152099609375\n",
            "New h_val is : tf.Tensor(0.5591297, shape=(), dtype=float32)\n",
            "Epoch: {} 44\n",
            "MSE Loss is: 0.014859633520245552, h Loss is: 150.59751892089844, L1 loss: 1.586734414100647, Total Loss is: 150.6123809814453\n",
            "MSE Loss is: 0.014874578453600407, h Loss is: 150.73159790039062, L1 loss: 1.586780071258545, Total Loss is: 150.74647521972656\n",
            "MSE Loss is: 0.013847057707607746, h Loss is: 151.0665283203125, L1 loss: 1.5867576599121094, Total Loss is: 151.0803680419922\n",
            "MSE Loss is: 0.014118624851107597, h Loss is: 151.5191650390625, L1 loss: 1.5867217779159546, Total Loss is: 151.5332794189453\n",
            "MSE Loss is: 0.011471779085695744, h Loss is: 151.8439178466797, L1 loss: 1.5865623950958252, Total Loss is: 151.8553924560547\n",
            "MSE Loss is: 0.013904500752687454, h Loss is: 152.0516357421875, L1 loss: 1.5863393545150757, Total Loss is: 152.06553649902344\n",
            "MSE Loss is: 0.013172121718525887, h Loss is: 152.18748474121094, L1 loss: 1.58603835105896, Total Loss is: 152.20065307617188\n",
            "MSE Loss is: 0.013686142861843109, h Loss is: 152.28848266601562, L1 loss: 1.585842490196228, Total Loss is: 152.3021697998047\n",
            "MSE Loss is: 0.012695531360805035, h Loss is: 152.36460876464844, L1 loss: 1.5854523181915283, Total Loss is: 152.37730407714844\n",
            "MSE Loss is: 0.013843970373272896, h Loss is: 152.57923889160156, L1 loss: 1.5851526260375977, Total Loss is: 152.59307861328125\n",
            "MSE Loss is: 0.012018430046737194, h Loss is: 152.87005615234375, L1 loss: 1.5848174095153809, Total Loss is: 152.882080078125\n",
            "MSE Loss is: 0.012379301711916924, h Loss is: 153.24888610839844, L1 loss: 1.5845474004745483, Total Loss is: 153.26126098632812\n",
            "MSE Loss is: 0.013584833592176437, h Loss is: 153.66270446777344, L1 loss: 1.5843819379806519, Total Loss is: 153.67628479003906\n",
            "MSE Loss is: 0.013990805484354496, h Loss is: 154.0195770263672, L1 loss: 1.584271788597107, Total Loss is: 154.0335693359375\n",
            "MSE Loss is: 0.01786653883755207, h Loss is: 154.21078491210938, L1 loss: 1.5839935541152954, Total Loss is: 154.22865295410156\n",
            "MSE Loss is: 0.01739950105547905, h Loss is: 154.30702209472656, L1 loss: 1.5837427377700806, Total Loss is: 154.3244171142578\n",
            "MSE Loss is: 0.016579724848270416, h Loss is: 154.24925231933594, L1 loss: 1.5832880735397339, Total Loss is: 154.26583862304688\n",
            "MSE Loss is: 0.013616342097520828, h Loss is: 154.2640380859375, L1 loss: 1.583063006401062, Total Loss is: 154.27764892578125\n",
            "MSE Loss is: 0.014623960480093956, h Loss is: 154.24691772460938, L1 loss: 1.582890272140503, Total Loss is: 154.26153564453125\n",
            "New h_val is : tf.Tensor(0.57205105, shape=(), dtype=float32)\n",
            "Epoch: {} 45\n",
            "MSE Loss is: 0.014789948239922523, h Loss is: 176.9599151611328, L1 loss: 1.5828019380569458, Total Loss is: 176.97470092773438\n",
            "MSE Loss is: 0.014812594279646873, h Loss is: 177.10586547851562, L1 loss: 1.582789421081543, Total Loss is: 177.1206817626953\n",
            "MSE Loss is: 0.013794200494885445, h Loss is: 177.492431640625, L1 loss: 1.5828131437301636, Total Loss is: 177.5062255859375\n",
            "MSE Loss is: 0.014092059805989265, h Loss is: 178.01466369628906, L1 loss: 1.582815170288086, Total Loss is: 178.0287628173828\n",
            "MSE Loss is: 0.011433979496359825, h Loss is: 178.3759002685547, L1 loss: 1.582661747932434, Total Loss is: 178.3873291015625\n",
            "MSE Loss is: 0.013874941505491734, h Loss is: 178.58876037597656, L1 loss: 1.5824615955352783, Total Loss is: 178.60263061523438\n",
            "MSE Loss is: 0.013118993490934372, h Loss is: 178.70994567871094, L1 loss: 1.5821311473846436, Total Loss is: 178.7230682373047\n",
            "MSE Loss is: 0.01366035733371973, h Loss is: 178.79412841796875, L1 loss: 1.5818957090377808, Total Loss is: 178.8077850341797\n",
            "MSE Loss is: 0.01264705415815115, h Loss is: 178.85386657714844, L1 loss: 1.5814651250839233, Total Loss is: 178.86651611328125\n",
            "MSE Loss is: 0.013796052895486355, h Loss is: 179.08389282226562, L1 loss: 1.5811312198638916, Total Loss is: 179.09768676757812\n",
            "MSE Loss is: 0.011986127123236656, h Loss is: 179.41275024414062, L1 loss: 1.5807687044143677, Total Loss is: 179.42474365234375\n",
            "MSE Loss is: 0.012349504977464676, h Loss is: 179.8492889404297, L1 loss: 1.5804722309112549, Total Loss is: 179.86163330078125\n",
            "MSE Loss is: 0.013542331755161285, h Loss is: 180.3245391845703, L1 loss: 1.5802799463272095, Total Loss is: 180.3380889892578\n",
            "MSE Loss is: 0.013961751945316792, h Loss is: 180.72726440429688, L1 loss: 1.5801388025283813, Total Loss is: 180.74122619628906\n",
            "MSE Loss is: 0.017842872068285942, h Loss is: 180.9274139404297, L1 loss: 1.5798214673995972, Total Loss is: 180.94525146484375\n",
            "MSE Loss is: 0.017350155860185623, h Loss is: 181.00543212890625, L1 loss: 1.5795249938964844, Total Loss is: 181.0227813720703\n",
            "MSE Loss is: 0.01649290695786476, h Loss is: 180.89820861816406, L1 loss: 1.5790176391601562, Total Loss is: 180.91470336914062\n",
            "MSE Loss is: 0.013577084988355637, h Loss is: 180.88108825683594, L1 loss: 1.5787476301193237, Total Loss is: 180.89466857910156\n",
            "MSE Loss is: 0.01461022812873125, h Loss is: 180.83856201171875, L1 loss: 1.5785373449325562, Total Loss is: 180.85316467285156\n",
            "New h_val is : tf.Tensor(0.5839853, shape=(), dtype=float32)\n",
            "Epoch: {} 46\n",
            "MSE Loss is: 0.014724863693118095, h Loss is: 206.8594207763672, L1 loss: 1.578419804573059, Total Loss is: 206.8741455078125\n",
            "MSE Loss is: 0.014755203388631344, h Loss is: 207.02099609375, L1 loss: 1.5783851146697998, Total Loss is: 207.03575134277344\n",
            "MSE Loss is: 0.013745758682489395, h Loss is: 207.4678192138672, L1 loss: 1.5783909559249878, Total Loss is: 207.4815673828125\n",
            "MSE Loss is: 0.01406802050769329, h Loss is: 208.07012939453125, L1 loss: 1.578372836112976, Total Loss is: 208.08419799804688\n",
            "MSE Loss is: 0.011398980394005775, h Loss is: 208.47003173828125, L1 loss: 1.5781891345977783, Total Loss is: 208.48143005371094\n",
            "MSE Loss is: 0.013848602771759033, h Loss is: 208.68194580078125, L1 loss: 1.577950119972229, Total Loss is: 208.69580078125\n",
            "MSE Loss is: 0.013069134205579758, h Loss is: 208.7794952392578, L1 loss: 1.5775766372680664, Total Loss is: 208.7925567626953\n",
            "MSE Loss is: 0.013636879622936249, h Loss is: 208.83883666992188, L1 loss: 1.5773054361343384, Total Loss is: 208.85247802734375\n",
            "MSE Loss is: 0.012602302245795727, h Loss is: 208.87631225585938, L1 loss: 1.576839566230774, Total Loss is: 208.888916015625\n",
            "MSE Loss is: 0.0137516800314188, h Loss is: 209.1239471435547, L1 loss: 1.5764769315719604, Total Loss is: 209.1376953125\n",
            "MSE Loss is: 0.011956719681620598, h Loss is: 209.4986114501953, L1 loss: 1.576093077659607, Total Loss is: 209.5105743408203\n",
            "MSE Loss is: 0.012323079630732536, h Loss is: 210.00286865234375, L1 loss: 1.5757759809494019, Total Loss is: 210.01519775390625\n",
            "MSE Loss is: 0.013503127731382847, h Loss is: 210.5496063232422, L1 loss: 1.5755618810653687, Total Loss is: 210.5631103515625\n",
            "MSE Loss is: 0.013935402035713196, h Loss is: 211.00245666503906, L1 loss: 1.575393795967102, Total Loss is: 211.01638793945312\n",
            "MSE Loss is: 0.01782301254570484, h Loss is: 211.20762634277344, L1 loss: 1.5750401020050049, Total Loss is: 211.22544860839844\n",
            "MSE Loss is: 0.01730451174080372, h Loss is: 211.25772094726562, L1 loss: 1.5747008323669434, Total Loss is: 211.2750244140625\n",
            "MSE Loss is: 0.016411451622843742, h Loss is: 211.0869903564453, L1 loss: 1.5741443634033203, Total Loss is: 211.10340881347656\n",
            "MSE Loss is: 0.013541433960199356, h Loss is: 211.02865600585938, L1 loss: 1.57383394241333, Total Loss is: 211.0421905517578\n",
            "MSE Loss is: 0.01459843572229147, h Loss is: 210.9561309814453, L1 loss: 1.573591709136963, Total Loss is: 210.97073364257812\n",
            "New h_val is : tf.Tensor(0.5949764, shape=(), dtype=float32)\n",
            "Epoch: {} 47\n",
            "MSE Loss is: 0.0146641181781888, h Loss is: 240.6506805419922, L1 loss: 1.5734509229660034, Total Loss is: 240.66534423828125\n",
            "MSE Loss is: 0.014702124521136284, h Loss is: 240.8329315185547, L1 loss: 1.5734002590179443, Total Loss is: 240.84764099121094\n",
            "MSE Loss is: 0.013701335527002811, h Loss is: 241.35098266601562, L1 loss: 1.5733938217163086, Total Loss is: 241.36468505859375\n",
            "MSE Loss is: 0.014046290889382362, h Loss is: 242.0449676513672, L1 loss: 1.5733598470687866, Total Loss is: 242.05902099609375\n",
            "MSE Loss is: 0.011366579681634903, h Loss is: 242.48536682128906, L1 loss: 1.5731486082077026, Total Loss is: 242.49673461914062\n",
            "MSE Loss is: 0.013825184665620327, h Loss is: 242.68862915039062, L1 loss: 1.5728731155395508, Total Loss is: 242.70245361328125\n",
            "MSE Loss is: 0.013022338971495628, h Loss is: 242.74998474121094, L1 loss: 1.5724595785140991, Total Loss is: 242.76300048828125\n",
            "MSE Loss is: 0.0136155616492033, h Loss is: 242.77432250976562, L1 loss: 1.5721561908721924, Total Loss is: 242.78793334960938\n",
            "MSE Loss is: 0.012560997158288956, h Loss is: 242.783935546875, L1 loss: 1.5716594457626343, Total Loss is: 242.79649353027344\n",
            "MSE Loss is: 0.013710642233490944, h Loss is: 243.05226135253906, L1 loss: 1.571273922920227, Total Loss is: 243.06597900390625\n",
            "MSE Loss is: 0.011929989792406559, h Loss is: 243.48263549804688, L1 loss: 1.5708750486373901, Total Loss is: 243.49456787109375\n",
            "MSE Loss is: 0.012299677357077599, h Loss is: 244.0684051513672, L1 loss: 1.5705429315567017, Total Loss is: 244.08070373535156\n",
            "MSE Loss is: 0.013467039912939072, h Loss is: 244.6970977783203, L1 loss: 1.5703110694885254, Total Loss is: 244.7105712890625\n",
            "MSE Loss is: 0.0139116570353508, h Loss is: 245.2045440673828, L1 loss: 1.5701189041137695, Total Loss is: 245.2184600830078\n",
            "MSE Loss is: 0.01780661568045616, h Loss is: 245.4088592529297, L1 loss: 1.5697311162948608, Total Loss is: 245.42666625976562\n",
            "MSE Loss is: 0.017262373119592667, h Loss is: 245.41868591308594, L1 loss: 1.569351077079773, Total Loss is: 245.43594360351562\n",
            "MSE Loss is: 0.016335150226950645, h Loss is: 245.16769409179688, L1 loss: 1.5687485933303833, Total Loss is: 245.1840362548828\n",
            "MSE Loss is: 0.013509104028344154, h Loss is: 245.05673217773438, L1 loss: 1.5684021711349487, Total Loss is: 245.0702362060547\n",
            "MSE Loss is: 0.014588345773518085, h Loss is: 244.95091247558594, L1 loss: 1.56813383102417, Total Loss is: 244.9654998779297\n",
            "New h_val is : tf.Tensor(0.6050658, shape=(), dtype=float32)\n",
            "Epoch: {} 48\n",
            "MSE Loss is: 0.01460745744407177, h Loss is: 278.71807861328125, L1 loss: 1.5679759979248047, Total Loss is: 278.7326965332031\n",
            "MSE Loss is: 0.01465307641774416, h Loss is: 278.9281921386719, L1 loss: 1.5679149627685547, Total Loss is: 278.9428405761719\n",
            "MSE Loss is: 0.013660564087331295, h Loss is: 279.5306396484375, L1 loss: 1.567901372909546, Total Loss is: 279.5443115234375\n",
            "MSE Loss is: 0.014026684686541557, h Loss is: 280.3283386230469, L1 loss: 1.5678550004959106, Total Loss is: 280.3423767089844\n",
            "MSE Loss is: 0.011336591094732285, h Loss is: 280.8086853027344, L1 loss: 1.567618727684021, Total Loss is: 280.82000732421875\n",
            "MSE Loss is: 0.013804402202367783, h Loss is: 280.9931945800781, L1 loss: 1.5673086643218994, Total Loss is: 281.0069885253906\n",
            "MSE Loss is: 0.012978414073586464, h Loss is: 281.0029602050781, L1 loss: 1.5668566226959229, Total Loss is: 281.01593017578125\n",
            "MSE Loss is: 0.013596266508102417, h Loss is: 280.9810791015625, L1 loss: 1.5665243864059448, Total Loss is: 280.99468994140625\n",
            "MSE Loss is: 0.012522897683084011, h Loss is: 280.9566650390625, L1 loss: 1.5660017728805542, Total Loss is: 280.96917724609375\n",
            "MSE Loss is: 0.013672731816768646, h Loss is: 281.251220703125, L1 loss: 1.5655990839004517, Total Loss is: 281.264892578125\n",
            "MSE Loss is: 0.011905726045370102, h Loss is: 281.7510681152344, L1 loss: 1.5651910305023193, Total Loss is: 281.7629699707031\n",
            "MSE Loss is: 0.012278981506824493, h Loss is: 282.4337158203125, L1 loss: 1.5648488998413086, Total Loss is: 282.44598388671875\n",
            "MSE Loss is: 0.013433890417218208, h Loss is: 283.1568603515625, L1 loss: 1.564603328704834, Total Loss is: 283.1702880859375\n",
            "MSE Loss is: 0.013890398666262627, h Loss is: 283.7215576171875, L1 loss: 1.5643891096115112, Total Loss is: 283.7354431152344\n",
            "MSE Loss is: 0.017793357372283936, h Loss is: 283.9174499511719, L1 loss: 1.5639688968658447, Total Loss is: 283.93524169921875\n",
            "MSE Loss is: 0.017223550006747246, h Loss is: 283.86944580078125, L1 loss: 1.5635496377944946, Total Loss is: 283.88665771484375\n",
            "MSE Loss is: 0.016263794153928757, h Loss is: 283.5177917480469, L1 loss: 1.5629037618637085, Total Loss is: 283.5340576171875\n",
            "MSE Loss is: 0.013479833491146564, h Loss is: 283.34405517578125, L1 loss: 1.5625253915786743, Total Loss is: 283.3575439453125\n",
            "MSE Loss is: 0.014579759910702705, h Loss is: 283.2013244628906, L1 loss: 1.5622371435165405, Total Loss is: 283.2159118652344\n",
            "New h_val is : tf.Tensor(0.6142969, shape=(), dtype=float32)\n",
            "Epoch: {} 49\n",
            "MSE Loss is: 0.014554621651768684, h Loss is: 321.4772033691406, L1 loss: 1.5620683431625366, Total Loss is: 321.49176025390625\n",
            "MSE Loss is: 0.014607777819037437, h Loss is: 321.7247314453125, L1 loss: 1.5620026588439941, Total Loss is: 321.7393493652344\n",
            "MSE Loss is: 0.013623121194541454, h Loss is: 322.42669677734375, L1 loss: 1.5619862079620361, Total Loss is: 322.4403076171875\n",
            "MSE Loss is: 0.014009039849042892, h Loss is: 323.34210205078125, L1 loss: 1.56210458278656, Total Loss is: 323.3561096191406\n",
            "MSE Loss is: 0.011308841407299042, h Loss is: 323.86041259765625, L1 loss: 1.561976671218872, Total Loss is: 323.8717346191406\n",
            "MSE Loss is: 0.013785981573164463, h Loss is: 324.0104064941406, L1 loss: 1.5617640018463135, Total Loss is: 324.0242004394531\n",
            "MSE Loss is: 0.012937178835272789, h Loss is: 323.9496765136719, L1 loss: 1.5613981485366821, Total Loss is: 323.9626159667969\n",
            "MSE Loss is: 0.013578871265053749, h Loss is: 323.86859130859375, L1 loss: 1.561065435409546, Total Loss is: 323.8821716308594\n",
            "MSE Loss is: 0.012487782165408134, h Loss is: 323.8049621582031, L1 loss: 1.5606029033660889, Total Loss is: 323.81744384765625\n",
            "MSE Loss is: 0.013637742958962917, h Loss is: 324.13427734375, L1 loss: 1.5602614879608154, Total Loss is: 324.1479187011719\n",
            "MSE Loss is: 0.011883718892931938, h Loss is: 324.7205505371094, L1 loss: 1.5599486827850342, Total Loss is: 324.732421875\n",
            "MSE Loss is: 0.012260712683200836, h Loss is: 325.51934814453125, L1 loss: 1.559748888015747, Total Loss is: 325.5316162109375\n",
            "MSE Loss is: 0.013403510674834251, h Loss is: 326.34954833984375, L1 loss: 1.5596332550048828, Total Loss is: 326.3629455566406\n",
            "MSE Loss is: 0.013871490955352783, h Loss is: 326.9737854003906, L1 loss: 1.559539794921875, Total Loss is: 326.9876708984375\n",
            "MSE Loss is: 0.01778291165828705, h Loss is: 327.147705078125, L1 loss: 1.5592460632324219, Total Loss is: 327.1654968261719\n",
            "MSE Loss is: 0.017187854275107384, h Loss is: 327.0224304199219, L1 loss: 1.5589240789413452, Total Loss is: 327.03961181640625\n",
            "MSE Loss is: 0.01619717851281166, h Loss is: 326.5474853515625, L1 loss: 1.5583600997924805, Total Loss is: 326.5636901855469\n",
            "MSE Loss is: 0.013453377410769463, h Loss is: 326.2977600097656, L1 loss: 1.5580462217330933, Total Loss is: 326.31121826171875\n",
            "MSE Loss is: 0.014572500251233578, h Loss is: 326.1180725097656, L1 loss: 1.557753324508667, Total Loss is: 326.1326599121094\n",
            "New h_val is : tf.Tensor(0.622715, shape=(), dtype=float32)\n",
            "saving model to: /content//CausalNN_model_final_1713137906.h5\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "The conv layer 1 weights before training : [[ 0.02187178 -0.24416807 -0.04100567  0.23558342  0.2623369   0.06792504\n",
            "  -0.2874765   0.44231367 -0.04958326 -0.18524122 -0.14620405 -0.1329028\n",
            "  -0.2886819  -0.05010253  0.27157623]]\n",
            "The conv layer 1 weights after training : [[-0.06090481 -0.3809923  -0.09867758  0.05039306  0.14137092  0.04342361\n",
            "   0.73540103  0.08862806 -0.10637347 -0.16568115  0.46963218  0.00742914\n",
            "   0.57384735  0.07036448  0.14820348]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckpp6cuerupo"
      },
      "outputs": [],
      "source": [
        "mat_df_2d_s = pd.DataFrame(mat)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat_f_df = pd.DataFrame(mat).T"
      ],
      "metadata": {
        "id": "UAa0WohUJ_t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "9CtUItJErupo",
        "outputId": "972973f9-8119-4a0d-e798-1866d83882f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4\n",
              "0  -0.133379  0.017326 -0.066284  0.073838 -0.063677\n",
              "1  -0.131074 -0.254185 -0.054034 -0.003586 -0.071311\n",
              "2   0.054087  0.065023  0.002750  0.195507  0.099389\n",
              "3   0.198963  0.207131  0.231414  0.266026  0.228047\n",
              "4   0.031329  0.003151 -0.046549  0.084663 -0.049138\n",
              "5  -0.110829  0.049991 -0.061157  0.029284  0.031442\n",
              "6   0.219217  0.136088  0.291734  0.255445  0.302697\n",
              "7  -0.155086 -0.121586 -0.149746 -0.134100 -0.171602\n",
              "8  -0.246915 -0.242254 -0.208614 -0.158333 -0.187511\n",
              "9   0.127352  0.198100  0.174697  0.261861  0.244770\n",
              "10 -0.243281 -0.027621 -0.051975  0.006722 -0.014057\n",
              "11 -0.106598 -0.290429 -0.168813 -0.119340 -0.107961\n",
              "12  0.182925  0.183222  0.062288  0.222406  0.172661\n",
              "13  0.176171  0.119764  0.107330  0.240969  0.145179\n",
              "14 -0.116393 -0.011526 -0.030755 -0.001214 -0.131494\n",
              "15 -0.358520 -0.116791 -0.008868  0.008189 -0.090923\n",
              "16  0.139068 -0.054377  0.099549  0.221774  0.134702\n",
              "17 -0.061332 -0.154922 -0.315909 -0.101987 -0.119804\n",
              "18 -0.155291 -0.204201 -0.229222 -0.191594 -0.220126\n",
              "19 -0.046536  0.007318 -0.031392  0.023228 -0.264548\n",
              "20  0.815084  0.118873 -0.062028 -0.023913  0.129443\n",
              "21  0.126861  0.649741  0.215181  0.065758 -0.032124\n",
              "22  0.142533  0.190490  0.764287  0.174341  0.148736\n",
              "23 -0.000754  0.015558  0.178712  0.305389  0.155203\n",
              "24  0.154068 -0.007351 -0.003487  0.139064  0.481443\n",
              "25  0.000000  0.567231  0.135490  0.057525  0.544053\n",
              "26  0.631003  0.000000  0.690261  0.166254  0.147722\n",
              "27  0.256922  0.738641  0.000000  0.544786  0.363798\n",
              "28  0.175853  0.254234  0.556782  0.000000  0.568309\n",
              "29  0.659191  0.207242  0.343741  0.540475  0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c901e2a5-abfb-4513-8d52-f35a5143a263\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.133379</td>\n",
              "      <td>0.017326</td>\n",
              "      <td>-0.066284</td>\n",
              "      <td>0.073838</td>\n",
              "      <td>-0.063677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.131074</td>\n",
              "      <td>-0.254185</td>\n",
              "      <td>-0.054034</td>\n",
              "      <td>-0.003586</td>\n",
              "      <td>-0.071311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.054087</td>\n",
              "      <td>0.065023</td>\n",
              "      <td>0.002750</td>\n",
              "      <td>0.195507</td>\n",
              "      <td>0.099389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.198963</td>\n",
              "      <td>0.207131</td>\n",
              "      <td>0.231414</td>\n",
              "      <td>0.266026</td>\n",
              "      <td>0.228047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.031329</td>\n",
              "      <td>0.003151</td>\n",
              "      <td>-0.046549</td>\n",
              "      <td>0.084663</td>\n",
              "      <td>-0.049138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.110829</td>\n",
              "      <td>0.049991</td>\n",
              "      <td>-0.061157</td>\n",
              "      <td>0.029284</td>\n",
              "      <td>0.031442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.219217</td>\n",
              "      <td>0.136088</td>\n",
              "      <td>0.291734</td>\n",
              "      <td>0.255445</td>\n",
              "      <td>0.302697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.155086</td>\n",
              "      <td>-0.121586</td>\n",
              "      <td>-0.149746</td>\n",
              "      <td>-0.134100</td>\n",
              "      <td>-0.171602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.246915</td>\n",
              "      <td>-0.242254</td>\n",
              "      <td>-0.208614</td>\n",
              "      <td>-0.158333</td>\n",
              "      <td>-0.187511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.127352</td>\n",
              "      <td>0.198100</td>\n",
              "      <td>0.174697</td>\n",
              "      <td>0.261861</td>\n",
              "      <td>0.244770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.243281</td>\n",
              "      <td>-0.027621</td>\n",
              "      <td>-0.051975</td>\n",
              "      <td>0.006722</td>\n",
              "      <td>-0.014057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-0.106598</td>\n",
              "      <td>-0.290429</td>\n",
              "      <td>-0.168813</td>\n",
              "      <td>-0.119340</td>\n",
              "      <td>-0.107961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.182925</td>\n",
              "      <td>0.183222</td>\n",
              "      <td>0.062288</td>\n",
              "      <td>0.222406</td>\n",
              "      <td>0.172661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.176171</td>\n",
              "      <td>0.119764</td>\n",
              "      <td>0.107330</td>\n",
              "      <td>0.240969</td>\n",
              "      <td>0.145179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-0.116393</td>\n",
              "      <td>-0.011526</td>\n",
              "      <td>-0.030755</td>\n",
              "      <td>-0.001214</td>\n",
              "      <td>-0.131494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-0.358520</td>\n",
              "      <td>-0.116791</td>\n",
              "      <td>-0.008868</td>\n",
              "      <td>0.008189</td>\n",
              "      <td>-0.090923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.139068</td>\n",
              "      <td>-0.054377</td>\n",
              "      <td>0.099549</td>\n",
              "      <td>0.221774</td>\n",
              "      <td>0.134702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>-0.061332</td>\n",
              "      <td>-0.154922</td>\n",
              "      <td>-0.315909</td>\n",
              "      <td>-0.101987</td>\n",
              "      <td>-0.119804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>-0.155291</td>\n",
              "      <td>-0.204201</td>\n",
              "      <td>-0.229222</td>\n",
              "      <td>-0.191594</td>\n",
              "      <td>-0.220126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>-0.046536</td>\n",
              "      <td>0.007318</td>\n",
              "      <td>-0.031392</td>\n",
              "      <td>0.023228</td>\n",
              "      <td>-0.264548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.815084</td>\n",
              "      <td>0.118873</td>\n",
              "      <td>-0.062028</td>\n",
              "      <td>-0.023913</td>\n",
              "      <td>0.129443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.126861</td>\n",
              "      <td>0.649741</td>\n",
              "      <td>0.215181</td>\n",
              "      <td>0.065758</td>\n",
              "      <td>-0.032124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.142533</td>\n",
              "      <td>0.190490</td>\n",
              "      <td>0.764287</td>\n",
              "      <td>0.174341</td>\n",
              "      <td>0.148736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>-0.000754</td>\n",
              "      <td>0.015558</td>\n",
              "      <td>0.178712</td>\n",
              "      <td>0.305389</td>\n",
              "      <td>0.155203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.154068</td>\n",
              "      <td>-0.007351</td>\n",
              "      <td>-0.003487</td>\n",
              "      <td>0.139064</td>\n",
              "      <td>0.481443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.567231</td>\n",
              "      <td>0.135490</td>\n",
              "      <td>0.057525</td>\n",
              "      <td>0.544053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.631003</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.690261</td>\n",
              "      <td>0.166254</td>\n",
              "      <td>0.147722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.256922</td>\n",
              "      <td>0.738641</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.544786</td>\n",
              "      <td>0.363798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.175853</td>\n",
              "      <td>0.254234</td>\n",
              "      <td>0.556782</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.568309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.659191</td>\n",
              "      <td>0.207242</td>\n",
              "      <td>0.343741</td>\n",
              "      <td>0.540475</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c901e2a5-abfb-4513-8d52-f35a5143a263')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c901e2a5-abfb-4513-8d52-f35a5143a263 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c901e2a5-abfb-4513-8d52-f35a5143a263');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a67ab5db-9439-47ed-9557-5bec2491830e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a67ab5db-9439-47ed-9557-5bec2491830e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a67ab5db-9439-47ed-9557-5bec2491830e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"mat_df_2d_s\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.25692206621170044,\n          -0.3585203289985657,\n          -0.0007544358959421515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.7386407256126404,\n          -0.11679086834192276,\n          0.015558233484625816\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.0,\n          -0.00886831060051918,\n          0.1787121593952179\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.5447857975959778,\n          0.008189479820430279,\n          0.30538880825042725\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.3637980818748474,\n          -0.0909229964017868,\n          0.1552031934261322\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "mat_df_2d_s.T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat_f_df.iloc[20:,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "qrIvGlpIKGpn",
        "outputId": "a3563c2e-31d4-4f14-8962-0be1209e8284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3\n",
              "20  0.000000 -0.173380  0.080703 -0.061715\n",
              "21 -0.095194  0.000000  0.037806 -0.136843\n",
              "22  0.069021  0.172888  0.000000  0.835213\n",
              "23 -0.108998 -0.878886  2.633786  0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a655d8e7-ddff-448d-b084-b3e9d991851b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.173380</td>\n",
              "      <td>0.080703</td>\n",
              "      <td>-0.061715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>-0.095194</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037806</td>\n",
              "      <td>-0.136843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.069021</td>\n",
              "      <td>0.172888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.835213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>-0.108998</td>\n",
              "      <td>-0.878886</td>\n",
              "      <td>2.633786</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a655d8e7-ddff-448d-b084-b3e9d991851b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a655d8e7-ddff-448d-b084-b3e9d991851b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a655d8e7-ddff-448d-b084-b3e9d991851b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f145f777-b284-4d4f-8917-f358fea3a390\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f145f777-b284-4d4f-8917-f358fea3a390')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f145f777-b284-4d4f-8917-f358fea3a390 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"mat_f_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -0.09519411623477936,\n          -0.1089979037642479,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0,\n          -0.8788855075836182,\n          -0.17337976396083832\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.03780581057071686,\n          2.633786201477051,\n          0.08070340752601624\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -0.13684332370758057,\n          0.0,\n          -0.06171455979347229\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijo5Wyjm6qRR"
      },
      "source": [
        "#Summary Causal Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvIvNNEjrupo"
      },
      "outputs": [],
      "source": [
        "matrix_2d_2d_s = mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfX8KQwJ6qRR"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "G_2d_s1 = nx.DiGraph()\n",
        "\n",
        "nodes_2d_s1 = [\"S1\", \"S2\", \"S3\",  \"S4\", \"S5\"]\n",
        "nodes_r_2d_s1= [\"S1\", \"S2\", \"S3\",  \"S4\", \"S5\"]\n",
        "edges_2d_s1 = []\n",
        "pred_graph_s1 = np.zeros((5,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79j7uDTN6qRR"
      },
      "outputs": [],
      "source": [
        "for i in range (0, 5):\n",
        "  G_2d_s1.add_node(nodes_2d_s1[i],pos=(int(i/2)+1,(i%2)+1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_2d_2d_s.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RouYjyuVnIwl",
        "outputId": "6429d0df-9eee-41c4-ce94-26c1d9677d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 15):\n",
        "  for j in range (0, 5):\n",
        "    if matrix_2d_2d_s[j,i] > 0.5:\n",
        "      print(i,j,matrix_2d_2d_s[j,i])\n",
        "      col = np.round(matrix_2d_2d_s[j,i], 2)\n",
        "      G_2d_s1.add_edge(nodes_2d_s1[i%5], nodes_r_2d_s1[j], weight=1)\n",
        "      pred_graph_s1[i%5, j]=1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip1xAXSW7AIK",
        "outputId": "8260ba6e-7319-41b3-b372-6440d8c1e6fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 0 0.978764\n",
            "6 1 0.73540103\n",
            "7 2 0.92348546\n",
            "9 4 0.5464282\n",
            "11 0 0.6237839\n",
            "11 2 0.6359247\n",
            "12 1 0.57384735\n",
            "13 4 0.66091746\n",
            "14 0 0.7391445\n",
            "14 3 0.7309054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQRq97oL6qRS",
        "outputId": "dd5ec2ad-5819-4355-8ea4-fefc8192a2cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'S1': (1, 1), 'S2': (1, 2), 'S3': (2, 1), 'S4': (2, 2), 'S5': (3, 1)}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "pos_2d_s1=nx.get_node_attributes(G_2d_s1,'pos')\n",
        "pos_2d_s1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "938WuKdz6qRS"
      },
      "outputs": [],
      "source": [
        "weights_2d_s1 = nx.get_edge_attributes(G_2d_s1,'weight').values()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "nx.draw(G_2d_s1, pos_2d_s1,  edge_cmap= plt.cm.tab20,  #cmap = plt.get_cmap('jet'),\n",
        "        font_size=12, node_size=1200, node_color='#c0c0c0', #[30,30,30,30,30],\n",
        "        edge_color=weights_2d_s1, with_labels = True, connectionstyle='arc3, rad = 0.3')\n",
        "#nx.draw_networkx(G, with_labels = True)\n",
        "plt.colorbar(mpl.cm.ScalarMappable(norm=mpl.colors.Normalize(0.3, 1), cmap=plt.cm.tab20),\n",
        "              orientation='vertical', label='Edge Strength')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "Mw47bO8L_aC4",
        "outputId": "80069cec-923d-491c-d40b-ecfd9995ab18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savetxt('proposed-summary-adj-mat.csv', pred_graph_s1, delimiter=\",\")"
      ],
      "metadata": {
        "id": "6DgXJmarS6p9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cdt.metrics.SHD(true_graph, pred_graph_s1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_1qPVtYFV73",
        "outputId": "09ef391c-3225-4e4f-c751-cdd1434ac174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_values = true_graph\n",
        "predictions = pred_graph_s1\n",
        "\n",
        "N = true_values.shape[1]*true_values.shape[0]\n",
        "accuracy = (true_values == predictions).sum() / N\n",
        "TP = ((predictions == 1) & (true_values == 1)).sum()\n",
        "FP = ((predictions == 1) & (true_values == 0)).sum()\n",
        "TN = ((predictions == 0) & (true_values == 0)).sum()\n",
        "FN = ((predictions == 0) & (true_values == 1)).sum()\n",
        "precision = TP / (TP+FP)\n",
        "recall = TP / (TP + FN)\n",
        "FDR = FP / (FP + TP)\n",
        "F1 = 2 * (precision * recall) / (precision + recall)\n",
        "print('Accuracy: {}, Precision: {}, Recall: {}, FDR: {}, F1 Score: {}'.format(accuracy, precision, recall, FDR,F1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTy-ZiS66Sbr",
        "outputId": "4d5f320c-cf62-4880-adf9-259573deb979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.88, Precision: 0.625, Recall: 1.0, FDR: 0.375, F1 Score: 0.7692307692307693\n"
          ]
        }
      ]
    }
  ]
}