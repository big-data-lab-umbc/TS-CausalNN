{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En1xrlBKaIrC"
      },
      "source": [
        "#TS-CausalNN applied to Synthetic Dataset 2\n",
        "\n",
        "\n",
        "This notebook contains the proposed model. Here we have developed the proposed Causal Conv2D layer and the optimization function.\n",
        "\n",
        "The functions to visualize the predicted causal graph are available after the model training codes. The predicted graph is compared with ground truth using an adjacency matrix (array).   \n",
        "\n",
        "In this notebook, we applied the proposed model to the synthetic dataset-2 to generate a full causal graph and summary graph."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = 100000\n",
        "\n",
        "#Create noise\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(1001)\n",
        "np.set_printoptions(suppress=True)\n",
        "noise = np.random.poisson(lam=1.0, size=(t)) #np.random.exponential(scale=1.0, size=(t)) # np.random.normal(0,1,t)\n",
        "noise = noise\n",
        "print(noise.size)\n",
        "#Variable 1\n",
        "source1 = np.zeros((t))\n",
        "source1_1st_term = np.zeros((t))\n",
        "import math\n",
        "source1[0] = noise[0] +10\n",
        "source1[1] = noise[1] +10\n",
        "source1[2] = noise[2] +10\n",
        "for x in range(3,t):\n",
        "  #print(x)\n",
        "  if(x<5):\n",
        "    source1_1st_term[x] = 0.5*math.sqrt(2)*math.exp(-source1[x-2]*source1[x-2]/2)\n",
        "    source1[x] = 0.5*math.sqrt(2)*math.exp(-source1[x-2]*source1[x-2]/2) + noise[x]\n",
        "  else:\n",
        "    #print((source1[x-5]*source1[x-5])*(-source1[x-2]*source1[x-2])/2)\n",
        "    source1_1st_term[x] = 0.5*math.sqrt(2)*math.exp((source1[x-5]*source1[x-5])*(-source1[x-2]*source1[x-2])/2) #2*math.sqrt(2)*math.exp(-source1[x-5]*source1[x-5]/2)\n",
        "    source1[x] = 0.5*math.sqrt(2)*math.exp((source1[x-5]*source1[x-5])*(-source1[x-2]*source1[x-2])/2) + noise[x]\n",
        "\n",
        "#Variable 2\n",
        "source2 = np.zeros((t))\n",
        "source2_1st_term = np.zeros((t))\n",
        "np.set_printoptions(suppress=True)\n",
        "noise2 = np.random.poisson(lam=1.0, size=(t)) # np.random.normal(0,1,t)\n",
        "#noise2 = noise2 /2\n",
        "import math\n",
        "source2[1] = noise2[1]\n",
        "source2[2] = noise2[2]\n",
        "for x in range(3,t):\n",
        "  if source1[x-1] > 0:\n",
        "    source2_1st_term[x] = 2.2*math.exp(-source1[x-1]*source1[x-1]/2)+ 0.5*math.exp(-source1[x]*source1[x]/2)\n",
        "    source2[x] = 2.2*math.exp(-source1[x-1]*source1[x-1]/2) + noise2[x]+ 0.5*math.exp(-source1[x]*source1[x]/2)\n",
        "  else:\n",
        "    source2_1st_term[x] = -2*math.exp(-source1[x-1]*source1[x-1])+ 0.5*math.exp(-source1[x]*source1[x]/2)\n",
        "    source2[x] = -2*math.exp(-source1[x-1]*source1[x-1]) + noise2[x]+ 0.5*math.exp(-source1[x]*source1[x]/2)\n",
        "\n",
        "#Variable 3\n",
        "source3 = np.zeros((t))\n",
        "source3_1st_term = np.zeros((t))\n",
        "np.set_printoptions(suppress=True)\n",
        "noise3 = np.random.poisson(lam=1.0, size=(t)) # np.random.normal(0,1,t)\n",
        "noise3 = noise3 /2\n",
        "import math\n",
        "source3[1] = noise3[1]\n",
        "source3[2] = noise3[2]\n",
        "for x in range(3,t):\n",
        "  source3_1st_term[x] = -5.05*math.exp(-source1[x-1]*source1[x-1]/2)\n",
        "  source3[x] = -5.05*math.exp(-source1[x-1]*source1[x-1]/2) + noise3[x]\n",
        "\n",
        "#Variable 4\n",
        "source4 = np.zeros((t))\n",
        "source4_1st_term = np.zeros((t))\n",
        "np.set_printoptions(suppress=True)\n",
        "noise4 = np.random.poisson(lam=1.0, size=(t)) # np.random.normal(0,1,t)\n",
        "noise4 = noise4 /2\n",
        "import math\n",
        "source4[1] = noise4[1] + 10\n",
        "source4[2] = noise4[2] + 10\n",
        "for x in range(3,t):\n",
        "  source4_1st_term[x] = -1.15*math.exp(-source1[x-1]*source1[x-1]/2) + 1.5*math.sqrt(2)*math.exp(-source4[x-1]*source4[x-1]/2) + 2.35*math.exp(-source3[x-1]*source3[x-1]/2) + 3*math.exp(-source3[x]*source3[x]/2)\n",
        "  source4[x] = -1.15*math.exp(-source1[x-1]*source1[x-1]/2) + 1.5*math.sqrt(2)*math.exp(-source4[x-1]*source4[x-1]/2) + 2.35*math.exp(-source3[x-1]*source3[x-1]/2) + noise4[x] + 3*math.exp(-source3[x]*source3[x]/2)\n",
        "\n",
        "\n",
        "#combining data\n",
        "dict={'S1':source1,'S2':source2,'S3':source3,'S4':source4,'noise1':noise,'noise2':noise2,'noise3':noise3,'noise4':noise4}\n",
        "data=pd.DataFrame(dict)\n",
        "data.to_csv('synthetic_2nd_dataset.csv',header=True,index=False)\n",
        "from google.colab import files\n",
        "#files.download( \"synthetic_2nd_dataset.csv\" )"
      ],
      "metadata": {
        "id": "DgVx8XwdZ__C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "z96f-sD2rAOk",
        "outputId": "024e66b7-c0bb-426b-ec1b-18bc64007cf9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              S1            S2            S3         S4  noise1  noise2  \\\n",
              "10000  14.642136  9.501468e+00  8.486597e+00  10.895058     0.5     0.5   \n",
              "10001  14.642136  3.959384e-46  5.000000e-01  -0.647491     0.5     0.0   \n",
              "10002   0.500000  4.029988e+00  1.000000e+00   7.571438     0.5     0.5   \n",
              "10003   0.500000  1.403146e+01  7.986597e+00   9.789798     0.5     1.5   \n",
              "10004  13.707028  9.001468e+00  7.986597e+00   5.544859     0.0     0.0   \n",
              "10005   0.500000  4.529988e+00  5.000000e-01   0.352510     0.5     1.0   \n",
              "10006   0.500000  1.303146e+01  8.986597e+00  14.519082     0.5     0.5   \n",
              "10007  13.707028  9.001468e+00  7.986597e+00   5.544859     0.0     0.0   \n",
              "10008  14.207028  1.623932e-40  1.440316e-40  -0.999999     0.5     0.0   \n",
              "10009   0.000000  4.000000e+00  1.341923e-43   6.094847     0.0     0.0   \n",
              "\n",
              "       noise3  noise4  \n",
              "10000     0.5       1  \n",
              "10001     0.5       2  \n",
              "10002     1.0       1  \n",
              "10003     0.0       2  \n",
              "10004     0.0       1  \n",
              "10005     0.5       3  \n",
              "10006     1.0       1  \n",
              "10007     0.0       1  \n",
              "10008     0.0       2  \n",
              "10009     0.0       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c781106-72d6-41d2-b6fe-2609a70cfd4a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S1</th>\n",
              "      <th>S2</th>\n",
              "      <th>S3</th>\n",
              "      <th>S4</th>\n",
              "      <th>noise1</th>\n",
              "      <th>noise2</th>\n",
              "      <th>noise3</th>\n",
              "      <th>noise4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>14.642136</td>\n",
              "      <td>9.501468e+00</td>\n",
              "      <td>8.486597e+00</td>\n",
              "      <td>10.895058</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10001</th>\n",
              "      <td>14.642136</td>\n",
              "      <td>3.959384e-46</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>-0.647491</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10002</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>4.029988e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>7.571438</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10003</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.403146e+01</td>\n",
              "      <td>7.986597e+00</td>\n",
              "      <td>9.789798</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10004</th>\n",
              "      <td>13.707028</td>\n",
              "      <td>9.001468e+00</td>\n",
              "      <td>7.986597e+00</td>\n",
              "      <td>5.544859</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10005</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>4.529988e+00</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>0.352510</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10006</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.303146e+01</td>\n",
              "      <td>8.986597e+00</td>\n",
              "      <td>14.519082</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10007</th>\n",
              "      <td>13.707028</td>\n",
              "      <td>9.001468e+00</td>\n",
              "      <td>7.986597e+00</td>\n",
              "      <td>5.544859</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10008</th>\n",
              "      <td>14.207028</td>\n",
              "      <td>1.623932e-40</td>\n",
              "      <td>1.440316e-40</td>\n",
              "      <td>-0.999999</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10009</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>1.341923e-43</td>\n",
              "      <td>6.094847</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c781106-72d6-41d2-b6fe-2609a70cfd4a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c781106-72d6-41d2-b6fe-2609a70cfd4a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c781106-72d6-41d2-b6fe-2609a70cfd4a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-57f676c4-19ed-4ec8-b463-555b2ef68488\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-57f676c4-19ed-4ec8-b463-555b2ef68488')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-57f676c4-19ed-4ec8-b463-555b2ef68488 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"S1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.271482050083118,\n        \"min\": 0.0,\n        \"max\": 14.642135623730951,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          14.642135623730951,\n          0.5,\n          14.20702785299188\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.9574368499629005,\n        \"min\": 3.959383892530495e-46,\n        \"max\": 14.031456016701256,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1.6239321480058703e-40,\n          3.959383892530495e-46,\n          4.529987610281024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.176601879696565,\n        \"min\": 1.3419228507219262e-43,\n        \"max\": 8.986596968260816,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          8.48659696839059,\n          0.5,\n          1.4403155145147296e-40\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.149937015061419,\n        \"min\": -0.999999046385613,\n        \"max\": 14.519081583533978,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.999999046385613,\n          -0.6474907077537853,\n          0.3525102458606004\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"noise1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24152294576982397,\n        \"min\": 0.0,\n        \"max\": 0.5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"noise2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5163977794943223,\n        \"min\": 0.0,\n        \"max\": 1.5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"noise3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.41163630117428235,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"noise4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "data.iloc[10000:10010,:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "\n",
        "def signaltonoise(a, axis=0, ddof=0):\n",
        "    a = np.asanyarray(a)\n",
        "    m = a.mean(axis)\n",
        "    sd = a.std(axis=axis, ddof=ddof)\n",
        "    return np.where(sd == 0, 0, (m*m)/(sd*sd))\n",
        "\n"
      ],
      "metadata": {
        "id": "5wbvAZ0YJMz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_np = data.to_numpy()"
      ],
      "metadata": {
        "id": "zfJw775iJYWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snr1 = signaltonoise(data_np[:,0])\n",
        "snr2 = signaltonoise(data_np[:,1])\n",
        "snr3 = signaltonoise(data_np[:,2])\n",
        "snr4 = signaltonoise(data_np[:,3])"
      ],
      "metadata": {
        "id": "U3duiwVkJPiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snr1, snr2, snr3, snr4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynBRfnUoJmVF",
        "outputId": "6ccf9f39-85ed-492e-ab49-52631372a4dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(1.69822276), array(3.3130597), array(1.14746314), array(1.93885138))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_graph = np.zeros((4,4))\n",
        "true_graph[0,0]=1\n",
        "true_graph[0,1]=1\n",
        "true_graph[0,2]=1\n",
        "true_graph[0,3]=1\n",
        "true_graph[2,3]=1\n",
        "true_graph[3,3]=1\n",
        "true_graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b80PfUYGIwQZ",
        "outputId": "5cccb19a-f913-41ff-efda-9cd99afd008a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_full_graph = np.zeros((4,24))\n",
        "true_full_graph[0,0]=1\n",
        "true_full_graph[0,12]=1\n",
        "\n",
        "true_full_graph[1,16]=1\n",
        "true_full_graph[1,20]=1\n",
        "\n",
        "true_full_graph[2,16]=1\n",
        "\n",
        "true_full_graph[3,16]=1\n",
        "true_full_graph[3,18]=1\n",
        "true_full_graph[3,19]=1\n",
        "true_full_graph[3,22]=1\n",
        "true_full_graph\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkng21cFeX4a",
        "outputId": "29e9fc23-bb66-4453-a720-f510392edeb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 1., 1., 0., 0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cdt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S9iW6BIFQsw",
        "outputId": "e1532401-132d-4b98-e0b1-2aad2dfdf225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cdt\n",
            "  Downloading cdt-0.6.0-py3-none-any.whl (921 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m921.1/921.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cdt) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from cdt) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from cdt) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from cdt) (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from cdt) (1.5.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from cdt) (0.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from cdt) (3.2.1)\n",
            "Collecting skrebate (from cdt)\n",
            "  Downloading skrebate-0.62.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from cdt) (4.66.2)\n",
            "Collecting GPUtil (from cdt)\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from cdt) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->cdt) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->cdt) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->cdt) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->cdt) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->cdt) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->cdt) (2024.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->cdt) (3.3.0)\n",
            "Requirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->cdt) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->cdt) (24.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.4->statsmodels->cdt) (1.16.0)\n",
            "Building wheels for collected packages: GPUtil, skrebate\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7394 sha256=d404e08ac273e16d59a42e03114923a8d261d0cde3971106ca0ee1e7aeb8eda0\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "  Building wheel for skrebate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for skrebate: filename=skrebate-0.62-py3-none-any.whl size=29255 sha256=c59cf66a632c233cf4b3e002af0e7b134535eeed8019a6ef13f46c85cd8f0ee5\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/67/40/683074a684607162bd0e34dcf7ccdfcab5861c3b2a83286f3a\n",
            "Successfully built GPUtil skrebate\n",
            "Installing collected packages: GPUtil, skrebate, cdt\n",
            "Successfully installed GPUtil-1.4.0 cdt-0.6.0 skrebate-0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cdt"
      ],
      "metadata": {
        "id": "9zOqtLmEFTV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf0de24-8c65-44f8-cda1-c041b8072bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No GPU automatically detected. Setting SETTINGS.GPU to 0, and SETTINGS.NJOBS to cpu_count.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Pre-processing"
      ],
      "metadata": {
        "id": "_c4DRyupElS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def data_preprocessing(data, max_lag=5):\n",
        "  from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "  #convert to numpy array\n",
        "  syn_data_np = data.to_numpy()\n",
        "\n",
        "  #normalize the dataset\n",
        "  scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
        "  syn_data_np_nor = scaler_X.fit_transform(syn_data_np)\n",
        "  syn_data_np = syn_data_np_nor\n",
        "\n",
        "  #transform into 2D data\n",
        "  syn_data_np_T= syn_data_np.T\n",
        "  syn_data_pro = np.zeros((syn_data_np.shape[0]-max_lag,syn_data_np.shape[1],(max_lag+1)))\n",
        "  for i in range(0, (syn_data_np.shape[0]-max_lag)):\n",
        "    syn_data_pro[i,:,:]= syn_data_np_T[:, i:i+(max_lag+1)]\n",
        "  syn_data_2d = np.expand_dims(syn_data_pro, axis =-1)\n",
        "\n",
        "  #make datafrom with normalized data\n",
        "  syn_data_nor_df =pd.DataFrame(data = syn_data_np,\n",
        "                  columns = data.columns)\n",
        "\n",
        "  #transform normalized data into 1D shape with lagged and current time values\n",
        "  size_1d = syn_data_np.shape[1]*(max_lag+1)\n",
        "  print(size_1d)\n",
        "  syn_data_1d = np.zeros((syn_data_np.shape[0]-max_lag,size_1d))\n",
        "  for i in range(0, (syn_data_np.shape[0]-max_lag)):\n",
        "    for j in range(0,(max_lag+1)):\n",
        "      j_end = j * syn_data_np.shape[1]\n",
        "      syn_data_1d[i,j_end:j_end+syn_data_np.shape[1]]= syn_data_np[i+j, :]\n",
        "\n",
        "  #transform non-normalized data into 1D shape with lagged and current time values\n",
        "  syn_data_np_2 = data.to_numpy()\n",
        "  syn_data_1d_not_norm = np.zeros((syn_data_np_2.shape[0]-max_lag,size_1d))\n",
        "  for i in range(0, (syn_data_np_2.shape[0]-max_lag)):\n",
        "    for j in range(0,(max_lag+1)):\n",
        "      j_end = j * syn_data_np_2.shape[1]\n",
        "      syn_data_1d_not_norm[i,j_end:j_end+syn_data_np_2.shape[1]]= syn_data_np_2[i+j, :]\n",
        "\n",
        "\n",
        "  return syn_data_np_nor, syn_data_2d, syn_data_nor_df, syn_data_1d,  syn_data_1d_not_norm"
      ],
      "metadata": {
        "id": "4DVdqlr5lFs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "syn_data_np, syn_data_2d, syn_data_nor_df, syn_data_1d,  syn_data_1d_not_norm = data_preprocessing(data, max_lag=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJH74-HmjFE5",
        "outputId": "5d6202d4-1a56-441c-c0a4-13e165b93c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "syn_data_2d.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-sM8O9yjX_k",
        "outputId": "e9837a3f-b622-4922-de29-ccd298cd72f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99998, 4, 3, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "syn_data_np_nor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrkQ-tqyjbgM",
        "outputId": "a976bd30-afe8-4564-d4be-9be67838d030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "syn_data_nor_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7G3LI5yjeDz",
        "outputId": "c1612608-6423-4f53-eafb-1f0c19af0092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "syn_data_1d.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHgkpfgljzhB",
        "outputId": "788a07eb-7c61-4cc2-bbb9-04737d427390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99998, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "syn_data_1d_not_norm.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP6kicJpj13B",
        "outputId": "506f9cc4-e2a8-4521-d7c3-e35233b4bfe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99998, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CvHxTQArupm",
        "outputId": "7f0c002a-aa25-4a5b-9995-fea6a2cd4dae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100000, 4), (99995, 4, 6, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "syn_data_np.shape, syn_data_2d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "510yT1YNJHlt",
        "outputId": "10880a54-71a9-4e9e-8d46-7ac01a292ee5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99995, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "data_y_syn = syn_data_np[5:,0:4]\n",
        "data_y_syn.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KVllbLUkHjt"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyklufMFkH7O"
      },
      "outputs": [],
      "source": [
        "import keras,os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Dropout, AveragePooling2D, LSTM, Activation, ConvLSTM2D, TimeDistributed, Input, Reshape\n",
        "from keras.layers import UpSampling1D, Conv2DTranspose, UpSampling2D, Conv1D, AveragePooling1D, LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras import callbacks\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras.layers import concatenate\n",
        "from keras.regularizers import l1, l2\n",
        "from time import time\n",
        "\n",
        "keras.utils.set_random_seed(1001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_probability as tfp"
      ],
      "metadata": {
        "id": "QPNiH7qHKe0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalConv2D(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_outputs, counter, *args, **kwargs):\n",
        "        super(CausalConv2D, self).__init__()\n",
        "        self.conv2d = tf.keras.layers.Conv2D(*args, **kwargs)\n",
        "        self.num_outputs = num_outputs\n",
        "        self.counter = counter\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W=self.add_weight(name='kernel',\n",
        "                           shape=(input_shape[1], input_shape[2],input_shape[3], 1),\n",
        "                           #initializer = keras.initializers.RandomUniform(minval=0.05, maxval=0.5),\n",
        "                           #initializer ='uniform',\n",
        "                           initializer = tf.keras.initializers.glorot_uniform(seed=8),\n",
        "                           trainable=True)\n",
        "        self.mask = np.ones(shape=self.W.shape)\n",
        "        print(self.W)\n",
        "        self.mask[self.counter,(input_shape[2]-1),...] = 0.0\n",
        "\n",
        "    #def masked_convolution_op(self, filters, kernel, mask):\n",
        "    #    return self._convolution_op(filters, tf.math.multiply(kernel, tf.reshape(mask, mask.shape + [1,1] )))\n",
        "\n",
        "    def get_weights(self):\n",
        "        return super().get_weights()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        self.W.assign(tf.math.multiply(self.W, self.mask))\n",
        "        #self.conv2d._convolution_op = functools.partial(self.masked_convolution_op, mask=mask)\n",
        "        #return self.conv2d.call(x)\n",
        "        return self.conv2d.convolution_op(inputs, self.W)"
      ],
      "metadata": {
        "id": "z2o2-R2mFIm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D\n",
        "def get_model_2d(input_dims):\n",
        "    input_batch = Input(shape = input_dims)\n",
        "\n",
        "    conv_model = Sequential()\n",
        "    conv_model = Conv2D(filters=4, kernel_size=1, strides=(1,1), padding='valid', activation=\"linear\", name='conv1')(input_batch)\n",
        "    #conv_model = AveragePooling2D(pool_size=(1,1), strides=None, padding='valid', name='pool1')(conv_model) activation=LeakyReLU(0.05)\n",
        "    conv_model = tf.math.reduce_mean(conv_model, axis=-1)\n",
        "    conv_model = Reshape((4, 6, 1))(conv_model)\n",
        "    #conv_model = Flatten()(conv_model )\n",
        "    pooled_outputs = []\n",
        "    for i in range(0, 4):\n",
        "      #layer = CausalConv2D(num_outputs=1, counter=i, name=\"parr\"+str(i))(conv_model) # , kernel_regularizer = l1(0.2)\n",
        "      layer = CausalConv2D(filters=1, kernel_size=(4,6), num_outputs=1, counter=i, padding='valid', activation=\"sigmoid\",)(conv_model)\n",
        "      #den1 = layer(tf.ones([481, 30]))\n",
        "      #conv = Conv2D(1, kernel_size=filter_sizes[i], padding='valid', activation='relu')(conv_model)\n",
        "      pooled_outputs.append(layer)\n",
        "    output = concatenate(pooled_outputs)\n",
        "    output = Flatten()(output)\n",
        "\n",
        "    model = Model(inputs=input_batch, outputs=output, name='cpred')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "WwughzzGFJIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with gradient tape\n",
        "\n",
        "class CausalNNModel(object):\n",
        "    def __init__(self,\n",
        "                 dims,\n",
        "                 alpha=0.0,\n",
        "                 rho = 1.0,\n",
        "                 rho_max = 10e20,\n",
        "                 h_tol = 1e-8,\n",
        "                 init='glorot_uniform'):\n",
        "\n",
        "        super(CausalNNModel, self).__init__()\n",
        "\n",
        "        self.dims = dims\n",
        "        self.n_stacks = len(self.dims) - 1\n",
        "        self.alpha = alpha\n",
        "        self.rho = rho\n",
        "        self.h_p = np.Inf\n",
        "        self.rho_max = rho_max\n",
        "        self.h_tol = h_tol\n",
        "        self.model_2d = get_model_2d(self.dims)\n",
        "        print(\"====Model created=====\")\n",
        "\n",
        "        self.model = Model(inputs=self.model_2d.input, outputs=self.model_2d.output)\n",
        "\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        return self.model_cnn.predict(x)\n",
        "\n",
        "    def predict(self, x):  # predict cluster labels using the output of clustering layer\n",
        "        q = self.model.predict(x, verbose=0)[1]\n",
        "        return q.argmax(1)\n",
        "\n",
        "    def custom_loss_function(self, y_true, y_pred):\n",
        "      mse = keras.losses.mean_squared_error(y_true, y_pred)\n",
        "      h_val = self.causal_loss_h()\n",
        "      h_loss = 0.5 * self.rho * h_val * h_val + self.alpha * h_val\n",
        "      lambda1 = 0.1\n",
        "      adj_mat = self.get_mat()\n",
        "      sparse_loss = lambda1 * tf.math.reduce_sum(tf.abs(adj_mat))\n",
        "      #neg_weight = np.sum(adj_mat, where=adj_mat<0)\n",
        "      #neg_loss = 0.5 * tf.abs(neg_weight)\n",
        "      print('MSE Loss is: {}, h Loss is: {}, L1 loss: {}, Total Loss is: {}'.format(tf.reduce_mean(mse), h_loss, sparse_loss, tf.reduce_mean(mse)+h_loss))\n",
        "      return mse + h_loss + sparse_loss #+ neg_loss\n",
        "\n",
        "    def causal_loss_h(self):\n",
        "      mat = self.get_mat()\n",
        "      h_val = self.h_acy_1(mat[:, 20:])\n",
        "      return h_val\n",
        "\n",
        "    def get_mat(self):\n",
        "      w1_2d_s = self.model.get_layer(index=-6).get_weights()\n",
        "      w2_2d_s = self.model.get_layer(index=-5).get_weights()\n",
        "      w3_2d_s = self.model.get_layer(index=-4).get_weights()\n",
        "      w4_2d_s = self.model.get_layer(index=-3).get_weights()\n",
        "      arr1_2d_s = np.expand_dims(np.squeeze(np.array(w1_2d_s), axis=(0,3,4)).flatten('F'), axis=0)\n",
        "      arr2_2d_s = np.expand_dims(np.squeeze(np.array(w2_2d_s), axis=(0,3,4)).flatten('F'), axis=0)\n",
        "      arr3_2d_s = np.expand_dims(np.squeeze(np.array(w3_2d_s), axis=(0,3,4)).flatten('F'), axis=0)\n",
        "      arr4_2d_s = np.expand_dims(np.squeeze(np.array(w4_2d_s), axis=(0,3,4)).flatten('F'), axis=0)\n",
        "      mat_2d_s = np.concatenate((arr1_2d_s, arr2_2d_s, arr3_2d_s, arr4_2d_s))\n",
        "      #print(mat_2d_s)\n",
        "      return mat_2d_s\n",
        "\n",
        "    def h_acy_1(self, A):\n",
        "      n_var = A.shape[0]\n",
        "      h = tf.linalg.trace(tf.linalg.expm(A * A)) - n_var\n",
        "      return h\n",
        "\n",
        "\n",
        "    def h_acy(self, A):\n",
        "      '''Calculate the constraint of A ensure that it's a DAG'''\n",
        "      #(Yu et al. 2019 DAG-GNN)\n",
        "      # h(w) = tr[(I + kA*A)^n_variables] - n_variables\n",
        "      n_var = A.shape[0]\n",
        "      M = tf.eye(n_var, num_columns = n_var) + A/n_var\n",
        "      E = M\n",
        "      for _ in range(n_var - 2):\n",
        "        E = tf.linalg.matmul(E, M)\n",
        "      h = tf.math.reduce_sum(tf.transpose(E) * M) - n_var\n",
        "      return h\n",
        "\n",
        "    def compile(self, optimizer='adam'):\n",
        "        self.model.compile(optimizer=optimizer, loss= self.custom_loss_function) # ['mse', self.causal_loss()])\n",
        "\n",
        "    def fit(self, x, y=None, maxiter=100, batch_size=512, save_dir='./results/temp'):\n",
        "        t1 = time()\n",
        "\n",
        "\n",
        "        # Step 2: deep clustering\n",
        "        # logging file\n",
        "        import csv\n",
        "        logfile = open(save_dir + '/causalnn_log.csv', 'w')\n",
        "        logwriter = csv.DictWriter(logfile, fieldnames=['iter','loss'])\n",
        "        logwriter.writeheader()\n",
        "        train_loader = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size)\n",
        "        optimizer = tf.keras.optimizers.Adam(1e-2)\n",
        "        w1_2d_s = self.model.get_layer(index=-6).get_weights()\n",
        "        arr1_2d_s = np.expand_dims(np.squeeze(np.array(w1_2d_s), axis=(0,3,4)).flatten('F'), axis=0)\n",
        "\n",
        "\n",
        "        for epoch in range(int(maxiter)):\n",
        "          print('Epoch: {}', epoch)\n",
        "          h_n = None\n",
        "          for (x, y) in train_loader:\n",
        "            #eval loss and compute gradients\n",
        "            with tf.GradientTape() as tape:\n",
        "              tape.watch(self.model.trainable_variables)\n",
        "              #passing through neural network\n",
        "              output = self.model(x)\n",
        "              #calculate loss\n",
        "              loss = self.custom_loss_function(y, output)\n",
        "              gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "              optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "              h_n = self.causal_loss_h()\n",
        "              #print('New h_val is :', h_n)\n",
        "              #if h_n > 0.25 * self.h_p:\n",
        "              #  self.rho = self.rho*10\n",
        "              #else:\n",
        "              #  break\n",
        "\n",
        "          if h_n > 0.25 * self.h_p:\n",
        "                self.rho = self.rho*1.1\n",
        "          self.h_p = h_n\n",
        "          print('New h_val is :', h_n)\n",
        "          self.alpha += self.rho * self.h_p\n",
        "\n",
        "          if self.h_p <= self.h_tol or self.rho >= self.rho_max:\n",
        "            print('Before the loop end # h_val is: {}, rho is: {}'.format(self.h_p, self.rho))\n",
        "            break\n",
        "\n",
        "        #for ite in range(int(maxiter)):\n",
        "        #  print('Epoch: {}', ite)\n",
        "        #  self.model.fit(x, y, epochs=1, batch_size=batch_size, verbose=True)\n",
        "\n",
        "        # save the trained model\n",
        "        logfile.close()\n",
        "        file_name  = \"/CausalNN_model_final_\" + str(round(time()))+ \".h5\"\n",
        "        print('saving model to:', save_dir + file_name)\n",
        "        self.model.save_weights(save_dir + file_name)\n",
        "\n",
        "        w1_2d_s_1 = self.model.get_layer(index=-6).get_weights()\n",
        "        arr1_2d_s_1 = np.expand_dims(np.squeeze(np.array(w1_2d_s_1), axis=(0,3,4)).flatten('F'), axis=0)\n",
        "\n",
        "        y_pred = self.model.predict(x)\n",
        "        adj_mat = self.get_mat()\n",
        "\n",
        "        print('The conv layer 1 weights before training :', arr1_2d_s)\n",
        "        print('The conv layer 1 weights after training :', arr1_2d_s_1)\n",
        "\n",
        "        return y_pred, adj_mat"
      ],
      "metadata": {
        "id": "HbY_kEfhJ2HV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model creation and training:"
      ],
      "metadata": {
        "id": "PM6hvqYoVHG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.set_random_seed(1001)\n",
        "\n",
        "cnnmodel = CausalNNModel(dims=syn_data_2d.shape[1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rxv1FjaM_u6",
        "outputId": "468ac23a-f8cf-4c22-fc15-b6db58e46a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'causal_conv2d_20/kernel:0' shape=(4, 6, 1, 1) dtype=float32, numpy=\n",
            "array([[[[ 0.01729116]],\n",
            "\n",
            "        [[ 0.05369946]],\n",
            "\n",
            "        [[-0.11558445]],\n",
            "\n",
            "        [[-0.1930318 ]],\n",
            "\n",
            "        [[-0.22727013]],\n",
            "\n",
            "        [[-0.10506889]]],\n",
            "\n",
            "\n",
            "       [[[-0.03241783]],\n",
            "\n",
            "        [[ 0.34967968]],\n",
            "\n",
            "        [[-0.22822307]],\n",
            "\n",
            "        [[ 0.18624505]],\n",
            "\n",
            "        [[-0.03919902]],\n",
            "\n",
            "        [[-0.03960952]]],\n",
            "\n",
            "\n",
            "       [[[ 0.20739552]],\n",
            "\n",
            "        [[-0.14644605]],\n",
            "\n",
            "        [[ 0.21469983]],\n",
            "\n",
            "        [[-0.17902574]],\n",
            "\n",
            "        [[ 0.06509387]],\n",
            "\n",
            "        [[ 0.17076865]]],\n",
            "\n",
            "\n",
            "       [[[ 0.21393666]],\n",
            "\n",
            "        [[-0.3412853 ]],\n",
            "\n",
            "        [[ 0.0880048 ]],\n",
            "\n",
            "        [[-0.3153036 ]],\n",
            "\n",
            "        [[-0.07369781]],\n",
            "\n",
            "        [[ 0.15640828]]]], dtype=float32)>\n",
            "<tf.Variable 'causal_conv2d_21/kernel:0' shape=(4, 6, 1, 1) dtype=float32, numpy=\n",
            "array([[[[ 0.01729116]],\n",
            "\n",
            "        [[ 0.05369946]],\n",
            "\n",
            "        [[-0.11558445]],\n",
            "\n",
            "        [[-0.1930318 ]],\n",
            "\n",
            "        [[-0.22727013]],\n",
            "\n",
            "        [[-0.10506889]]],\n",
            "\n",
            "\n",
            "       [[[-0.03241783]],\n",
            "\n",
            "        [[ 0.34967968]],\n",
            "\n",
            "        [[-0.22822307]],\n",
            "\n",
            "        [[ 0.18624505]],\n",
            "\n",
            "        [[-0.03919902]],\n",
            "\n",
            "        [[-0.03960952]]],\n",
            "\n",
            "\n",
            "       [[[ 0.20739552]],\n",
            "\n",
            "        [[-0.14644605]],\n",
            "\n",
            "        [[ 0.21469983]],\n",
            "\n",
            "        [[-0.17902574]],\n",
            "\n",
            "        [[ 0.06509387]],\n",
            "\n",
            "        [[ 0.17076865]]],\n",
            "\n",
            "\n",
            "       [[[ 0.21393666]],\n",
            "\n",
            "        [[-0.3412853 ]],\n",
            "\n",
            "        [[ 0.0880048 ]],\n",
            "\n",
            "        [[-0.3153036 ]],\n",
            "\n",
            "        [[-0.07369781]],\n",
            "\n",
            "        [[ 0.15640828]]]], dtype=float32)>\n",
            "<tf.Variable 'causal_conv2d_22/kernel:0' shape=(4, 6, 1, 1) dtype=float32, numpy=\n",
            "array([[[[ 0.01729116]],\n",
            "\n",
            "        [[ 0.05369946]],\n",
            "\n",
            "        [[-0.11558445]],\n",
            "\n",
            "        [[-0.1930318 ]],\n",
            "\n",
            "        [[-0.22727013]],\n",
            "\n",
            "        [[-0.10506889]]],\n",
            "\n",
            "\n",
            "       [[[-0.03241783]],\n",
            "\n",
            "        [[ 0.34967968]],\n",
            "\n",
            "        [[-0.22822307]],\n",
            "\n",
            "        [[ 0.18624505]],\n",
            "\n",
            "        [[-0.03919902]],\n",
            "\n",
            "        [[-0.03960952]]],\n",
            "\n",
            "\n",
            "       [[[ 0.20739552]],\n",
            "\n",
            "        [[-0.14644605]],\n",
            "\n",
            "        [[ 0.21469983]],\n",
            "\n",
            "        [[-0.17902574]],\n",
            "\n",
            "        [[ 0.06509387]],\n",
            "\n",
            "        [[ 0.17076865]]],\n",
            "\n",
            "\n",
            "       [[[ 0.21393666]],\n",
            "\n",
            "        [[-0.3412853 ]],\n",
            "\n",
            "        [[ 0.0880048 ]],\n",
            "\n",
            "        [[-0.3153036 ]],\n",
            "\n",
            "        [[-0.07369781]],\n",
            "\n",
            "        [[ 0.15640828]]]], dtype=float32)>\n",
            "<tf.Variable 'causal_conv2d_23/kernel:0' shape=(4, 6, 1, 1) dtype=float32, numpy=\n",
            "array([[[[ 0.01729116]],\n",
            "\n",
            "        [[ 0.05369946]],\n",
            "\n",
            "        [[-0.11558445]],\n",
            "\n",
            "        [[-0.1930318 ]],\n",
            "\n",
            "        [[-0.22727013]],\n",
            "\n",
            "        [[-0.10506889]]],\n",
            "\n",
            "\n",
            "       [[[-0.03241783]],\n",
            "\n",
            "        [[ 0.34967968]],\n",
            "\n",
            "        [[-0.22822307]],\n",
            "\n",
            "        [[ 0.18624505]],\n",
            "\n",
            "        [[-0.03919902]],\n",
            "\n",
            "        [[-0.03960952]]],\n",
            "\n",
            "\n",
            "       [[[ 0.20739552]],\n",
            "\n",
            "        [[-0.14644605]],\n",
            "\n",
            "        [[ 0.21469983]],\n",
            "\n",
            "        [[-0.17902574]],\n",
            "\n",
            "        [[ 0.06509387]],\n",
            "\n",
            "        [[ 0.17076865]]],\n",
            "\n",
            "\n",
            "       [[[ 0.21393666]],\n",
            "\n",
            "        [[-0.3412853 ]],\n",
            "\n",
            "        [[ 0.0880048 ]],\n",
            "\n",
            "        [[-0.3153036 ]],\n",
            "\n",
            "        [[-0.07369781]],\n",
            "\n",
            "        [[ 0.15640828]]]], dtype=float32)>\n",
            "====Model created=====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnnmodel.model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tqt4qRYdNCdx",
        "outputId": "15d721e1-70ed-412d-8f6b-09db39f685db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, 4, 6, 1)]            0         []                            \n",
            "                                                                                                  \n",
            " conv1 (Conv2D)              (None, 4, 6, 4)              8         ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_5 (TFO  (None, 4, 6)                 0         ['conv1[0][0]']               \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " reshape_5 (Reshape)         (None, 4, 6, 1)              0         ['tf.math.reduce_mean_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " causal_conv2d_20 (CausalCo  (None, 1, 1, 1)              24        ['reshape_5[0][0]']           \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " causal_conv2d_21 (CausalCo  (None, 1, 1, 1)              24        ['reshape_5[0][0]']           \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " causal_conv2d_22 (CausalCo  (None, 1, 1, 1)              24        ['reshape_5[0][0]']           \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " causal_conv2d_23 (CausalCo  (None, 1, 1, 1)              24        ['reshape_5[0][0]']           \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 1, 1, 4)              0         ['causal_conv2d_20[0][0]',    \n",
            " )                                                                   'causal_conv2d_21[0][0]',    \n",
            "                                                                     'causal_conv2d_22[0][0]',    \n",
            "                                                                     'causal_conv2d_23[0][0]']    \n",
            "                                                                                                  \n",
            " flatten_5 (Flatten)         (None, 4)                    0         ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 104 (416.00 Byte)\n",
            "Trainable params: 104 (416.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnnmodel.compile()"
      ],
      "metadata": {
        "id": "cH2nDfu0NFUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred, mat = cnnmodel.fit(x=syn_data_2d, y=data_y_syn, maxiter=25, batch_size=2048, save_dir='/content/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQOuTYC6y9yR",
        "outputId": "768afc3b-073b-41ed-e4bb-c397cb795c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: {} 0\n",
            "MSE Loss is: 0.09585773944854736, h Loss is: 1.003495640361507e-06, L1 loss: 1.4565690755844116, Total Loss is: 0.09585874527692795\n",
            "MSE Loss is: 0.09111841022968292, h Loss is: 1.1561634210011107e-06, L1 loss: 1.4485690593719482, Total Loss is: 0.09111956506967545\n",
            "MSE Loss is: 0.08848144859075546, h Loss is: 1.3918680679125828e-06, L1 loss: 1.4417228698730469, Total Loss is: 0.08848284184932709\n",
            "MSE Loss is: 0.08863845467567444, h Loss is: 1.7755955923348665e-06, L1 loss: 1.437688946723938, Total Loss is: 0.0886402279138565\n",
            "MSE Loss is: 0.08831506967544556, h Loss is: 2.377456439717207e-06, L1 loss: 1.4386862516403198, Total Loss is: 0.08831744641065598\n",
            "MSE Loss is: 0.08610644936561584, h Loss is: 3.251569069107063e-06, L1 loss: 1.445637583732605, Total Loss is: 0.0861096978187561\n",
            "MSE Loss is: 0.08261927962303162, h Loss is: 4.4807716221839655e-06, L1 loss: 1.4577423334121704, Total Loss is: 0.08262375742197037\n",
            "MSE Loss is: 0.07731837034225464, h Loss is: 6.1483337958634365e-06, L1 loss: 1.4712574481964111, Total Loss is: 0.0773245170712471\n",
            "MSE Loss is: 0.07194682955741882, h Loss is: 8.310791599797085e-06, L1 loss: 1.4857492446899414, Total Loss is: 0.0719551369547844\n",
            "MSE Loss is: 0.06550578773021698, h Loss is: 1.1012270988430828e-05, L1 loss: 1.504960298538208, Total Loss is: 0.06551679968833923\n",
            "MSE Loss is: 0.057376135140657425, h Loss is: 1.4360366549226455e-05, L1 loss: 1.527532696723938, Total Loss is: 0.057390496134757996\n",
            "MSE Loss is: 0.04815785586833954, h Loss is: 1.858282121247612e-05, L1 loss: 1.5500324964523315, Total Loss is: 0.04817643761634827\n",
            "MSE Loss is: 0.04182801395654678, h Loss is: 2.40115805354435e-05, L1 loss: 1.5718542337417603, Total Loss is: 0.04185202717781067\n",
            "MSE Loss is: 0.035927727818489075, h Loss is: 3.1071409466676414e-05, L1 loss: 1.591644287109375, Total Loss is: 0.035958800464868546\n",
            "MSE Loss is: 0.03148971125483513, h Loss is: 4.0305534639628604e-05, L1 loss: 1.6077216863632202, Total Loss is: 0.03153001517057419\n",
            "MSE Loss is: 0.0301100704818964, h Loss is: 5.23173512192443e-05, L1 loss: 1.6197201013565063, Total Loss is: 0.030162388458848\n",
            "MSE Loss is: 0.031097158789634705, h Loss is: 6.736873183399439e-05, L1 loss: 1.6307343244552612, Total Loss is: 0.03116452693939209\n",
            "MSE Loss is: 0.03194154053926468, h Loss is: 8.484764111926779e-05, L1 loss: 1.6377719640731812, Total Loss is: 0.03202638775110245\n",
            "MSE Loss is: 0.032475102692842484, h Loss is: 0.00010306301555829123, L1 loss: 1.6396507024765015, Total Loss is: 0.03257816657423973\n",
            "MSE Loss is: 0.03307104855775833, h Loss is: 0.00012008172052446753, L1 loss: 1.6381367444992065, Total Loss is: 0.03319112956523895\n",
            "MSE Loss is: 0.031055163592100143, h Loss is: 0.0001342666510026902, L1 loss: 1.6348637342453003, Total Loss is: 0.031189430505037308\n",
            "MSE Loss is: 0.029706109315156937, h Loss is: 0.00014520135300699621, L1 loss: 1.6296192407608032, Total Loss is: 0.029851309955120087\n",
            "MSE Loss is: 0.0272458977997303, h Loss is: 0.00015319878002628684, L1 loss: 1.6233848333358765, Total Loss is: 0.02739909663796425\n",
            "MSE Loss is: 0.026226099580526352, h Loss is: 0.00015921624435577542, L1 loss: 1.6158052682876587, Total Loss is: 0.026385316625237465\n",
            "MSE Loss is: 0.025296427309513092, h Loss is: 0.00016432799748145044, L1 loss: 1.6079038381576538, Total Loss is: 0.025460755452513695\n",
            "MSE Loss is: 0.025595776736736298, h Loss is: 0.00016958198102656752, L1 loss: 1.601021409034729, Total Loss is: 0.02576535940170288\n",
            "MSE Loss is: 0.02573317289352417, h Loss is: 0.00017582954023964703, L1 loss: 1.5937080383300781, Total Loss is: 0.025909002870321274\n",
            "MSE Loss is: 0.026708345860242844, h Loss is: 0.00018410658231005073, L1 loss: 1.5865141153335571, Total Loss is: 0.02689245156943798\n",
            "MSE Loss is: 0.027076080441474915, h Loss is: 0.0001948735152836889, L1 loss: 1.5804966688156128, Total Loss is: 0.027270954102277756\n",
            "MSE Loss is: 0.0277190413326025, h Loss is: 0.00020867476996500045, L1 loss: 1.5764658451080322, Total Loss is: 0.027927715331315994\n",
            "MSE Loss is: 0.027032092213630676, h Loss is: 0.00022624272969551384, L1 loss: 1.5737354755401611, Total Loss is: 0.027258334681391716\n",
            "MSE Loss is: 0.026143021881580353, h Loss is: 0.00024759882944636047, L1 loss: 1.5729073286056519, Total Loss is: 0.026390621438622475\n",
            "MSE Loss is: 0.025708578526973724, h Loss is: 0.0002729620900936425, L1 loss: 1.5732454061508179, Total Loss is: 0.025981539860367775\n",
            "MSE Loss is: 0.025756333023309708, h Loss is: 0.00030300315120257437, L1 loss: 1.5746594667434692, Total Loss is: 0.026059336960315704\n",
            "MSE Loss is: 0.024455228820443153, h Loss is: 0.00033837262890301645, L1 loss: 1.5777523517608643, Total Loss is: 0.024793600663542747\n",
            "MSE Loss is: 0.02323048934340477, h Loss is: 0.0003788376343436539, L1 loss: 1.5821269750595093, Total Loss is: 0.023609327152371407\n",
            "MSE Loss is: 0.02271510846912861, h Loss is: 0.0004243890580255538, L1 loss: 1.5872138738632202, Total Loss is: 0.02313949726521969\n",
            "MSE Loss is: 0.023265257477760315, h Loss is: 0.00047475655446760356, L1 loss: 1.592324137687683, Total Loss is: 0.02374001406133175\n",
            "MSE Loss is: 0.023343820124864578, h Loss is: 0.0005293897120282054, L1 loss: 1.596521258354187, Total Loss is: 0.023873209953308105\n",
            "MSE Loss is: 0.023889102041721344, h Loss is: 0.0005875041242688894, L1 loss: 1.60015070438385, Total Loss is: 0.024476606398820877\n",
            "MSE Loss is: 0.023700054734945297, h Loss is: 0.0006478030700236559, L1 loss: 1.602378487586975, Total Loss is: 0.024347858503460884\n",
            "MSE Loss is: 0.02307039126753807, h Loss is: 0.000709699175786227, L1 loss: 1.6028594970703125, Total Loss is: 0.023780090734362602\n",
            "MSE Loss is: 0.02270941622555256, h Loss is: 0.0007724685128778219, L1 loss: 1.6028156280517578, Total Loss is: 0.023481884971261024\n",
            "MSE Loss is: 0.023479685187339783, h Loss is: 0.0008361414074897766, L1 loss: 1.6017948389053345, Total Loss is: 0.02431582659482956\n",
            "MSE Loss is: 0.022708384320139885, h Loss is: 0.0009023153688758612, L1 loss: 1.5995925664901733, Total Loss is: 0.02361069992184639\n",
            "MSE Loss is: 0.021990545094013214, h Loss is: 0.0009711352176964283, L1 loss: 1.5966143608093262, Total Loss is: 0.022961679846048355\n",
            "MSE Loss is: 0.022044729441404343, h Loss is: 0.001045534387230873, L1 loss: 1.5938555002212524, Total Loss is: 0.023090263828635216\n",
            "MSE Loss is: 0.02173132821917534, h Loss is: 0.0011270670220255852, L1 loss: 1.5910812616348267, Total Loss is: 0.0228583961725235\n",
            "MSE Loss is: 0.02220301516354084, h Loss is: 0.0012176771415397525, L1 loss: 1.589133620262146, Total Loss is: 0.02342069149017334\n",
            "New h_val is : tf.Tensor(0.051417828, shape=(), dtype=float32)\n",
            "Epoch: {} 1\n",
            "MSE Loss is: 0.02253780886530876, h Loss is: 0.003956229891628027, L1 loss: 1.5877268314361572, Total Loss is: 0.026494039222598076\n",
            "MSE Loss is: 0.02240099385380745, h Loss is: 0.004180796444416046, L1 loss: 1.5869489908218384, Total Loss is: 0.026581790298223495\n",
            "MSE Loss is: 0.022235870361328125, h Loss is: 0.004430277273058891, L1 loss: 1.5869805812835693, Total Loss is: 0.026666147634387016\n",
            "MSE Loss is: 0.022441715002059937, h Loss is: 0.004706527106463909, L1 loss: 1.5876216888427734, Total Loss is: 0.02714824303984642\n",
            "MSE Loss is: 0.02170024998486042, h Loss is: 0.005007966887205839, L1 loss: 1.588757872581482, Total Loss is: 0.026708217337727547\n",
            "MSE Loss is: 0.022252459079027176, h Loss is: 0.005334903951734304, L1 loss: 1.5909210443496704, Total Loss is: 0.027587363496422768\n",
            "MSE Loss is: 0.021609876304864883, h Loss is: 0.00568508030846715, L1 loss: 1.593679428100586, Total Loss is: 0.027294956147670746\n",
            "MSE Loss is: 0.02098415046930313, h Loss is: 0.00605523306876421, L1 loss: 1.5965782403945923, Total Loss is: 0.027039382606744766\n",
            "MSE Loss is: 0.021352071315050125, h Loss is: 0.006438596174120903, L1 loss: 1.5993648767471313, Total Loss is: 0.027790667489171028\n",
            "MSE Loss is: 0.02164471708238125, h Loss is: 0.006832155864685774, L1 loss: 1.6018379926681519, Total Loss is: 0.02847687341272831\n",
            "MSE Loss is: 0.021069662645459175, h Loss is: 0.007231520488858223, L1 loss: 1.603868842124939, Total Loss is: 0.028301183134317398\n",
            "MSE Loss is: 0.020848074927926064, h Loss is: 0.007633730303496122, L1 loss: 1.6054037809371948, Total Loss is: 0.028481805697083473\n",
            "MSE Loss is: 0.021282734349370003, h Loss is: 0.008034479804337025, L1 loss: 1.6064366102218628, Total Loss is: 0.029317215085029602\n",
            "MSE Loss is: 0.021296881139278412, h Loss is: 0.008439537137746811, L1 loss: 1.6070579290390015, Total Loss is: 0.029736418277025223\n",
            "MSE Loss is: 0.020742317661643028, h Loss is: 0.008853448554873466, L1 loss: 1.6073379516601562, Total Loss is: 0.029595766216516495\n",
            "MSE Loss is: 0.020900839939713478, h Loss is: 0.009285121224820614, L1 loss: 1.6074345111846924, Total Loss is: 0.030185960233211517\n",
            "MSE Loss is: 0.021364158019423485, h Loss is: 0.009743274189531803, L1 loss: 1.6075865030288696, Total Loss is: 0.031107433140277863\n",
            "MSE Loss is: 0.020719606429338455, h Loss is: 0.010234951972961426, L1 loss: 1.6078194379806519, Total Loss is: 0.03095455840229988\n",
            "MSE Loss is: 0.02013016678392887, h Loss is: 0.010761545971035957, L1 loss: 1.6081936359405518, Total Loss is: 0.03089171275496483\n",
            "MSE Loss is: 0.020661907270550728, h Loss is: 0.011333834379911423, L1 loss: 1.608833909034729, Total Loss is: 0.0319957435131073\n",
            "MSE Loss is: 0.020180590450763702, h Loss is: 0.011951431632041931, L1 loss: 1.6097490787506104, Total Loss is: 0.032132022082805634\n",
            "MSE Loss is: 0.020615657791495323, h Loss is: 0.012622732669115067, L1 loss: 1.610965371131897, Total Loss is: 0.03323838859796524\n",
            "MSE Loss is: 0.019965413957834244, h Loss is: 0.013348711654543877, L1 loss: 1.6124528646469116, Total Loss is: 0.03331412374973297\n",
            "MSE Loss is: 0.020111506804823875, h Loss is: 0.014130979776382446, L1 loss: 1.6141270399093628, Total Loss is: 0.03424248844385147\n",
            "MSE Loss is: 0.019711146131157875, h Loss is: 0.014967802911996841, L1 loss: 1.6158770322799683, Total Loss is: 0.034678950905799866\n",
            "MSE Loss is: 0.019810695201158524, h Loss is: 0.015854166820645332, L1 loss: 1.617553949356079, Total Loss is: 0.035664863884449005\n",
            "MSE Loss is: 0.019492559134960175, h Loss is: 0.016779066994786263, L1 loss: 1.618970513343811, Total Loss is: 0.03627162426710129\n",
            "MSE Loss is: 0.01977841928601265, h Loss is: 0.01775149628520012, L1 loss: 1.620080590248108, Total Loss is: 0.03752991557121277\n",
            "MSE Loss is: 0.019550945609807968, h Loss is: 0.018756533041596413, L1 loss: 1.6208810806274414, Total Loss is: 0.03830748051404953\n",
            "MSE Loss is: 0.019824761897325516, h Loss is: 0.019793450832366943, L1 loss: 1.6213905811309814, Total Loss is: 0.03961821272969246\n",
            "MSE Loss is: 0.01957603543996811, h Loss is: 0.020878169685602188, L1 loss: 1.6219466924667358, Total Loss is: 0.0404542051255703\n",
            "MSE Loss is: 0.019060995429754257, h Loss is: 0.02198789454996586, L1 loss: 1.6222072839736938, Total Loss is: 0.041048891842365265\n",
            "MSE Loss is: 0.018953317776322365, h Loss is: 0.023119833320379257, L1 loss: 1.6222561597824097, Total Loss is: 0.04207315295934677\n",
            "MSE Loss is: 0.019557710736989975, h Loss is: 0.024299219250679016, L1 loss: 1.6222975254058838, Total Loss is: 0.04385692998766899\n",
            "MSE Loss is: 0.01911761984229088, h Loss is: 0.025562092661857605, L1 loss: 1.6223782300949097, Total Loss is: 0.04467971250414848\n",
            "MSE Loss is: 0.018713096156716347, h Loss is: 0.026898151263594627, L1 loss: 1.6228033304214478, Total Loss is: 0.045611247420310974\n",
            "MSE Loss is: 0.018302056938409805, h Loss is: 0.02832138165831566, L1 loss: 1.6234028339385986, Total Loss is: 0.046623438596725464\n",
            "MSE Loss is: 0.018845215439796448, h Loss is: 0.029842689633369446, L1 loss: 1.6242319345474243, Total Loss is: 0.048687905073165894\n",
            "MSE Loss is: 0.018836509436368942, h Loss is: 0.031476885080337524, L1 loss: 1.6252098083496094, Total Loss is: 0.05031339451670647\n",
            "MSE Loss is: 0.01882322132587433, h Loss is: 0.033226873725652695, L1 loss: 1.6265476942062378, Total Loss is: 0.05205009505152702\n",
            "MSE Loss is: 0.01826324313879013, h Loss is: 0.03507893532514572, L1 loss: 1.6280449628829956, Total Loss is: 0.05334217846393585\n",
            "MSE Loss is: 0.01780310459434986, h Loss is: 0.03704206272959709, L1 loss: 1.6296064853668213, Total Loss is: 0.0548451691865921\n",
            "MSE Loss is: 0.01739848032593727, h Loss is: 0.03910364210605621, L1 loss: 1.6319046020507812, Total Loss is: 0.056502122431993484\n",
            "MSE Loss is: 0.018314842134714127, h Loss is: 0.041257575154304504, L1 loss: 1.6341384649276733, Total Loss is: 0.05957241728901863\n",
            "MSE Loss is: 0.01784629002213478, h Loss is: 0.04353336617350578, L1 loss: 1.6362789869308472, Total Loss is: 0.061379656195640564\n",
            "MSE Loss is: 0.01742209494113922, h Loss is: 0.04588935524225235, L1 loss: 1.638311743736267, Total Loss is: 0.06331145018339157\n",
            "MSE Loss is: 0.017581216990947723, h Loss is: 0.04837251827120781, L1 loss: 1.6402019262313843, Total Loss is: 0.06595373153686523\n",
            "MSE Loss is: 0.017193304374814034, h Loss is: 0.050973739475011826, L1 loss: 1.6419658660888672, Total Loss is: 0.06816704571247101\n",
            "MSE Loss is: 0.01753462851047516, h Loss is: 0.05369587615132332, L1 loss: 1.6436538696289062, Total Loss is: 0.07123050093650818\n",
            "New h_val is : tf.Tensor(0.28886652, shape=(), dtype=float32)\n",
            "Epoch: {} 2\n",
            "MSE Loss is: 0.017579205334186554, h Loss is: 0.15240786969661713, L1 loss: 1.6452617645263672, Total Loss is: 0.16998708248138428\n",
            "MSE Loss is: 0.01734190806746483, h Loss is: 0.15841558575630188, L1 loss: 1.6468292474746704, Total Loss is: 0.175757497549057\n",
            "MSE Loss is: 0.017035096883773804, h Loss is: 0.16470226645469666, L1 loss: 1.6483650207519531, Total Loss is: 0.18173736333847046\n",
            "MSE Loss is: 0.017394304275512695, h Loss is: 0.17131298780441284, L1 loss: 1.6498454809188843, Total Loss is: 0.18870729207992554\n",
            "MSE Loss is: 0.016697969287633896, h Loss is: 0.17818784713745117, L1 loss: 1.651327133178711, Total Loss is: 0.19488582015037537\n",
            "MSE Loss is: 0.01732497103512287, h Loss is: 0.18536722660064697, L1 loss: 1.6528081893920898, Total Loss is: 0.2026921957731247\n",
            "MSE Loss is: 0.01680055819451809, h Loss is: 0.19285614788532257, L1 loss: 1.6541759967803955, Total Loss is: 0.2096567004919052\n",
            "MSE Loss is: 0.016290802508592606, h Loss is: 0.2006542682647705, L1 loss: 1.6554495096206665, Total Loss is: 0.21694506704807281\n",
            "MSE Loss is: 0.01652115024626255, h Loss is: 0.20868469774723053, L1 loss: 1.65663743019104, Total Loss is: 0.22520585358142853\n",
            "MSE Loss is: 0.01654662936925888, h Loss is: 0.21700379252433777, L1 loss: 1.65771484375, Total Loss is: 0.23355042934417725\n",
            "MSE Loss is: 0.016045626252889633, h Loss is: 0.22559858858585358, L1 loss: 1.6587101221084595, Total Loss is: 0.2416442185640335\n",
            "MSE Loss is: 0.01576543226838112, h Loss is: 0.23449435830116272, L1 loss: 1.6596378087997437, Total Loss is: 0.25025978684425354\n",
            "MSE Loss is: 0.016069766134023666, h Loss is: 0.24364371597766876, L1 loss: 1.660530686378479, Total Loss is: 0.25971347093582153\n",
            "MSE Loss is: 0.016047563403844833, h Loss is: 0.2531830072402954, L1 loss: 1.6614038944244385, Total Loss is: 0.26923057436943054\n",
            "MSE Loss is: 0.015665488317608833, h Loss is: 0.26316240429878235, L1 loss: 1.6622034311294556, Total Loss is: 0.2788279056549072\n",
            "MSE Loss is: 0.015604476444423199, h Loss is: 0.2737135589122772, L1 loss: 1.663346529006958, Total Loss is: 0.2893180251121521\n",
            "MSE Loss is: 0.016217153519392014, h Loss is: 0.28487998247146606, L1 loss: 1.6648151874542236, Total Loss is: 0.3010971248149872\n",
            "MSE Loss is: 0.01550412829965353, h Loss is: 0.2966461777687073, L1 loss: 1.6662975549697876, Total Loss is: 0.3121502995491028\n",
            "MSE Loss is: 0.014948241412639618, h Loss is: 0.308887243270874, L1 loss: 1.6676578521728516, Total Loss is: 0.32383549213409424\n",
            "MSE Loss is: 0.015438529662787914, h Loss is: 0.3216801881790161, L1 loss: 1.6689316034317017, Total Loss is: 0.3371187150478363\n",
            "MSE Loss is: 0.014893747866153717, h Loss is: 0.3348522186279297, L1 loss: 1.6700538396835327, Total Loss is: 0.3497459590435028\n",
            "MSE Loss is: 0.01525118574500084, h Loss is: 0.3484862446784973, L1 loss: 1.6710439920425415, Total Loss is: 0.36373743414878845\n",
            "MSE Loss is: 0.014474315568804741, h Loss is: 0.36253300309181213, L1 loss: 1.6719337701797485, Total Loss is: 0.37700730562210083\n",
            "MSE Loss is: 0.014667031355202198, h Loss is: 0.37698009610176086, L1 loss: 1.673038125038147, Total Loss is: 0.3916471302509308\n",
            "MSE Loss is: 0.014435186050832272, h Loss is: 0.3918137550354004, L1 loss: 1.6740556955337524, Total Loss is: 0.40624892711639404\n",
            "MSE Loss is: 0.014704961329698563, h Loss is: 0.40702229738235474, L1 loss: 1.6749054193496704, Total Loss is: 0.4217272698879242\n",
            "MSE Loss is: 0.013994245789945126, h Loss is: 0.42248740792274475, L1 loss: 1.675632119178772, Total Loss is: 0.43648165464401245\n",
            "MSE Loss is: 0.014375157654285431, h Loss is: 0.43854808807373047, L1 loss: 1.6763527393341064, Total Loss is: 0.4529232382774353\n",
            "MSE Loss is: 0.014114814810454845, h Loss is: 0.45497745275497437, L1 loss: 1.6769764423370361, Total Loss is: 0.4690922796726227\n",
            "MSE Loss is: 0.014206874184310436, h Loss is: 0.47183284163475037, L1 loss: 1.6775568723678589, Total Loss is: 0.4860397279262543\n",
            "MSE Loss is: 0.014050365425646305, h Loss is: 0.48956355452537537, L1 loss: 1.6780887842178345, Total Loss is: 0.5036139488220215\n",
            "MSE Loss is: 0.01361873745918274, h Loss is: 0.5076389312744141, L1 loss: 1.6784816980361938, Total Loss is: 0.5212576389312744\n",
            "MSE Loss is: 0.01342894695699215, h Loss is: 0.5260127782821655, L1 loss: 1.6788469552993774, Total Loss is: 0.539441704750061\n",
            "MSE Loss is: 0.013747291639447212, h Loss is: 0.544967532157898, L1 loss: 1.6793683767318726, Total Loss is: 0.5587148070335388\n",
            "MSE Loss is: 0.013395493850111961, h Loss is: 0.5650980472564697, L1 loss: 1.6798683404922485, Total Loss is: 0.5784935355186462\n",
            "MSE Loss is: 0.013245293870568275, h Loss is: 0.5860061645507812, L1 loss: 1.680246353149414, Total Loss is: 0.5992514491081238\n",
            "MSE Loss is: 0.012683121487498283, h Loss is: 0.607724666595459, L1 loss: 1.6804245710372925, Total Loss is: 0.62040776014328\n",
            "MSE Loss is: 0.013095665723085403, h Loss is: 0.6301630735397339, L1 loss: 1.6805610656738281, Total Loss is: 0.6432587504386902\n",
            "MSE Loss is: 0.013315990567207336, h Loss is: 0.6534753441810608, L1 loss: 1.680536150932312, Total Loss is: 0.6667913198471069\n",
            "MSE Loss is: 0.013114146888256073, h Loss is: 0.6773836016654968, L1 loss: 1.6803442239761353, Total Loss is: 0.6904977560043335\n",
            "MSE Loss is: 0.012462401762604713, h Loss is: 0.7015395164489746, L1 loss: 1.6799910068511963, Total Loss is: 0.7140018939971924\n",
            "MSE Loss is: 0.012413131073117256, h Loss is: 0.726069986820221, L1 loss: 1.6794666051864624, Total Loss is: 0.7384831309318542\n",
            "MSE Loss is: 0.011922745034098625, h Loss is: 0.7507205009460449, L1 loss: 1.6787570714950562, Total Loss is: 0.7626432180404663\n",
            "MSE Loss is: 0.012665743008255959, h Loss is: 0.7754645347595215, L1 loss: 1.6782087087631226, Total Loss is: 0.7881302833557129\n",
            "MSE Loss is: 0.012210057117044926, h Loss is: 0.8007241487503052, L1 loss: 1.6775696277618408, Total Loss is: 0.8129342198371887\n",
            "MSE Loss is: 0.011844859458506107, h Loss is: 0.825941264629364, L1 loss: 1.6768845319747925, Total Loss is: 0.8377861380577087\n",
            "MSE Loss is: 0.012119786813855171, h Loss is: 0.8519353270530701, L1 loss: 1.6763328313827515, Total Loss is: 0.8640550971031189\n",
            "MSE Loss is: 0.01187773048877716, h Loss is: 0.8784765601158142, L1 loss: 1.6760015487670898, Total Loss is: 0.8903542757034302\n",
            "MSE Loss is: 0.012054020538926125, h Loss is: 0.9054408073425293, L1 loss: 1.6759871244430542, Total Loss is: 0.9174948334693909\n",
            "New h_val is : tf.Tensor(1.009449, shape=(), dtype=float32)\n",
            "Epoch: {} 3\n",
            "MSE Loss is: 0.012141276150941849, h Loss is: 2.221205472946167, L1 loss: 1.6759766340255737, Total Loss is: 2.233346700668335\n",
            "MSE Loss is: 0.01197122409939766, h Loss is: 2.2743263244628906, L1 loss: 1.6759271621704102, Total Loss is: 2.286297559738159\n",
            "MSE Loss is: 0.011532154865562916, h Loss is: 2.3279531002044678, L1 loss: 1.675775170326233, Total Loss is: 2.3394851684570312\n",
            "MSE Loss is: 0.012162533588707447, h Loss is: 2.3827033042907715, L1 loss: 1.6754320859909058, Total Loss is: 2.3948657512664795\n",
            "MSE Loss is: 0.011539498344063759, h Loss is: 2.4370882511138916, L1 loss: 1.6748203039169312, Total Loss is: 2.4486277103424072\n",
            "MSE Loss is: 0.011917827650904655, h Loss is: 2.491297483444214, L1 loss: 1.6739625930786133, Total Loss is: 2.5032153129577637\n",
            "MSE Loss is: 0.0116381561383605, h Loss is: 2.5453178882598877, L1 loss: 1.6727646589279175, Total Loss is: 2.5569560527801514\n",
            "MSE Loss is: 0.011310175992548466, h Loss is: 2.599040985107422, L1 loss: 1.671308159828186, Total Loss is: 2.610351085662842\n",
            "MSE Loss is: 0.011322073638439178, h Loss is: 2.651494264602661, L1 loss: 1.6696516275405884, Total Loss is: 2.662816286087036\n",
            "MSE Loss is: 0.01142873615026474, h Loss is: 2.7035751342773438, L1 loss: 1.6678104400634766, Total Loss is: 2.7150039672851562\n",
            "MSE Loss is: 0.011074231937527657, h Loss is: 2.7546350955963135, L1 loss: 1.6658594608306885, Total Loss is: 2.765709400177002\n",
            "MSE Loss is: 0.010886592790484428, h Loss is: 2.8054494857788086, L1 loss: 1.6638622283935547, Total Loss is: 2.816336154937744\n",
            "MSE Loss is: 0.011095203459262848, h Loss is: 2.8558509349823, L1 loss: 1.661955714225769, Total Loss is: 2.866946220397949\n",
            "MSE Loss is: 0.011075885966420174, h Loss is: 2.9066288471221924, L1 loss: 1.6605786085128784, Total Loss is: 2.9177048206329346\n",
            "MSE Loss is: 0.01075934711843729, h Loss is: 2.957996368408203, L1 loss: 1.659234642982483, Total Loss is: 2.9687557220458984\n",
            "MSE Loss is: 0.010837294161319733, h Loss is: 3.0112311840057373, L1 loss: 1.657859206199646, Total Loss is: 3.022068500518799\n",
            "MSE Loss is: 0.01128669735044241, h Loss is: 3.065798282623291, L1 loss: 1.6564792394638062, Total Loss is: 3.077085018157959\n",
            "MSE Loss is: 0.010767829604446888, h Loss is: 3.120180130004883, L1 loss: 1.6549873352050781, Total Loss is: 3.130948066711426\n",
            "MSE Loss is: 0.010427146218717098, h Loss is: 3.1733806133270264, L1 loss: 1.6533492803573608, Total Loss is: 3.183807849884033\n",
            "MSE Loss is: 0.01094871573150158, h Loss is: 3.2256088256835938, L1 loss: 1.6517353057861328, Total Loss is: 3.2365574836730957\n",
            "MSE Loss is: 0.010592177510261536, h Loss is: 3.275184154510498, L1 loss: 1.6497341394424438, Total Loss is: 3.285776376724243\n",
            "MSE Loss is: 0.010873955674469471, h Loss is: 3.323004722595215, L1 loss: 1.647403597831726, Total Loss is: 3.333878755569458\n",
            "MSE Loss is: 0.010205513797700405, h Loss is: 3.3687877655029297, L1 loss: 1.6448545455932617, Total Loss is: 3.378993272781372\n",
            "MSE Loss is: 0.010493965819478035, h Loss is: 3.412627696990967, L1 loss: 1.6422070264816284, Total Loss is: 3.423121690750122\n",
            "MSE Loss is: 0.01045850571244955, h Loss is: 3.4547860622406006, L1 loss: 1.6396042108535767, Total Loss is: 3.4652445316314697\n",
            "MSE Loss is: 0.010645221918821335, h Loss is: 3.496034622192383, L1 loss: 1.6369160413742065, Total Loss is: 3.5066797733306885\n",
            "MSE Loss is: 0.00993974506855011, h Loss is: 3.535646915435791, L1 loss: 1.6341924667358398, Total Loss is: 3.545586585998535\n",
            "MSE Loss is: 0.010542531497776508, h Loss is: 3.5759544372558594, L1 loss: 1.631601333618164, Total Loss is: 3.5864970684051514\n",
            "MSE Loss is: 0.01030997559428215, h Loss is: 3.615072250366211, L1 loss: 1.6291583776474, Total Loss is: 3.6253821849823\n",
            "MSE Loss is: 0.010299699380993843, h Loss is: 3.6526713371276855, L1 loss: 1.6268701553344727, Total Loss is: 3.662971019744873\n",
            "MSE Loss is: 0.010296289809048176, h Loss is: 3.6917777061462402, L1 loss: 1.624714732170105, Total Loss is: 3.7020740509033203\n",
            "MSE Loss is: 0.010034658014774323, h Loss is: 3.728175640106201, L1 loss: 1.622260332107544, Total Loss is: 3.7382102012634277\n",
            "MSE Loss is: 0.010077291168272495, h Loss is: 3.762038230895996, L1 loss: 1.6195896863937378, Total Loss is: 3.772115468978882\n",
            "MSE Loss is: 0.01001091580837965, h Loss is: 3.7940821647644043, L1 loss: 1.616906762123108, Total Loss is: 3.8040931224823\n",
            "MSE Loss is: 0.009863540530204773, h Loss is: 3.82780385017395, L1 loss: 1.614466905593872, Total Loss is: 3.837667465209961\n",
            "MSE Loss is: 0.00979611836373806, h Loss is: 3.8612780570983887, L1 loss: 1.611697793006897, Total Loss is: 3.8710741996765137\n",
            "MSE Loss is: 0.009581243619322777, h Loss is: 3.893836498260498, L1 loss: 1.608748435974121, Total Loss is: 3.9034178256988525\n",
            "MSE Loss is: 0.009729181416332722, h Loss is: 3.9254705905914307, L1 loss: 1.6060333251953125, Total Loss is: 3.935199737548828\n",
            "MSE Loss is: 0.010135212913155556, h Loss is: 3.957298517227173, L1 loss: 1.6035164594650269, Total Loss is: 3.9674336910247803\n",
            "MSE Loss is: 0.009930849075317383, h Loss is: 3.987067699432373, L1 loss: 1.6011863946914673, Total Loss is: 3.9969985485076904\n",
            "MSE Loss is: 0.009384475648403168, h Loss is: 4.013646125793457, L1 loss: 1.5990320444107056, Total Loss is: 4.023030757904053\n",
            "MSE Loss is: 0.00946841761469841, h Loss is: 4.038296222686768, L1 loss: 1.5969136953353882, Total Loss is: 4.047764778137207\n",
            "MSE Loss is: 0.009189295582473278, h Loss is: 4.060237884521484, L1 loss: 1.594812035560608, Total Loss is: 4.069427013397217\n",
            "MSE Loss is: 0.009749017655849457, h Loss is: 4.080450057983398, L1 loss: 1.5926735401153564, Total Loss is: 4.090198993682861\n",
            "MSE Loss is: 0.00942414440214634, h Loss is: 4.100898742675781, L1 loss: 1.59033203125, Total Loss is: 4.110322952270508\n",
            "MSE Loss is: 0.009120417758822441, h Loss is: 4.119585037231445, L1 loss: 1.587805986404419, Total Loss is: 4.1287055015563965\n",
            "MSE Loss is: 0.009490065276622772, h Loss is: 4.140010356903076, L1 loss: 1.5854071378707886, Total Loss is: 4.149500370025635\n",
            "MSE Loss is: 0.009484926238656044, h Loss is: 4.160664081573486, L1 loss: 1.5831243991851807, Total Loss is: 4.170148849487305\n",
            "MSE Loss is: 0.009543515741825104, h Loss is: 4.1808905601501465, L1 loss: 1.5808416604995728, Total Loss is: 4.190433979034424\n",
            "New h_val is : tf.Tensor(1.6305981, shape=(), dtype=float32)\n",
            "Epoch: {} 4\n",
            "MSE Loss is: 0.009768868796527386, h Loss is: 7.899937629699707, L1 loss: 1.578682780265808, Total Loss is: 7.9097065925598145\n",
            "MSE Loss is: 0.009632948786020279, h Loss is: 7.933023452758789, L1 loss: 1.5769308805465698, Total Loss is: 7.942656517028809\n",
            "MSE Loss is: 0.009180046617984772, h Loss is: 7.962113857269287, L1 loss: 1.5752296447753906, Total Loss is: 7.971293926239014\n",
            "MSE Loss is: 0.010066873393952847, h Loss is: 7.990716934204102, L1 loss: 1.5733883380889893, Total Loss is: 8.000783920288086\n",
            "MSE Loss is: 0.009528227150440216, h Loss is: 8.014396667480469, L1 loss: 1.5712236166000366, Total Loss is: 8.023924827575684\n",
            "MSE Loss is: 0.009639249183237553, h Loss is: 8.034496307373047, L1 loss: 1.5688714981079102, Total Loss is: 8.044135093688965\n",
            "MSE Loss is: 0.009612513706088066, h Loss is: 8.05172061920166, L1 loss: 1.5662113428115845, Total Loss is: 8.061332702636719\n",
            "MSE Loss is: 0.00933825969696045, h Loss is: 8.067166328430176, L1 loss: 1.5634559392929077, Total Loss is: 8.076504707336426\n",
            "MSE Loss is: 0.009255102835595608, h Loss is: 8.079340934753418, L1 loss: 1.5606590509414673, Total Loss is: 8.08859634399414\n",
            "MSE Loss is: 0.009498072788119316, h Loss is: 8.092013359069824, L1 loss: 1.5578250885009766, Total Loss is: 8.101511001586914\n",
            "MSE Loss is: 0.009235951118171215, h Loss is: 8.102777481079102, L1 loss: 1.5550273656845093, Total Loss is: 8.112013816833496\n",
            "MSE Loss is: 0.00910700112581253, h Loss is: 8.114703178405762, L1 loss: 1.5523489713668823, Total Loss is: 8.123809814453125\n",
            "MSE Loss is: 0.009256620891392231, h Loss is: 8.12846851348877, L1 loss: 1.549744963645935, Total Loss is: 8.137724876403809\n",
            "MSE Loss is: 0.009258612059056759, h Loss is: 8.14350700378418, L1 loss: 1.547434687614441, Total Loss is: 8.152765274047852\n",
            "MSE Loss is: 0.008977657184004784, h Loss is: 8.158588409423828, L1 loss: 1.5453933477401733, Total Loss is: 8.167566299438477\n",
            "MSE Loss is: 0.00929116178303957, h Loss is: 8.177639961242676, L1 loss: 1.5434397459030151, Total Loss is: 8.186930656433105\n",
            "MSE Loss is: 0.009514538571238518, h Loss is: 8.198476791381836, L1 loss: 1.541621446609497, Total Loss is: 8.207991600036621\n",
            "MSE Loss is: 0.009164055809378624, h Loss is: 8.214035034179688, L1 loss: 1.5399125814437866, Total Loss is: 8.223198890686035\n",
            "MSE Loss is: 0.008947590366005898, h Loss is: 8.22474479675293, L1 loss: 1.5378726720809937, Total Loss is: 8.233692169189453\n",
            "MSE Loss is: 0.009482154622673988, h Loss is: 8.232280731201172, L1 loss: 1.5354253053665161, Total Loss is: 8.2417631149292\n",
            "MSE Loss is: 0.009278945624828339, h Loss is: 8.234579086303711, L1 loss: 1.532789707183838, Total Loss is: 8.243858337402344\n",
            "MSE Loss is: 0.009447870776057243, h Loss is: 8.235865592956543, L1 loss: 1.5299211740493774, Total Loss is: 8.24531364440918\n",
            "MSE Loss is: 0.008928835391998291, h Loss is: 8.237039566040039, L1 loss: 1.5270416736602783, Total Loss is: 8.24596881866455\n",
            "MSE Loss is: 0.00925672147423029, h Loss is: 8.23816204071045, L1 loss: 1.524393081665039, Total Loss is: 8.247418403625488\n",
            "MSE Loss is: 0.009213265031576157, h Loss is: 8.239786148071289, L1 loss: 1.5221229791641235, Total Loss is: 8.24899959564209\n",
            "MSE Loss is: 0.009360650554299355, h Loss is: 8.24365234375, L1 loss: 1.5199791193008423, Total Loss is: 8.253012657165527\n",
            "MSE Loss is: 0.008721317164599895, h Loss is: 8.246336936950684, L1 loss: 1.5179731845855713, Total Loss is: 8.255058288574219\n",
            "MSE Loss is: 0.009448938071727753, h Loss is: 8.2510986328125, L1 loss: 1.5162020921707153, Total Loss is: 8.260547637939453\n",
            "MSE Loss is: 0.00919342041015625, h Loss is: 8.253462791442871, L1 loss: 1.5147082805633545, Total Loss is: 8.262656211853027\n",
            "MSE Loss is: 0.009182455018162727, h Loss is: 8.251325607299805, L1 loss: 1.5132355690002441, Total Loss is: 8.26050853729248\n",
            "MSE Loss is: 0.00925355963408947, h Loss is: 8.251703262329102, L1 loss: 1.5118095874786377, Total Loss is: 8.260956764221191\n",
            "MSE Loss is: 0.009031920693814754, h Loss is: 8.246609687805176, L1 loss: 1.5096635818481445, Total Loss is: 8.25564193725586\n",
            "MSE Loss is: 0.009202351793646812, h Loss is: 8.238921165466309, L1 loss: 1.5070046186447144, Total Loss is: 8.248123168945312\n",
            "MSE Loss is: 0.009046018123626709, h Loss is: 8.229657173156738, L1 loss: 1.5043529272079468, Total Loss is: 8.238702774047852\n",
            "MSE Loss is: 0.008904501795768738, h Loss is: 8.22656536102295, L1 loss: 1.5019851922988892, Total Loss is: 8.235469818115234\n",
            "MSE Loss is: 0.008870603516697884, h Loss is: 8.22746753692627, L1 loss: 1.4993966817855835, Total Loss is: 8.23633861541748\n",
            "MSE Loss is: 0.008835891261696815, h Loss is: 8.228314399719238, L1 loss: 1.4969253540039062, Total Loss is: 8.237150192260742\n",
            "MSE Loss is: 0.008882570080459118, h Loss is: 8.230470657348633, L1 loss: 1.4948186874389648, Total Loss is: 8.23935317993164\n",
            "MSE Loss is: 0.00933757796883583, h Loss is: 8.235648155212402, L1 loss: 1.493182897567749, Total Loss is: 8.244985580444336\n",
            "MSE Loss is: 0.009110723622143269, h Loss is: 8.237142562866211, L1 loss: 1.4917268753051758, Total Loss is: 8.24625301361084\n",
            "MSE Loss is: 0.008666044101119041, h Loss is: 8.233469009399414, L1 loss: 1.4902681112289429, Total Loss is: 8.242135047912598\n",
            "MSE Loss is: 0.008686893619596958, h Loss is: 8.22764778137207, L1 loss: 1.4885050058364868, Total Loss is: 8.236334800720215\n",
            "MSE Loss is: 0.008573531173169613, h Loss is: 8.218121528625488, L1 loss: 1.4864161014556885, Total Loss is: 8.22669506072998\n",
            "MSE Loss is: 0.009017937816679478, h Loss is: 8.208244323730469, L1 loss: 1.4839171171188354, Total Loss is: 8.217262268066406\n",
            "MSE Loss is: 0.008750979788601398, h Loss is: 8.20266056060791, L1 loss: 1.4810688495635986, Total Loss is: 8.211411476135254\n",
            "MSE Loss is: 0.008497688919305801, h Loss is: 8.197381019592285, L1 loss: 1.4782174825668335, Total Loss is: 8.205878257751465\n",
            "MSE Loss is: 0.00887396838515997, h Loss is: 8.198330879211426, L1 loss: 1.4758808612823486, Total Loss is: 8.207204818725586\n",
            "MSE Loss is: 0.008911598473787308, h Loss is: 8.201261520385742, L1 loss: 1.4740842580795288, Total Loss is: 8.210172653198242\n",
            "MSE Loss is: 0.008953917771577835, h Loss is: 8.204118728637695, L1 loss: 1.4725699424743652, Total Loss is: 8.213072776794434\n",
            "New h_val is : tf.Tensor(1.6822071, shape=(), dtype=float32)\n",
            "Epoch: {} 5\n",
            "MSE Loss is: 0.009228922426700592, h Loss is: 12.538193702697754, L1 loss: 1.4713112115859985, Total Loss is: 12.547422409057617\n",
            "MSE Loss is: 0.009097275324165821, h Loss is: 12.541328430175781, L1 loss: 1.4701592922210693, Total Loss is: 12.55042552947998\n",
            "MSE Loss is: 0.008655337616801262, h Loss is: 12.536130905151367, L1 loss: 1.4687930345535278, Total Loss is: 12.54478645324707\n",
            "MSE Loss is: 0.009599038399755955, h Loss is: 12.530473709106445, L1 loss: 1.4669746160507202, Total Loss is: 12.540072441101074\n",
            "MSE Loss is: 0.009062707424163818, h Loss is: 12.519509315490723, L1 loss: 1.4645280838012695, Total Loss is: 12.528572082519531\n",
            "MSE Loss is: 0.009118997491896152, h Loss is: 12.50717544555664, L1 loss: 1.4617441892623901, Total Loss is: 12.516294479370117\n",
            "MSE Loss is: 0.00914853997528553, h Loss is: 12.495471000671387, L1 loss: 1.4586995840072632, Total Loss is: 12.504619598388672\n",
            "MSE Loss is: 0.008877957239747047, h Loss is: 12.48654842376709, L1 loss: 1.4557784795761108, Total Loss is: 12.495426177978516\n",
            "MSE Loss is: 0.008793806657195091, h Loss is: 12.477384567260742, L1 loss: 1.4531691074371338, Total Loss is: 12.486178398132324\n",
            "MSE Loss is: 0.009025093168020248, h Loss is: 12.473429679870605, L1 loss: 1.4508112668991089, Total Loss is: 12.482454299926758\n",
            "MSE Loss is: 0.008828937076032162, h Loss is: 12.468040466308594, L1 loss: 1.4486725330352783, Total Loss is: 12.476869583129883\n",
            "MSE Loss is: 0.008710945025086403, h Loss is: 12.464742660522461, L1 loss: 1.4466763734817505, Total Loss is: 12.473453521728516\n",
            "MSE Loss is: 0.008803550153970718, h Loss is: 12.464198112487793, L1 loss: 1.4446372985839844, Total Loss is: 12.473001480102539\n",
            "MSE Loss is: 0.008820148184895515, h Loss is: 12.46328353881836, L1 loss: 1.4427164793014526, Total Loss is: 12.4721040725708\n",
            "MSE Loss is: 0.008577702566981316, h Loss is: 12.459061622619629, L1 loss: 1.4408329725265503, Total Loss is: 12.467638969421387\n",
            "MSE Loss is: 0.008963890373706818, h Loss is: 12.460305213928223, L1 loss: 1.438776969909668, Total Loss is: 12.469268798828125\n",
            "MSE Loss is: 0.009114623069763184, h Loss is: 12.46486759185791, L1 loss: 1.4367188215255737, Total Loss is: 12.473981857299805\n",
            "MSE Loss is: 0.008791844360530376, h Loss is: 12.461012840270996, L1 loss: 1.4346998929977417, Total Loss is: 12.469804763793945\n",
            "MSE Loss is: 0.008593296632170677, h Loss is: 12.452725410461426, L1 loss: 1.4324458837509155, Total Loss is: 12.461318969726562\n",
            "MSE Loss is: 0.00914439931511879, h Loss is: 12.444158554077148, L1 loss: 1.4299728870391846, Total Loss is: 12.453303337097168\n",
            "MSE Loss is: 0.008978298865258694, h Loss is: 12.432758331298828, L1 loss: 1.4272159337997437, Total Loss is: 12.441736221313477\n",
            "MSE Loss is: 0.00908067636191845, h Loss is: 12.42512321472168, L1 loss: 1.424499750137329, Total Loss is: 12.4342041015625\n",
            "MSE Loss is: 0.008620207197964191, h Loss is: 12.421506881713867, L1 loss: 1.4220037460327148, Total Loss is: 12.430127143859863\n",
            "MSE Loss is: 0.008940298110246658, h Loss is: 12.419122695922852, L1 loss: 1.419844627380371, Total Loss is: 12.42806339263916\n",
            "MSE Loss is: 0.008853524923324585, h Loss is: 12.416692733764648, L1 loss: 1.4180176258087158, Total Loss is: 12.425546646118164\n",
            "MSE Loss is: 0.00905152503401041, h Loss is: 12.415597915649414, L1 loss: 1.4161157608032227, Total Loss is: 12.424649238586426\n",
            "MSE Loss is: 0.008401656523346901, h Loss is: 12.409140586853027, L1 loss: 1.414074182510376, Total Loss is: 12.417542457580566\n",
            "MSE Loss is: 0.009162139147520065, h Loss is: 12.402364730834961, L1 loss: 1.4120022058486938, Total Loss is: 12.411526679992676\n",
            "MSE Loss is: 0.008901461958885193, h Loss is: 12.390419960021973, L1 loss: 1.4098141193389893, Total Loss is: 12.399321556091309\n",
            "MSE Loss is: 0.008906376548111439, h Loss is: 12.37150764465332, L1 loss: 1.4076744318008423, Total Loss is: 12.380414009094238\n",
            "MSE Loss is: 0.008960522711277008, h Loss is: 12.358903884887695, L1 loss: 1.4057382345199585, Total Loss is: 12.367864608764648\n",
            "MSE Loss is: 0.00872618705034256, h Loss is: 12.341291427612305, L1 loss: 1.4032517671585083, Total Loss is: 12.350017547607422\n",
            "MSE Loss is: 0.008947782218456268, h Loss is: 12.323948860168457, L1 loss: 1.40046226978302, Total Loss is: 12.33289623260498\n",
            "MSE Loss is: 0.008799790404736996, h Loss is: 12.307299613952637, L1 loss: 1.3980950117111206, Total Loss is: 12.316099166870117\n",
            "MSE Loss is: 0.00862091314047575, h Loss is: 12.302619934082031, L1 loss: 1.3961561918258667, Total Loss is: 12.311241149902344\n",
            "MSE Loss is: 0.00861278735101223, h Loss is: 12.305506706237793, L1 loss: 1.3940362930297852, Total Loss is: 12.314119338989258\n",
            "MSE Loss is: 0.008606255985796452, h Loss is: 12.305868148803711, L1 loss: 1.3919315338134766, Total Loss is: 12.314474105834961\n",
            "MSE Loss is: 0.008632810786366463, h Loss is: 12.305407524108887, L1 loss: 1.3899673223495483, Total Loss is: 12.314040184020996\n",
            "MSE Loss is: 0.009102260693907738, h Loss is: 12.306941032409668, L1 loss: 1.3882083892822266, Total Loss is: 12.31604290008545\n",
            "MSE Loss is: 0.008859554305672646, h Loss is: 12.300039291381836, L1 loss: 1.3864917755126953, Total Loss is: 12.30889892578125\n",
            "MSE Loss is: 0.008453215472400188, h Loss is: 12.284461975097656, L1 loss: 1.3847684860229492, Total Loss is: 12.292915344238281\n",
            "MSE Loss is: 0.008430360816419125, h Loss is: 12.26703929901123, L1 loss: 1.3828201293945312, Total Loss is: 12.275469779968262\n",
            "MSE Loss is: 0.008369404822587967, h Loss is: 12.246896743774414, L1 loss: 1.380743384361267, Total Loss is: 12.255266189575195\n",
            "MSE Loss is: 0.00876834336668253, h Loss is: 12.230478286743164, L1 loss: 1.3785353899002075, Total Loss is: 12.239246368408203\n",
            "MSE Loss is: 0.008529426530003548, h Loss is: 12.225159645080566, L1 loss: 1.3762826919555664, Total Loss is: 12.233689308166504\n",
            "MSE Loss is: 0.008304500952363014, h Loss is: 12.221902847290039, L1 loss: 1.3741791248321533, Total Loss is: 12.230207443237305\n",
            "MSE Loss is: 0.008659210056066513, h Loss is: 12.228271484375, L1 loss: 1.3725064992904663, Total Loss is: 12.236930847167969\n",
            "MSE Loss is: 0.008707999251782894, h Loss is: 12.235221862792969, L1 loss: 1.3712395429611206, Total Loss is: 12.243929862976074\n",
            "MSE Loss is: 0.008717327378690243, h Loss is: 12.238161087036133, L1 loss: 1.3699886798858643, Total Loss is: 12.246878623962402\n",
            "New h_val is : tf.Tensor(1.6477122, shape=(), dtype=float32)\n",
            "Epoch: {} 6\n",
            "MSE Loss is: 0.009019064716994762, h Loss is: 16.809551239013672, L1 loss: 1.3687593936920166, Total Loss is: 16.818571090698242\n",
            "MSE Loss is: 0.0088999904692173, h Loss is: 16.804317474365234, L1 loss: 1.3674007654190063, Total Loss is: 16.813217163085938\n",
            "MSE Loss is: 0.008466944098472595, h Loss is: 16.785215377807617, L1 loss: 1.3657715320587158, Total Loss is: 16.793682098388672\n",
            "MSE Loss is: 0.009392280131578445, h Loss is: 16.766803741455078, L1 loss: 1.3637611865997314, Total Loss is: 16.776195526123047\n",
            "MSE Loss is: 0.00885133258998394, h Loss is: 16.745269775390625, L1 loss: 1.3613765239715576, Total Loss is: 16.754121780395508\n",
            "MSE Loss is: 0.008907496929168701, h Loss is: 16.727811813354492, L1 loss: 1.3590205907821655, Total Loss is: 16.736719131469727\n",
            "MSE Loss is: 0.00895458459854126, h Loss is: 16.715980529785156, L1 loss: 1.3567513227462769, Total Loss is: 16.72493553161621\n",
            "MSE Loss is: 0.008688532747328281, h Loss is: 16.71016502380371, L1 loss: 1.3547515869140625, Total Loss is: 16.718852996826172\n",
            "MSE Loss is: 0.008601553738117218, h Loss is: 16.702938079833984, L1 loss: 1.353058099746704, Total Loss is: 16.71154022216797\n",
            "MSE Loss is: 0.00882640015333891, h Loss is: 16.70050048828125, L1 loss: 1.35140860080719, Total Loss is: 16.709327697753906\n",
            "MSE Loss is: 0.008650447241961956, h Loss is: 16.690996170043945, L1 loss: 1.349664568901062, Total Loss is: 16.69964599609375\n",
            "MSE Loss is: 0.008538167923688889, h Loss is: 16.68042755126953, L1 loss: 1.3477351665496826, Total Loss is: 16.68896484375\n",
            "MSE Loss is: 0.008602609857916832, h Loss is: 16.67119026184082, L1 loss: 1.3455575704574585, Total Loss is: 16.679792404174805\n",
            "MSE Loss is: 0.00862928107380867, h Loss is: 16.660579681396484, L1 loss: 1.3434706926345825, Total Loss is: 16.669208526611328\n",
            "MSE Loss is: 0.008404236286878586, h Loss is: 16.645883560180664, L1 loss: 1.341528058052063, Total Loss is: 16.654287338256836\n",
            "MSE Loss is: 0.008806951344013214, h Loss is: 16.64273452758789, L1 loss: 1.3396892547607422, Total Loss is: 16.651540756225586\n",
            "MSE Loss is: 0.008931169286370277, h Loss is: 16.647838592529297, L1 loss: 1.3380440473556519, Total Loss is: 16.656770706176758\n",
            "MSE Loss is: 0.008613944984972477, h Loss is: 16.642147064208984, L1 loss: 1.3367300033569336, Total Loss is: 16.650760650634766\n",
            "MSE Loss is: 0.00842526275664568, h Loss is: 16.63080596923828, L1 loss: 1.3353261947631836, Total Loss is: 16.639230728149414\n",
            "MSE Loss is: 0.00898097362369299, h Loss is: 16.619226455688477, L1 loss: 1.3336724042892456, Total Loss is: 16.62820816040039\n",
            "MSE Loss is: 0.008821413852274418, h Loss is: 16.60320472717285, L1 loss: 1.3315811157226562, Total Loss is: 16.61202621459961\n",
            "MSE Loss is: 0.008899662643671036, h Loss is: 16.592065811157227, L1 loss: 1.3293626308441162, Total Loss is: 16.60096549987793\n",
            "MSE Loss is: 0.008461853489279747, h Loss is: 16.586254119873047, L1 loss: 1.3272182941436768, Total Loss is: 16.594715118408203\n",
            "MSE Loss is: 0.008765868842601776, h Loss is: 16.581092834472656, L1 loss: 1.325307846069336, Total Loss is: 16.589859008789062\n",
            "MSE Loss is: 0.008659161627292633, h Loss is: 16.574542999267578, L1 loss: 1.3237167596817017, Total Loss is: 16.583202362060547\n",
            "MSE Loss is: 0.008891184814274311, h Loss is: 16.568872451782227, L1 loss: 1.3220996856689453, Total Loss is: 16.5777645111084\n",
            "MSE Loss is: 0.008241682313382626, h Loss is: 16.55425262451172, L1 loss: 1.3205126523971558, Total Loss is: 16.5624942779541\n",
            "MSE Loss is: 0.008999300189316273, h Loss is: 16.538053512573242, L1 loss: 1.3189505338668823, Total Loss is: 16.54705238342285\n",
            "MSE Loss is: 0.008749607019126415, h Loss is: 16.515159606933594, L1 loss: 1.3173705339431763, Total Loss is: 16.523908615112305\n",
            "MSE Loss is: 0.008756276220083237, h Loss is: 16.483888626098633, L1 loss: 1.3159258365631104, Total Loss is: 16.492645263671875\n",
            "MSE Loss is: 0.008801184594631195, h Loss is: 16.46353530883789, L1 loss: 1.3144264221191406, Total Loss is: 16.472335815429688\n",
            "MSE Loss is: 0.008546599186956882, h Loss is: 16.43767547607422, L1 loss: 1.312585473060608, Total Loss is: 16.44622230529785\n",
            "MSE Loss is: 0.008793268352746964, h Loss is: 16.41252326965332, L1 loss: 1.310463786125183, Total Loss is: 16.421316146850586\n",
            "MSE Loss is: 0.00864709634333849, h Loss is: 16.38772964477539, L1 loss: 1.308584451675415, Total Loss is: 16.396377563476562\n",
            "MSE Loss is: 0.008456436917185783, h Loss is: 16.378944396972656, L1 loss: 1.3068767786026, Total Loss is: 16.387401580810547\n",
            "MSE Loss is: 0.00846218690276146, h Loss is: 16.379966735839844, L1 loss: 1.3050339221954346, Total Loss is: 16.388429641723633\n",
            "MSE Loss is: 0.008456775918602943, h Loss is: 16.374055862426758, L1 loss: 1.3033736944198608, Total Loss is: 16.38251304626465\n",
            "MSE Loss is: 0.008489459753036499, h Loss is: 16.364091873168945, L1 loss: 1.3018600940704346, Total Loss is: 16.372581481933594\n",
            "MSE Loss is: 0.008954249322414398, h Loss is: 16.35529899597168, L1 loss: 1.3004467487335205, Total Loss is: 16.364253997802734\n",
            "MSE Loss is: 0.008708663284778595, h Loss is: 16.33481216430664, L1 loss: 1.2992194890975952, Total Loss is: 16.343521118164062\n",
            "MSE Loss is: 0.008317533880472183, h Loss is: 16.304048538208008, L1 loss: 1.2980175018310547, Total Loss is: 16.312366485595703\n",
            "MSE Loss is: 0.008276883512735367, h Loss is: 16.274112701416016, L1 loss: 1.2964709997177124, Total Loss is: 16.28238868713379\n",
            "MSE Loss is: 0.008234480395913124, h Loss is: 16.244359970092773, L1 loss: 1.2948317527770996, Total Loss is: 16.252593994140625\n",
            "MSE Loss is: 0.008614545688033104, h Loss is: 16.223421096801758, L1 loss: 1.2931435108184814, Total Loss is: 16.232036590576172\n",
            "MSE Loss is: 0.00838940404355526, h Loss is: 16.220014572143555, L1 loss: 1.2914785146713257, Total Loss is: 16.228403091430664\n",
            "MSE Loss is: 0.008175034075975418, h Loss is: 16.21678924560547, L1 loss: 1.2899348735809326, Total Loss is: 16.224964141845703\n",
            "MSE Loss is: 0.008519861847162247, h Loss is: 16.222646713256836, L1 loss: 1.2886772155761719, Total Loss is: 16.23116683959961\n",
            "MSE Loss is: 0.008575042709708214, h Loss is: 16.223655700683594, L1 loss: 1.2877540588378906, Total Loss is: 16.23223114013672\n",
            "MSE Loss is: 0.00856153666973114, h Loss is: 16.2143497467041, L1 loss: 1.2867473363876343, Total Loss is: 16.222911834716797\n",
            "New h_val is : tf.Tensor(1.594768, shape=(), dtype=float32)\n",
            "Epoch: {} 7\n",
            "MSE Loss is: 0.008882803842425346, h Loss is: 20.910654067993164, L1 loss: 1.2856963872909546, Total Loss is: 20.919536590576172\n",
            "MSE Loss is: 0.008765920996665955, h Loss is: 20.88645362854004, L1 loss: 1.2845453023910522, Total Loss is: 20.895219802856445\n",
            "MSE Loss is: 0.008338527753949165, h Loss is: 20.848201751708984, L1 loss: 1.2832587957382202, Total Loss is: 20.85654067993164\n",
            "MSE Loss is: 0.009242618456482887, h Loss is: 20.816864013671875, L1 loss: 1.2816312313079834, Total Loss is: 20.826107025146484\n",
            "MSE Loss is: 0.008708808571100235, h Loss is: 20.787872314453125, L1 loss: 1.2799335718154907, Total Loss is: 20.796581268310547\n",
            "MSE Loss is: 0.008771459572017193, h Loss is: 20.768726348876953, L1 loss: 1.2784208059310913, Total Loss is: 20.777498245239258\n",
            "MSE Loss is: 0.008822722360491753, h Loss is: 20.75666618347168, L1 loss: 1.2769427299499512, Total Loss is: 20.76548957824707\n",
            "MSE Loss is: 0.008556943386793137, h Loss is: 20.747404098510742, L1 loss: 1.2754806280136108, Total Loss is: 20.75596046447754\n",
            "MSE Loss is: 0.008471589535474777, h Loss is: 20.728830337524414, L1 loss: 1.2740992307662964, Total Loss is: 20.737302780151367\n",
            "MSE Loss is: 0.008699143305420876, h Loss is: 20.71053123474121, L1 loss: 1.2726844549179077, Total Loss is: 20.71923065185547\n",
            "MSE Loss is: 0.008537712506949902, h Loss is: 20.678600311279297, L1 loss: 1.2710907459259033, Total Loss is: 20.687137603759766\n",
            "MSE Loss is: 0.008416572585701942, h Loss is: 20.64580535888672, L1 loss: 1.2694053649902344, Total Loss is: 20.65422248840332\n",
            "MSE Loss is: 0.008473331108689308, h Loss is: 20.618610382080078, L1 loss: 1.2678302526474, Total Loss is: 20.62708282470703\n",
            "MSE Loss is: 0.008508814498782158, h Loss is: 20.595008850097656, L1 loss: 1.2664964199066162, Total Loss is: 20.603517532348633\n",
            "MSE Loss is: 0.008288604207336903, h Loss is: 20.5704288482666, L1 loss: 1.265236258506775, Total Loss is: 20.578718185424805\n",
            "MSE Loss is: 0.008697505109012127, h Loss is: 20.565353393554688, L1 loss: 1.2641801834106445, Total Loss is: 20.574050903320312\n",
            "MSE Loss is: 0.00880352407693863, h Loss is: 20.5711669921875, L1 loss: 1.2631555795669556, Total Loss is: 20.579971313476562\n",
            "MSE Loss is: 0.008502916432917118, h Loss is: 20.558155059814453, L1 loss: 1.2620296478271484, Total Loss is: 20.56665802001953\n",
            "MSE Loss is: 0.008317869156599045, h Loss is: 20.532623291015625, L1 loss: 1.2606950998306274, Total Loss is: 20.54094123840332\n",
            "MSE Loss is: 0.008871182799339294, h Loss is: 20.503883361816406, L1 loss: 1.2591521739959717, Total Loss is: 20.512754440307617\n",
            "MSE Loss is: 0.008711181581020355, h Loss is: 20.46930694580078, L1 loss: 1.2574115991592407, Total Loss is: 20.478017807006836\n",
            "MSE Loss is: 0.00878126360476017, h Loss is: 20.44408416748047, L1 loss: 1.2558088302612305, Total Loss is: 20.452865600585938\n",
            "MSE Loss is: 0.008362327702343464, h Loss is: 20.429872512817383, L1 loss: 1.2546871900558472, Total Loss is: 20.438234329223633\n",
            "MSE Loss is: 0.00865123700350523, h Loss is: 20.419179916381836, L1 loss: 1.2538353204727173, Total Loss is: 20.427831649780273\n",
            "MSE Loss is: 0.008526679128408432, h Loss is: 20.40697479248047, L1 loss: 1.2531113624572754, Total Loss is: 20.41550064086914\n",
            "MSE Loss is: 0.00878172554075718, h Loss is: 20.394235610961914, L1 loss: 1.2521876096725464, Total Loss is: 20.403017044067383\n",
            "MSE Loss is: 0.008135046809911728, h Loss is: 20.36627960205078, L1 loss: 1.2509793043136597, Total Loss is: 20.374414443969727\n",
            "MSE Loss is: 0.008887844160199165, h Loss is: 20.332813262939453, L1 loss: 1.249389886856079, Total Loss is: 20.34170150756836\n",
            "MSE Loss is: 0.00865187682211399, h Loss is: 20.290342330932617, L1 loss: 1.2477401494979858, Total Loss is: 20.298994064331055\n",
            "MSE Loss is: 0.008651826530694962, h Loss is: 20.23923683166504, L1 loss: 1.2463840246200562, Total Loss is: 20.247888565063477\n",
            "MSE Loss is: 0.00869068969041109, h Loss is: 20.205888748168945, L1 loss: 1.2453075647354126, Total Loss is: 20.21457862854004\n",
            "MSE Loss is: 0.008413819596171379, h Loss is: 20.16851806640625, L1 loss: 1.244350790977478, Total Loss is: 20.176931381225586\n",
            "MSE Loss is: 0.008690420538187027, h Loss is: 20.13250732421875, L1 loss: 1.2436026334762573, Total Loss is: 20.141197204589844\n",
            "MSE Loss is: 0.008541506715118885, h Loss is: 20.095441818237305, L1 loss: 1.242932915687561, Total Loss is: 20.10398292541504\n",
            "MSE Loss is: 0.008344215340912342, h Loss is: 20.076915740966797, L1 loss: 1.2418372631072998, Total Loss is: 20.08526039123535\n",
            "MSE Loss is: 0.008354932069778442, h Loss is: 20.069232940673828, L1 loss: 1.2404526472091675, Total Loss is: 20.077587127685547\n",
            "MSE Loss is: 0.008349994197487831, h Loss is: 20.04848861694336, L1 loss: 1.2386794090270996, Total Loss is: 20.056838989257812\n",
            "MSE Loss is: 0.008395059034228325, h Loss is: 20.020401000976562, L1 loss: 1.2370332479476929, Total Loss is: 20.02879524230957\n",
            "MSE Loss is: 0.00884921196848154, h Loss is: 19.994340896606445, L1 loss: 1.2357171773910522, Total Loss is: 20.003190994262695\n",
            "MSE Loss is: 0.00860130600631237, h Loss is: 19.9566650390625, L1 loss: 1.23477041721344, Total Loss is: 19.965267181396484\n",
            "MSE Loss is: 0.00821492075920105, h Loss is: 19.910085678100586, L1 loss: 1.2343555688858032, Total Loss is: 19.91830062866211\n",
            "MSE Loss is: 0.00817177165299654, h Loss is: 19.86901092529297, L1 loss: 1.2338634729385376, Total Loss is: 19.877182006835938\n",
            "MSE Loss is: 0.008138308301568031, h Loss is: 19.831134796142578, L1 loss: 1.2332292795181274, Total Loss is: 19.83927345275879\n",
            "MSE Loss is: 0.008506269194185734, h Loss is: 19.805301666259766, L1 loss: 1.2324720621109009, Total Loss is: 19.81380844116211\n",
            "MSE Loss is: 0.008288133889436722, h Loss is: 19.80031967163086, L1 loss: 1.2315081357955933, Total Loss is: 19.80860710144043\n",
            "MSE Loss is: 0.008078489452600479, h Loss is: 19.7891902923584, L1 loss: 1.2305586338043213, Total Loss is: 19.79726791381836\n",
            "MSE Loss is: 0.00842188484966755, h Loss is: 19.78366470336914, L1 loss: 1.229578971862793, Total Loss is: 19.792085647583008\n",
            "MSE Loss is: 0.008481775410473347, h Loss is: 19.767681121826172, L1 loss: 1.2288001775741577, Total Loss is: 19.77616310119629\n",
            "MSE Loss is: 0.00845000147819519, h Loss is: 19.738027572631836, L1 loss: 1.2281192541122437, Total Loss is: 19.746477127075195\n",
            "New h_val is : tf.Tensor(1.5115032, shape=(), dtype=float32)\n",
            "Epoch: {} 8\n",
            "MSE Loss is: 0.008783839643001556, h Loss is: 24.360546112060547, L1 loss: 1.2276531457901, Total Loss is: 24.36932945251465\n",
            "MSE Loss is: 0.008668431080877781, h Loss is: 24.321414947509766, L1 loss: 1.2272361516952515, Total Loss is: 24.3300838470459\n",
            "MSE Loss is: 0.008248323574662209, h Loss is: 24.27246856689453, L1 loss: 1.226717233657837, Total Loss is: 24.280715942382812\n",
            "MSE Loss is: 0.009138211607933044, h Loss is: 24.236434936523438, L1 loss: 1.2258843183517456, Total Loss is: 24.245573043823242\n",
            "MSE Loss is: 0.008604852482676506, h Loss is: 24.203998565673828, L1 loss: 1.2249144315719604, Total Loss is: 24.212602615356445\n",
            "MSE Loss is: 0.008674463257193565, h Loss is: 24.180492401123047, L1 loss: 1.224004864692688, Total Loss is: 24.189167022705078\n",
            "MSE Loss is: 0.008722019381821156, h Loss is: 24.158498764038086, L1 loss: 1.223052978515625, Total Loss is: 24.167221069335938\n",
            "MSE Loss is: 0.008464343845844269, h Loss is: 24.131187438964844, L1 loss: 1.2221381664276123, Total Loss is: 24.139652252197266\n",
            "MSE Loss is: 0.008381392806768417, h Loss is: 24.08662986755371, L1 loss: 1.2213709354400635, Total Loss is: 24.09501075744629\n",
            "MSE Loss is: 0.008607835508883, h Loss is: 24.04278564453125, L1 loss: 1.2205215692520142, Total Loss is: 24.051393508911133\n",
            "MSE Loss is: 0.008456342853605747, h Loss is: 23.986650466918945, L1 loss: 1.2195134162902832, Total Loss is: 23.995107650756836\n",
            "MSE Loss is: 0.008324422873556614, h Loss is: 23.9376163482666, L1 loss: 1.2185194492340088, Total Loss is: 23.945940017700195\n",
            "MSE Loss is: 0.008385123685002327, h Loss is: 23.902713775634766, L1 loss: 1.2175800800323486, Total Loss is: 23.91109848022461\n",
            "MSE Loss is: 0.008422632701694965, h Loss is: 23.875656127929688, L1 loss: 1.2168139219284058, Total Loss is: 23.884078979492188\n",
            "MSE Loss is: 0.008204192854464054, h Loss is: 23.845266342163086, L1 loss: 1.2159785032272339, Total Loss is: 23.853469848632812\n",
            "MSE Loss is: 0.008612776175141335, h Loss is: 23.835256576538086, L1 loss: 1.215201735496521, Total Loss is: 23.843870162963867\n",
            "MSE Loss is: 0.008715750649571419, h Loss is: 23.831829071044922, L1 loss: 1.2144230604171753, Total Loss is: 23.840545654296875\n",
            "MSE Loss is: 0.008427459746599197, h Loss is: 23.797746658325195, L1 loss: 1.2136069536209106, Total Loss is: 23.80617332458496\n",
            "MSE Loss is: 0.008237780071794987, h Loss is: 23.745792388916016, L1 loss: 1.2126654386520386, Total Loss is: 23.754030227661133\n",
            "MSE Loss is: 0.008784720674157143, h Loss is: 23.694292068481445, L1 loss: 1.2115439176559448, Total Loss is: 23.70307731628418\n",
            "MSE Loss is: 0.008633732795715332, h Loss is: 23.64403533935547, L1 loss: 1.2103042602539062, Total Loss is: 23.65266990661621\n",
            "MSE Loss is: 0.00870151724666357, h Loss is: 23.61418342590332, L1 loss: 1.2093896865844727, Total Loss is: 23.62288475036621\n",
            "MSE Loss is: 0.008291893638670444, h Loss is: 23.602678298950195, L1 loss: 1.208886742591858, Total Loss is: 23.61096954345703\n",
            "MSE Loss is: 0.00856402050703764, h Loss is: 23.593578338623047, L1 loss: 1.2085933685302734, Total Loss is: 23.602142333984375\n",
            "MSE Loss is: 0.008430268615484238, h Loss is: 23.575305938720703, L1 loss: 1.2082258462905884, Total Loss is: 23.583736419677734\n",
            "MSE Loss is: 0.008711780421435833, h Loss is: 23.547969818115234, L1 loss: 1.2073960304260254, Total Loss is: 23.55668067932129\n",
            "MSE Loss is: 0.00805606134235859, h Loss is: 23.495555877685547, L1 loss: 1.2061920166015625, Total Loss is: 23.503612518310547\n",
            "MSE Loss is: 0.008805673569440842, h Loss is: 23.43532943725586, L1 loss: 1.2046616077423096, Total Loss is: 23.444135665893555\n",
            "MSE Loss is: 0.008584216237068176, h Loss is: 23.370141983032227, L1 loss: 1.203330636024475, Total Loss is: 23.378726959228516\n",
            "MSE Loss is: 0.008582504466176033, h Loss is: 23.30369758605957, L1 loss: 1.2026304006576538, Total Loss is: 23.312280654907227\n",
            "MSE Loss is: 0.008608715608716011, h Loss is: 23.266803741455078, L1 loss: 1.2022517919540405, Total Loss is: 23.27541160583496\n",
            "MSE Loss is: 0.008320593275129795, h Loss is: 23.22748565673828, L1 loss: 1.2016609907150269, Total Loss is: 23.23580551147461\n",
            "MSE Loss is: 0.008612271398305893, h Loss is: 23.185237884521484, L1 loss: 1.2009116411209106, Total Loss is: 23.193849563598633\n",
            "MSE Loss is: 0.008453689515590668, h Loss is: 23.133920669555664, L1 loss: 1.2000757455825806, Total Loss is: 23.14237403869629\n",
            "MSE Loss is: 0.008263868279755116, h Loss is: 23.098590850830078, L1 loss: 1.1988003253936768, Total Loss is: 23.106855392456055\n",
            "MSE Loss is: 0.008279196918010712, h Loss is: 23.07455825805664, L1 loss: 1.1971113681793213, Total Loss is: 23.08283805847168\n",
            "MSE Loss is: 0.008273988962173462, h Loss is: 23.03368377685547, L1 loss: 1.1953184604644775, Total Loss is: 23.04195785522461\n",
            "MSE Loss is: 0.008329380303621292, h Loss is: 22.986997604370117, L1 loss: 1.194060206413269, Total Loss is: 22.99532699584961\n",
            "MSE Loss is: 0.00877193734049797, h Loss is: 22.948083877563477, L1 loss: 1.1934711933135986, Total Loss is: 22.95685577392578\n",
            "MSE Loss is: 0.00852123647928238, h Loss is: 22.90096664428711, L1 loss: 1.1933516263961792, Total Loss is: 22.909488677978516\n",
            "MSE Loss is: 0.008144007995724678, h Loss is: 22.846118927001953, L1 loss: 1.193558931350708, Total Loss is: 22.854263305664062\n",
            "MSE Loss is: 0.008097803220152855, h Loss is: 22.798418045043945, L1 loss: 1.1931965351104736, Total Loss is: 22.806516647338867\n",
            "MSE Loss is: 0.008067475631833076, h Loss is: 22.75284194946289, L1 loss: 1.1923259496688843, Total Loss is: 22.760910034179688\n",
            "MSE Loss is: 0.008425630629062653, h Loss is: 22.719039916992188, L1 loss: 1.1911998987197876, Total Loss is: 22.72746467590332\n",
            "MSE Loss is: 0.008216768503189087, h Loss is: 22.7078914642334, L1 loss: 1.190019965171814, Total Loss is: 22.716108322143555\n",
            "MSE Loss is: 0.008015312254428864, h Loss is: 22.683935165405273, L1 loss: 1.1893342733383179, Total Loss is: 22.69194984436035\n",
            "MSE Loss is: 0.008354684337973595, h Loss is: 22.664085388183594, L1 loss: 1.1890513896942139, Total Loss is: 22.672439575195312\n",
            "MSE Loss is: 0.00841381587088108, h Loss is: 22.63161277770996, L1 loss: 1.1892412900924683, Total Loss is: 22.640026092529297\n",
            "MSE Loss is: 0.008365124464035034, h Loss is: 22.585920333862305, L1 loss: 1.1892808675765991, Total Loss is: 22.59428596496582\n",
            "New h_val is : tf.Tensor(1.4076271, shape=(), dtype=float32)\n",
            "Epoch: {} 9\n",
            "MSE Loss is: 0.008713996969163418, h Loss is: 26.98276138305664, L1 loss: 1.1892321109771729, Total Loss is: 26.99147605895996\n",
            "MSE Loss is: 0.00860201008617878, h Loss is: 26.937944412231445, L1 loss: 1.188801646232605, Total Loss is: 26.94654655456543\n",
            "MSE Loss is: 0.008184642530977726, h Loss is: 26.88534927368164, L1 loss: 1.1880191564559937, Total Loss is: 26.89353370666504\n",
            "MSE Loss is: 0.00906342826783657, h Loss is: 26.847076416015625, L1 loss: 1.186867117881775, Total Loss is: 26.85614013671875\n",
            "MSE Loss is: 0.008527616038918495, h Loss is: 26.809118270874023, L1 loss: 1.1857941150665283, Total Loss is: 26.817646026611328\n",
            "MSE Loss is: 0.008606506511569023, h Loss is: 26.775815963745117, L1 loss: 1.1850929260253906, Total Loss is: 26.784421920776367\n",
            "MSE Loss is: 0.008648782968521118, h Loss is: 26.73772430419922, L1 loss: 1.1846164464950562, Total Loss is: 26.74637222290039\n",
            "MSE Loss is: 0.008397698402404785, h Loss is: 26.688175201416016, L1 loss: 1.1843823194503784, Total Loss is: 26.69657325744629\n",
            "MSE Loss is: 0.008316399529576302, h Loss is: 26.618141174316406, L1 loss: 1.1843105554580688, Total Loss is: 26.62645721435547\n",
            "MSE Loss is: 0.008541072718799114, h Loss is: 26.5551700592041, L1 loss: 1.1839402914047241, Total Loss is: 26.563711166381836\n",
            "MSE Loss is: 0.008398794569075108, h Loss is: 26.485843658447266, L1 loss: 1.183023452758789, Total Loss is: 26.49424171447754\n",
            "MSE Loss is: 0.008258702233433723, h Loss is: 26.432697296142578, L1 loss: 1.1818207502365112, Total Loss is: 26.440956115722656\n",
            "MSE Loss is: 0.00832252949476242, h Loss is: 26.398880004882812, L1 loss: 1.1808056831359863, Total Loss is: 26.407201766967773\n",
            "MSE Loss is: 0.008353947661817074, h Loss is: 26.370590209960938, L1 loss: 1.1803251504898071, Total Loss is: 26.378944396972656\n",
            "MSE Loss is: 0.008141768164932728, h Loss is: 26.329500198364258, L1 loss: 1.1801077127456665, Total Loss is: 26.337642669677734\n",
            "MSE Loss is: 0.0085520651191473, h Loss is: 26.30562400817871, L1 loss: 1.1799489259719849, Total Loss is: 26.314176559448242\n",
            "MSE Loss is: 0.008652969263494015, h Loss is: 26.284347534179688, L1 loss: 1.1799824237823486, Total Loss is: 26.293001174926758\n",
            "MSE Loss is: 0.008369218558073044, h Loss is: 26.225812911987305, L1 loss: 1.1798529624938965, Total Loss is: 26.234182357788086\n",
            "MSE Loss is: 0.008175058290362358, h Loss is: 26.151935577392578, L1 loss: 1.1794012784957886, Total Loss is: 26.160110473632812\n",
            "MSE Loss is: 0.00872115883976221, h Loss is: 26.090152740478516, L1 loss: 1.1784404516220093, Total Loss is: 26.098873138427734\n",
            "MSE Loss is: 0.008581940084695816, h Loss is: 26.04030418395996, L1 loss: 1.177342414855957, Total Loss is: 26.048885345458984\n",
            "MSE Loss is: 0.008642597123980522, h Loss is: 26.019065856933594, L1 loss: 1.1766434907913208, Total Loss is: 26.027708053588867\n",
            "MSE Loss is: 0.00823383592069149, h Loss is: 26.015060424804688, L1 loss: 1.1766554117202759, Total Loss is: 26.02329444885254\n",
            "MSE Loss is: 0.008499366231262684, h Loss is: 26.00204849243164, L1 loss: 1.176958680152893, Total Loss is: 26.010547637939453\n",
            "MSE Loss is: 0.00836210511624813, h Loss is: 25.965347290039062, L1 loss: 1.1772130727767944, Total Loss is: 25.973709106445312\n",
            "MSE Loss is: 0.008660264313220978, h Loss is: 25.911439895629883, L1 loss: 1.176815390586853, Total Loss is: 25.92009925842285\n",
            "MSE Loss is: 0.007997228763997555, h Loss is: 25.830318450927734, L1 loss: 1.1760342121124268, Total Loss is: 25.838315963745117\n",
            "MSE Loss is: 0.008744949474930763, h Loss is: 25.750473022460938, L1 loss: 1.1750462055206299, Total Loss is: 25.759218215942383\n",
            "MSE Loss is: 0.008536836132407188, h Loss is: 25.67927360534668, L1 loss: 1.1745067834854126, Total Loss is: 25.68781089782715\n",
            "MSE Loss is: 0.00853105541318655, h Loss is: 25.617204666137695, L1 loss: 1.17461097240448, Total Loss is: 25.625736236572266\n",
            "MSE Loss is: 0.008555220440030098, h Loss is: 25.590410232543945, L1 loss: 1.1750186681747437, Total Loss is: 25.59896469116211\n",
            "MSE Loss is: 0.00826115533709526, h Loss is: 25.551673889160156, L1 loss: 1.1746515035629272, Total Loss is: 25.559934616088867\n",
            "MSE Loss is: 0.00855467189103365, h Loss is: 25.49447250366211, L1 loss: 1.1740902662277222, Total Loss is: 25.503026962280273\n",
            "MSE Loss is: 0.008387506008148193, h Loss is: 25.41497802734375, L1 loss: 1.1735891103744507, Total Loss is: 25.423364639282227\n",
            "MSE Loss is: 0.008201606571674347, h Loss is: 25.352760314941406, L1 loss: 1.172825574874878, Total Loss is: 25.3609619140625\n",
            "MSE Loss is: 0.008224998600780964, h Loss is: 25.312702178955078, L1 loss: 1.1714986562728882, Total Loss is: 25.320926666259766\n",
            "MSE Loss is: 0.00821642018854618, h Loss is: 25.262813568115234, L1 loss: 1.1702221632003784, Total Loss is: 25.27103042602539\n",
            "MSE Loss is: 0.008283933624625206, h Loss is: 25.21453285217285, L1 loss: 1.1697717905044556, Total Loss is: 25.222816467285156\n",
            "MSE Loss is: 0.008712248876690865, h Loss is: 25.17816734313965, L1 loss: 1.170166254043579, Total Loss is: 25.186880111694336\n",
            "MSE Loss is: 0.008467523381114006, h Loss is: 25.13007354736328, L1 loss: 1.1707110404968262, Total Loss is: 25.138540267944336\n",
            "MSE Loss is: 0.008088938891887665, h Loss is: 25.066362380981445, L1 loss: 1.1713711023330688, Total Loss is: 25.074451446533203\n",
            "MSE Loss is: 0.008040773682296276, h Loss is: 25.005231857299805, L1 loss: 1.171213984489441, Total Loss is: 25.013273239135742\n",
            "MSE Loss is: 0.00801395159214735, h Loss is: 24.944393157958984, L1 loss: 1.1704447269439697, Total Loss is: 24.952407836914062\n",
            "MSE Loss is: 0.008370112627744675, h Loss is: 24.89922523498535, L1 loss: 1.1695127487182617, Total Loss is: 24.907594680786133\n",
            "MSE Loss is: 0.008163041435182095, h Loss is: 24.88490104675293, L1 loss: 1.1686404943466187, Total Loss is: 24.893064498901367\n",
            "MSE Loss is: 0.00797070749104023, h Loss is: 24.855493545532227, L1 loss: 1.1686828136444092, Total Loss is: 24.86346435546875\n",
            "MSE Loss is: 0.008301720023155212, h Loss is: 24.830108642578125, L1 loss: 1.1693247556686401, Total Loss is: 24.838409423828125\n",
            "MSE Loss is: 0.008365188725292683, h Loss is: 24.78870391845703, L1 loss: 1.1702560186386108, Total Loss is: 24.797069549560547\n",
            "MSE Loss is: 0.008302997797727585, h Loss is: 24.732181549072266, L1 loss: 1.1706087589263916, Total Loss is: 24.7404842376709\n",
            "New h_val is : tf.Tensor(1.2957025, shape=(), dtype=float32)\n",
            "Epoch: {} 10\n",
            "MSE Loss is: 0.008663304150104523, h Loss is: 28.818815231323242, L1 loss: 1.1705693006515503, Total Loss is: 28.827478408813477\n",
            "MSE Loss is: 0.008555348962545395, h Loss is: 28.77022933959961, L1 loss: 1.169898509979248, Total Loss is: 28.778783798217773\n",
            "MSE Loss is: 0.008135939948260784, h Loss is: 28.714616775512695, L1 loss: 1.1689881086349487, Total Loss is: 28.722753524780273\n",
            "MSE Loss is: 0.009008627384901047, h Loss is: 28.673519134521484, L1 loss: 1.1681393384933472, Total Loss is: 28.682527542114258\n",
            "MSE Loss is: 0.008469337597489357, h Loss is: 28.629121780395508, L1 loss: 1.1676255464553833, Total Loss is: 28.637590408325195\n",
            "MSE Loss is: 0.008557724766433239, h Loss is: 28.585920333862305, L1 loss: 1.167694330215454, Total Loss is: 28.594478607177734\n",
            "MSE Loss is: 0.008593477308750153, h Loss is: 28.533409118652344, L1 loss: 1.1678390502929688, Total Loss is: 28.542001724243164\n",
            "MSE Loss is: 0.008348356932401657, h Loss is: 28.466428756713867, L1 loss: 1.1682016849517822, Total Loss is: 28.474777221679688\n",
            "MSE Loss is: 0.008265841752290726, h Loss is: 28.379413604736328, L1 loss: 1.1684850454330444, Total Loss is: 28.387680053710938\n",
            "MSE Loss is: 0.008489569649100304, h Loss is: 28.308088302612305, L1 loss: 1.1681654453277588, Total Loss is: 28.316577911376953\n",
            "MSE Loss is: 0.008358130231499672, h Loss is: 28.235858917236328, L1 loss: 1.1674063205718994, Total Loss is: 28.244216918945312\n",
            "MSE Loss is: 0.008210884407162666, h Loss is: 28.184553146362305, L1 loss: 1.1666549444198608, Total Loss is: 28.192764282226562\n",
            "MSE Loss is: 0.008274410851299763, h Loss is: 28.151121139526367, L1 loss: 1.1664040088653564, Total Loss is: 28.159395217895508\n",
            "MSE Loss is: 0.008299963548779488, h Loss is: 28.115182876586914, L1 loss: 1.1667946577072144, Total Loss is: 28.123483657836914\n",
            "MSE Loss is: 0.008096417412161827, h Loss is: 28.055723190307617, L1 loss: 1.167378306388855, Total Loss is: 28.063819885253906\n",
            "MSE Loss is: 0.008508794009685516, h Loss is: 28.01479721069336, L1 loss: 1.167546033859253, Total Loss is: 28.023305892944336\n",
            "MSE Loss is: 0.008605802431702614, h Loss is: 27.980472564697266, L1 loss: 1.167617678642273, Total Loss is: 27.989078521728516\n",
            "MSE Loss is: 0.008321264758706093, h Loss is: 27.910587310791016, L1 loss: 1.167519450187683, Total Loss is: 27.918909072875977\n",
            "MSE Loss is: 0.008127627894282341, h Loss is: 27.831418991088867, L1 loss: 1.1672595739364624, Total Loss is: 27.83954620361328\n",
            "MSE Loss is: 0.00867591891437769, h Loss is: 27.77332878112793, L1 loss: 1.1666254997253418, Total Loss is: 27.782005310058594\n",
            "MSE Loss is: 0.008540956303477287, h Loss is: 27.729887008666992, L1 loss: 1.165993571281433, Total Loss is: 27.738428115844727\n",
            "MSE Loss is: 0.008593474514782429, h Loss is: 27.712982177734375, L1 loss: 1.1657291650772095, Total Loss is: 27.721574783325195\n",
            "MSE Loss is: 0.008190261200070381, h Loss is: 27.704957962036133, L1 loss: 1.1661169528961182, Total Loss is: 27.71314811706543\n",
            "MSE Loss is: 0.008454259485006332, h Loss is: 27.676286697387695, L1 loss: 1.166574239730835, Total Loss is: 27.68474006652832\n",
            "MSE Loss is: 0.008305727504193783, h Loss is: 27.61700439453125, L1 loss: 1.1667938232421875, Total Loss is: 27.62531089782715\n",
            "MSE Loss is: 0.008615029975771904, h Loss is: 27.544519424438477, L1 loss: 1.1663376092910767, Total Loss is: 27.55313491821289\n",
            "MSE Loss is: 0.00795529130846262, h Loss is: 27.45305061340332, L1 loss: 1.16567063331604, Total Loss is: 27.46100616455078\n",
            "MSE Loss is: 0.0087022315710783, h Loss is: 27.374902725219727, L1 loss: 1.1649563312530518, Total Loss is: 27.383604049682617\n",
            "MSE Loss is: 0.0084962397813797, h Loss is: 27.31298065185547, L1 loss: 1.164801001548767, Total Loss is: 27.321475982666016\n",
            "MSE Loss is: 0.008484192192554474, h Loss is: 27.2581787109375, L1 loss: 1.165197730064392, Total Loss is: 27.26666259765625\n",
            "MSE Loss is: 0.00852436013519764, h Loss is: 27.2312068939209, L1 loss: 1.1656010150909424, Total Loss is: 27.239730834960938\n",
            "MSE Loss is: 0.008214859291911125, h Loss is: 27.177013397216797, L1 loss: 1.1648924350738525, Total Loss is: 27.18522834777832\n",
            "MSE Loss is: 0.008514323271811008, h Loss is: 27.092697143554688, L1 loss: 1.1640335321426392, Total Loss is: 27.101211547851562\n",
            "MSE Loss is: 0.008349151350557804, h Loss is: 26.985990524291992, L1 loss: 1.1634750366210938, Total Loss is: 26.994338989257812\n",
            "MSE Loss is: 0.008156226016581059, h Loss is: 26.912595748901367, L1 loss: 1.1631206274032593, Total Loss is: 26.920751571655273\n",
            "MSE Loss is: 0.00818134006112814, h Loss is: 26.8802547454834, L1 loss: 1.1621016263961792, Total Loss is: 26.88843536376953\n",
            "MSE Loss is: 0.008172714151442051, h Loss is: 26.84149742126465, L1 loss: 1.1609888076782227, Total Loss is: 26.84967041015625\n",
            "MSE Loss is: 0.008256223984062672, h Loss is: 26.798843383789062, L1 loss: 1.160654902458191, Total Loss is: 26.807100296020508\n",
            "MSE Loss is: 0.008671056479215622, h Loss is: 26.757558822631836, L1 loss: 1.1610444784164429, Total Loss is: 26.7662296295166\n",
            "MSE Loss is: 0.00842495821416378, h Loss is: 26.69347381591797, L1 loss: 1.1614677906036377, Total Loss is: 26.7018985748291\n",
            "MSE Loss is: 0.008037867955863476, h Loss is: 26.608915328979492, L1 loss: 1.162256121635437, Total Loss is: 26.616952896118164\n",
            "MSE Loss is: 0.008001767098903656, h Loss is: 26.533729553222656, L1 loss: 1.1625163555145264, Total Loss is: 26.541730880737305\n",
            "MSE Loss is: 0.007976948283612728, h Loss is: 26.469871520996094, L1 loss: 1.1621431112289429, Total Loss is: 26.477848052978516\n",
            "MSE Loss is: 0.008324053138494492, h Loss is: 26.432449340820312, L1 loss: 1.1615418195724487, Total Loss is: 26.440773010253906\n",
            "MSE Loss is: 0.008123986423015594, h Loss is: 26.43134880065918, L1 loss: 1.1608824729919434, Total Loss is: 26.439472198486328\n",
            "MSE Loss is: 0.007941111922264099, h Loss is: 26.402687072753906, L1 loss: 1.161170244216919, Total Loss is: 26.410627365112305\n",
            "MSE Loss is: 0.008265554904937744, h Loss is: 26.366710662841797, L1 loss: 1.1619393825531006, Total Loss is: 26.374977111816406\n",
            "MSE Loss is: 0.008326146751642227, h Loss is: 26.306533813476562, L1 loss: 1.162947416305542, Total Loss is: 26.31485939025879\n",
            "MSE Loss is: 0.008252197876572609, h Loss is: 26.23322868347168, L1 loss: 1.163328766822815, Total Loss is: 26.24148178100586\n",
            "New h_val is : tf.Tensor(1.1839113, shape=(), dtype=float32)\n",
            "Epoch: {} 11\n",
            "MSE Loss is: 0.008630744181573391, h Loss is: 29.975284576416016, L1 loss: 1.1635903120040894, Total Loss is: 29.983915328979492\n",
            "MSE Loss is: 0.008523616939783096, h Loss is: 29.93536376953125, L1 loss: 1.1631768941879272, Total Loss is: 29.94388771057129\n",
            "MSE Loss is: 0.008102146908640862, h Loss is: 29.8929386138916, L1 loss: 1.1625473499298096, Total Loss is: 29.90104103088379\n",
            "MSE Loss is: 0.008968636393547058, h Loss is: 29.86003303527832, L1 loss: 1.1618858575820923, Total Loss is: 29.869001388549805\n",
            "MSE Loss is: 0.008426507003605366, h Loss is: 29.811115264892578, L1 loss: 1.1614912748336792, Total Loss is: 29.819541931152344\n",
            "MSE Loss is: 0.008523150347173214, h Loss is: 29.7525691986084, L1 loss: 1.1615604162216187, Total Loss is: 29.761093139648438\n",
            "MSE Loss is: 0.008550134487450123, h Loss is: 29.679872512817383, L1 loss: 1.161676049232483, Total Loss is: 29.68842315673828\n",
            "MSE Loss is: 0.008311610668897629, h Loss is: 29.595643997192383, L1 loss: 1.1620957851409912, Total Loss is: 29.60395622253418\n",
            "MSE Loss is: 0.008228980004787445, h Loss is: 29.50027847290039, L1 loss: 1.1627025604248047, Total Loss is: 29.508506774902344\n",
            "MSE Loss is: 0.008451851084828377, h Loss is: 29.434127807617188, L1 loss: 1.1626684665679932, Total Loss is: 29.44257926940918\n",
            "MSE Loss is: 0.008325882256031036, h Loss is: 29.371034622192383, L1 loss: 1.1618658304214478, Total Loss is: 29.37936019897461\n",
            "MSE Loss is: 0.0081761684268713, h Loss is: 29.32625389099121, L1 loss: 1.1609419584274292, Total Loss is: 29.334430694580078\n",
            "MSE Loss is: 0.008242280222475529, h Loss is: 29.289583206176758, L1 loss: 1.1605619192123413, Total Loss is: 29.29782485961914\n",
            "MSE Loss is: 0.00826052576303482, h Loss is: 29.238479614257812, L1 loss: 1.1610320806503296, Total Loss is: 29.246740341186523\n",
            "MSE Loss is: 0.008063241839408875, h Loss is: 29.156631469726562, L1 loss: 1.1618430614471436, Total Loss is: 29.16469383239746\n",
            "MSE Loss is: 0.008476534858345985, h Loss is: 29.10346031188965, L1 loss: 1.162180781364441, Total Loss is: 29.111936569213867\n",
            "MSE Loss is: 0.008572827093303204, h Loss is: 29.069040298461914, L1 loss: 1.162399172782898, Total Loss is: 29.077613830566406\n",
            "MSE Loss is: 0.008289402350783348, h Loss is: 29.003158569335938, L1 loss: 1.162297248840332, Total Loss is: 29.01144790649414\n",
            "MSE Loss is: 0.008091876283288002, h Loss is: 28.92938232421875, L1 loss: 1.1619447469711304, Total Loss is: 28.93747329711914\n",
            "MSE Loss is: 0.008642115630209446, h Loss is: 28.877017974853516, L1 loss: 1.1611732244491577, Total Loss is: 28.88566017150879\n",
            "MSE Loss is: 0.00851316750049591, h Loss is: 28.834510803222656, L1 loss: 1.1604547500610352, Total Loss is: 28.8430233001709\n",
            "MSE Loss is: 0.008558236993849277, h Loss is: 28.813861846923828, L1 loss: 1.1602503061294556, Total Loss is: 28.822420120239258\n",
            "MSE Loss is: 0.008157036267220974, h Loss is: 28.797279357910156, L1 loss: 1.1609220504760742, Total Loss is: 28.805437088012695\n",
            "MSE Loss is: 0.008420869708061218, h Loss is: 28.756572723388672, L1 loss: 1.1616623401641846, Total Loss is: 28.76499366760254\n",
            "MSE Loss is: 0.008263109251856804, h Loss is: 28.686532974243164, L1 loss: 1.1620205640792847, Total Loss is: 28.694795608520508\n",
            "MSE Loss is: 0.00858093611896038, h Loss is: 28.611068725585938, L1 loss: 1.1615710258483887, Total Loss is: 28.61964988708496\n",
            "MSE Loss is: 0.007927315309643745, h Loss is: 28.522451400756836, L1 loss: 1.1610020399093628, Total Loss is: 28.530378341674805\n",
            "MSE Loss is: 0.008670127019286156, h Loss is: 28.4516544342041, L1 loss: 1.1604048013687134, Total Loss is: 28.460325241088867\n",
            "MSE Loss is: 0.00846449937671423, h Loss is: 28.39609718322754, L1 loss: 1.1603684425354004, Total Loss is: 28.40456199645996\n",
            "MSE Loss is: 0.008448615670204163, h Loss is: 28.340436935424805, L1 loss: 1.160867691040039, Total Loss is: 28.348886489868164\n",
            "MSE Loss is: 0.008506670594215393, h Loss is: 28.305715560913086, L1 loss: 1.1611273288726807, Total Loss is: 28.31422233581543\n",
            "MSE Loss is: 0.008172998204827309, h Loss is: 28.23542022705078, L1 loss: 1.160333275794983, Total Loss is: 28.243593215942383\n",
            "MSE Loss is: 0.0084871556609869, h Loss is: 28.13253402709961, L1 loss: 1.1595700979232788, Total Loss is: 28.141021728515625\n",
            "MSE Loss is: 0.00832967646420002, h Loss is: 28.014726638793945, L1 loss: 1.1593071222305298, Total Loss is: 28.023056030273438\n",
            "MSE Loss is: 0.008118650875985622, h Loss is: 27.947101593017578, L1 loss: 1.1589523553848267, Total Loss is: 27.95522117614746\n",
            "MSE Loss is: 0.008144279941916466, h Loss is: 27.932531356811523, L1 loss: 1.1576651334762573, Total Loss is: 27.940675735473633\n",
            "MSE Loss is: 0.008144857361912727, h Loss is: 27.903404235839844, L1 loss: 1.156407356262207, Total Loss is: 27.911548614501953\n",
            "MSE Loss is: 0.00823894888162613, h Loss is: 27.855621337890625, L1 loss: 1.155974268913269, Total Loss is: 27.863861083984375\n",
            "MSE Loss is: 0.008641086518764496, h Loss is: 27.79796028137207, L1 loss: 1.1564865112304688, Total Loss is: 27.80660057067871\n",
            "MSE Loss is: 0.008388922549784184, h Loss is: 27.715484619140625, L1 loss: 1.1572374105453491, Total Loss is: 27.723873138427734\n",
            "MSE Loss is: 0.008000683039426804, h Loss is: 27.62033462524414, L1 loss: 1.1584776639938354, Total Loss is: 27.62833595275879\n",
            "MSE Loss is: 0.007973756641149521, h Loss is: 27.549556732177734, L1 loss: 1.1587872505187988, Total Loss is: 27.557531356811523\n",
            "MSE Loss is: 0.007943904027342796, h Loss is: 27.50023651123047, L1 loss: 1.1583024263381958, Total Loss is: 27.508180618286133\n",
            "MSE Loss is: 0.008282626047730446, h Loss is: 27.478111267089844, L1 loss: 1.1574548482894897, Total Loss is: 27.486392974853516\n",
            "MSE Loss is: 0.008103011175990105, h Loss is: 27.484952926635742, L1 loss: 1.1564081907272339, Total Loss is: 27.49305534362793\n",
            "MSE Loss is: 0.007923061028122902, h Loss is: 27.444135665893555, L1 loss: 1.1567187309265137, Total Loss is: 27.452058792114258\n",
            "MSE Loss is: 0.008236763998866081, h Loss is: 27.387168884277344, L1 loss: 1.1578634977340698, Total Loss is: 27.395404815673828\n",
            "MSE Loss is: 0.008297860622406006, h Loss is: 27.30954933166504, L1 loss: 1.159458041191101, Total Loss is: 27.317846298217773\n",
            "MSE Loss is: 0.008217626251280308, h Loss is: 27.233793258666992, L1 loss: 1.1602346897125244, Total Loss is: 27.24201011657715\n",
            "New h_val is : tf.Tensor(1.0796342, shape=(), dtype=float32)\n",
            "Epoch: {} 12\n",
            "MSE Loss is: 0.008607154712080956, h Loss is: 30.66384506225586, L1 loss: 1.1604433059692383, Total Loss is: 30.672452926635742\n",
            "MSE Loss is: 0.00849586259573698, h Loss is: 30.64834976196289, L1 loss: 1.159627914428711, Total Loss is: 30.656845092773438\n",
            "MSE Loss is: 0.008081602863967419, h Loss is: 30.621246337890625, L1 loss: 1.1585248708724976, Total Loss is: 30.62932777404785\n",
            "MSE Loss is: 0.008941838517785072, h Loss is: 30.585491180419922, L1 loss: 1.157654881477356, Total Loss is: 30.594432830810547\n",
            "MSE Loss is: 0.008394964039325714, h Loss is: 30.517375946044922, L1 loss: 1.1575008630752563, Total Loss is: 30.52577018737793\n",
            "MSE Loss is: 0.008496029302477837, h Loss is: 30.437259674072266, L1 loss: 1.1581239700317383, Total Loss is: 30.445755004882812\n",
            "MSE Loss is: 0.00851451512426138, h Loss is: 30.35248565673828, L1 loss: 1.1588103771209717, Total Loss is: 30.361000061035156\n",
            "MSE Loss is: 0.008285913616418839, h Loss is: 30.270112991333008, L1 loss: 1.1594513654708862, Total Loss is: 30.278398513793945\n",
            "MSE Loss is: 0.00820237398147583, h Loss is: 30.186140060424805, L1 loss: 1.1597737073898315, Total Loss is: 30.1943416595459\n",
            "MSE Loss is: 0.008418704383075237, h Loss is: 30.13521957397461, L1 loss: 1.1591328382492065, Total Loss is: 30.143638610839844\n",
            "MSE Loss is: 0.008300550282001495, h Loss is: 30.077852249145508, L1 loss: 1.1578527688980103, Total Loss is: 30.086153030395508\n",
            "MSE Loss is: 0.008153712376952171, h Loss is: 30.026823043823242, L1 loss: 1.1568998098373413, Total Loss is: 30.034976959228516\n",
            "MSE Loss is: 0.008218812756240368, h Loss is: 29.974777221679688, L1 loss: 1.1569617986679077, Total Loss is: 29.982995986938477\n",
            "MSE Loss is: 0.00822259858250618, h Loss is: 29.90663719177246, L1 loss: 1.1580358743667603, Total Loss is: 29.914859771728516\n",
            "MSE Loss is: 0.008045051246881485, h Loss is: 29.813756942749023, L1 loss: 1.1592861413955688, Total Loss is: 29.821802139282227\n",
            "MSE Loss is: 0.008456144481897354, h Loss is: 29.767684936523438, L1 loss: 1.159586787223816, Total Loss is: 29.776140213012695\n",
            "MSE Loss is: 0.008546663448214531, h Loss is: 29.74992561340332, L1 loss: 1.1592928171157837, Total Loss is: 29.758472442626953\n",
            "MSE Loss is: 0.008263749070465565, h Loss is: 29.693967819213867, L1 loss: 1.1588220596313477, Total Loss is: 29.702232360839844\n",
            "MSE Loss is: 0.008064188063144684, h Loss is: 29.619457244873047, L1 loss: 1.1584001779556274, Total Loss is: 29.627521514892578\n",
            "MSE Loss is: 0.008619097992777824, h Loss is: 29.561185836791992, L1 loss: 1.1579052209854126, Total Loss is: 29.569805145263672\n",
            "MSE Loss is: 0.008491966873407364, h Loss is: 29.511707305908203, L1 loss: 1.1578129529953003, Total Loss is: 29.520198822021484\n",
            "MSE Loss is: 0.008526338264346123, h Loss is: 29.488983154296875, L1 loss: 1.15822434425354, Total Loss is: 29.497509002685547\n",
            "MSE Loss is: 0.008133362978696823, h Loss is: 29.47494125366211, L1 loss: 1.1590934991836548, Total Loss is: 29.483074188232422\n",
            "MSE Loss is: 0.008398815989494324, h Loss is: 29.436769485473633, L1 loss: 1.1596587896347046, Total Loss is: 29.445167541503906\n",
            "MSE Loss is: 0.008224858902394772, h Loss is: 29.367225646972656, L1 loss: 1.159514307975769, Total Loss is: 29.375450134277344\n",
            "MSE Loss is: 0.008551103994250298, h Loss is: 29.29280662536621, L1 loss: 1.1586320400238037, Total Loss is: 29.30135726928711\n",
            "MSE Loss is: 0.007911374792456627, h Loss is: 29.204402923583984, L1 loss: 1.1579676866531372, Total Loss is: 29.21231460571289\n",
            "MSE Loss is: 0.008645320311188698, h Loss is: 29.135452270507812, L1 loss: 1.157679796218872, Total Loss is: 29.14409828186035\n",
            "MSE Loss is: 0.008438609540462494, h Loss is: 29.082487106323242, L1 loss: 1.1581991910934448, Total Loss is: 29.090925216674805\n",
            "MSE Loss is: 0.008420461788773537, h Loss is: 29.026960372924805, L1 loss: 1.1590989828109741, Total Loss is: 29.035381317138672\n",
            "MSE Loss is: 0.008497538045048714, h Loss is: 28.99037742614746, L1 loss: 1.1595309972763062, Total Loss is: 28.99887466430664\n",
            "MSE Loss is: 0.008132455870509148, h Loss is: 28.912925720214844, L1 loss: 1.158307671546936, Total Loss is: 28.921058654785156\n",
            "MSE Loss is: 0.008476639166474342, h Loss is: 28.80083465576172, L1 loss: 1.1570576429367065, Total Loss is: 28.809310913085938\n",
            "MSE Loss is: 0.008320599794387817, h Loss is: 28.679290771484375, L1 loss: 1.1565699577331543, Total Loss is: 28.687610626220703\n",
            "MSE Loss is: 0.008088267408311367, h Loss is: 28.620698928833008, L1 loss: 1.1565418243408203, Total Loss is: 28.628787994384766\n",
            "MSE Loss is: 0.008120307698845863, h Loss is: 28.62211799621582, L1 loss: 1.1557978391647339, Total Loss is: 28.630237579345703\n",
            "MSE Loss is: 0.0081271231174469, h Loss is: 28.597244262695312, L1 loss: 1.1546567678451538, Total Loss is: 28.605371475219727\n",
            "MSE Loss is: 0.008216447196900845, h Loss is: 28.539663314819336, L1 loss: 1.1541519165039062, Total Loss is: 28.547880172729492\n",
            "MSE Loss is: 0.00862229522317648, h Loss is: 28.46698760986328, L1 loss: 1.1546096801757812, Total Loss is: 28.475610733032227\n",
            "MSE Loss is: 0.008365117944777012, h Loss is: 28.375757217407227, L1 loss: 1.1552448272705078, Total Loss is: 28.384122848510742\n",
            "MSE Loss is: 0.007973968982696533, h Loss is: 28.28409767150879, L1 loss: 1.1562740802764893, Total Loss is: 28.292072296142578\n",
            "MSE Loss is: 0.007943941280245781, h Loss is: 28.22898292541504, L1 loss: 1.156345009803772, Total Loss is: 28.236927032470703\n",
            "MSE Loss is: 0.007917688228189945, h Loss is: 28.19671630859375, L1 loss: 1.1555631160736084, Total Loss is: 28.204633712768555\n",
            "MSE Loss is: 0.00825292058289051, h Loss is: 28.18290138244629, L1 loss: 1.1545599699020386, Total Loss is: 28.19115447998047\n",
            "MSE Loss is: 0.008082715794444084, h Loss is: 28.18668556213379, L1 loss: 1.153743028640747, Total Loss is: 28.19476890563965\n",
            "MSE Loss is: 0.00790890771895647, h Loss is: 28.127466201782227, L1 loss: 1.154488444328308, Total Loss is: 28.1353759765625\n",
            "MSE Loss is: 0.008216574788093567, h Loss is: 28.05449104309082, L1 loss: 1.1560981273651123, Total Loss is: 28.062707901000977\n",
            "MSE Loss is: 0.00828006025403738, h Loss is: 27.97492027282715, L1 loss: 1.157711386680603, Total Loss is: 27.983200073242188\n",
            "MSE Loss is: 0.008193938061594963, h Loss is: 27.914636611938477, L1 loss: 1.158003807067871, Total Loss is: 27.92283058166504\n",
            "New h_val is : tf.Tensor(0.98667765, shape=(), dtype=float32)\n",
            "Epoch: {} 13\n",
            "MSE Loss is: 0.008582448586821556, h Loss is: 31.084932327270508, L1 loss: 1.1576974391937256, Total Loss is: 31.093515396118164\n",
            "MSE Loss is: 0.008474756963551044, h Loss is: 31.089284896850586, L1 loss: 1.1565340757369995, Total Loss is: 31.097759246826172\n",
            "MSE Loss is: 0.008069846779108047, h Loss is: 31.060842514038086, L1 loss: 1.1554441452026367, Total Loss is: 31.068912506103516\n",
            "MSE Loss is: 0.008917059749364853, h Loss is: 31.0061092376709, L1 loss: 1.155080795288086, Total Loss is: 31.015026092529297\n",
            "MSE Loss is: 0.008367408066987991, h Loss is: 30.91602325439453, L1 loss: 1.1556326150894165, Total Loss is: 30.92439079284668\n",
            "MSE Loss is: 0.008478455245494843, h Loss is: 30.82879638671875, L1 loss: 1.156795620918274, Total Loss is: 30.8372745513916\n",
            "MSE Loss is: 0.00848802924156189, h Loss is: 30.755229949951172, L1 loss: 1.1573728322982788, Total Loss is: 30.763717651367188\n",
            "MSE Loss is: 0.008265383541584015, h Loss is: 30.692607879638672, L1 loss: 1.1574599742889404, Total Loss is: 30.70087242126465\n",
            "MSE Loss is: 0.008175292052328587, h Loss is: 30.622472763061523, L1 loss: 1.1571024656295776, Total Loss is: 30.630647659301758\n",
            "MSE Loss is: 0.008391786366701126, h Loss is: 30.57399559020996, L1 loss: 1.1562700271606445, Total Loss is: 30.582387924194336\n",
            "MSE Loss is: 0.008285369724035263, h Loss is: 30.50482940673828, L1 loss: 1.155319094657898, Total Loss is: 30.51311492919922\n",
            "MSE Loss is: 0.008132612332701683, h Loss is: 30.43822479248047, L1 loss: 1.1551735401153564, Total Loss is: 30.44635772705078\n",
            "MSE Loss is: 0.008191069588065147, h Loss is: 30.37672996520996, L1 loss: 1.1560509204864502, Total Loss is: 30.384920120239258\n",
            "MSE Loss is: 0.008189581334590912, h Loss is: 30.31002426147461, L1 loss: 1.1574512720108032, Total Loss is: 30.318214416503906\n",
            "MSE Loss is: 0.008033281192183495, h Loss is: 30.226438522338867, L1 loss: 1.1582263708114624, Total Loss is: 30.234472274780273\n",
            "MSE Loss is: 0.008437479846179485, h Loss is: 30.19789695739746, L1 loss: 1.157779335975647, Total Loss is: 30.206335067749023\n",
            "MSE Loss is: 0.008523164317011833, h Loss is: 30.192047119140625, L1 loss: 1.1570817232131958, Total Loss is: 30.200571060180664\n",
            "MSE Loss is: 0.008247342891991138, h Loss is: 30.131004333496094, L1 loss: 1.1566861867904663, Total Loss is: 30.139251708984375\n",
            "MSE Loss is: 0.008046521805226803, h Loss is: 30.042339324951172, L1 loss: 1.156714677810669, Total Loss is: 30.050386428833008\n",
            "MSE Loss is: 0.00859970785677433, h Loss is: 29.976655960083008, L1 loss: 1.156735897064209, Total Loss is: 29.98525619506836\n",
            "MSE Loss is: 0.008473768830299377, h Loss is: 29.932275772094727, L1 loss: 1.1568937301635742, Total Loss is: 29.940750122070312\n",
            "MSE Loss is: 0.008503659628331661, h Loss is: 29.925331115722656, L1 loss: 1.1571874618530273, Total Loss is: 29.933834075927734\n",
            "MSE Loss is: 0.008118100464344025, h Loss is: 29.926021575927734, L1 loss: 1.1577301025390625, Total Loss is: 29.934139251708984\n",
            "MSE Loss is: 0.008378662168979645, h Loss is: 29.89059066772461, L1 loss: 1.157845377922058, Total Loss is: 29.898969650268555\n",
            "MSE Loss is: 0.008192946203052998, h Loss is: 29.81214714050293, L1 loss: 1.1575610637664795, Total Loss is: 29.82033920288086\n",
            "MSE Loss is: 0.008530699647963047, h Loss is: 29.72898292541504, L1 loss: 1.1569702625274658, Total Loss is: 29.73751449584961\n",
            "MSE Loss is: 0.007894976064562798, h Loss is: 29.63884925842285, L1 loss: 1.1567776203155518, Total Loss is: 29.646743774414062\n",
            "MSE Loss is: 0.008620508015155792, h Loss is: 29.579381942749023, L1 loss: 1.1567963361740112, Total Loss is: 29.588003158569336\n",
            "MSE Loss is: 0.008423062041401863, h Loss is: 29.5407657623291, L1 loss: 1.1573991775512695, Total Loss is: 29.5491886138916\n",
            "MSE Loss is: 0.008400440216064453, h Loss is: 29.493650436401367, L1 loss: 1.1580997705459595, Total Loss is: 29.502050399780273\n",
            "MSE Loss is: 0.008479044772684574, h Loss is: 29.455862045288086, L1 loss: 1.1579995155334473, Total Loss is: 29.464340209960938\n",
            "MSE Loss is: 0.008104427717626095, h Loss is: 29.366960525512695, L1 loss: 1.156417727470398, Total Loss is: 29.375064849853516\n",
            "MSE Loss is: 0.008470864966511726, h Loss is: 29.242042541503906, L1 loss: 1.1552821397781372, Total Loss is: 29.250513076782227\n",
            "MSE Loss is: 0.008307082578539848, h Loss is: 29.118894577026367, L1 loss: 1.1553195714950562, Total Loss is: 29.127201080322266\n",
            "MSE Loss is: 0.008073408156633377, h Loss is: 29.07644271850586, L1 loss: 1.1553950309753418, Total Loss is: 29.084516525268555\n",
            "MSE Loss is: 0.00811718963086605, h Loss is: 29.10038185119629, L1 loss: 1.1544852256774902, Total Loss is: 29.10849952697754\n",
            "MSE Loss is: 0.008110545575618744, h Loss is: 29.08056640625, L1 loss: 1.1531227827072144, Total Loss is: 29.08867645263672\n",
            "MSE Loss is: 0.008201046846807003, h Loss is: 29.0096435546875, L1 loss: 1.1523394584655762, Total Loss is: 29.017845153808594\n",
            "MSE Loss is: 0.008608995005488396, h Loss is: 28.919729232788086, L1 loss: 1.1526902914047241, Total Loss is: 28.9283390045166\n",
            "MSE Loss is: 0.008349664509296417, h Loss is: 28.82393455505371, L1 loss: 1.153496503829956, Total Loss is: 28.832284927368164\n",
            "MSE Loss is: 0.007953636348247528, h Loss is: 28.744873046875, L1 loss: 1.1546356678009033, Total Loss is: 28.752826690673828\n",
            "MSE Loss is: 0.00792400911450386, h Loss is: 28.713211059570312, L1 loss: 1.1545711755752563, Total Loss is: 28.721134185791016\n",
            "MSE Loss is: 0.007901668548583984, h Loss is: 28.698665618896484, L1 loss: 1.1536002159118652, Total Loss is: 28.706567764282227\n",
            "MSE Loss is: 0.008229232393205166, h Loss is: 28.686357498168945, L1 loss: 1.15253484249115, Total Loss is: 28.6945858001709\n",
            "MSE Loss is: 0.008064032532274723, h Loss is: 28.678998947143555, L1 loss: 1.1519216299057007, Total Loss is: 28.687063217163086\n",
            "MSE Loss is: 0.007902952842414379, h Loss is: 28.600067138671875, L1 loss: 1.153015375137329, Total Loss is: 28.607969284057617\n",
            "MSE Loss is: 0.008198091760277748, h Loss is: 28.52043342590332, L1 loss: 1.154775857925415, Total Loss is: 28.52863121032715\n",
            "MSE Loss is: 0.008266471326351166, h Loss is: 28.454195022583008, L1 loss: 1.1562193632125854, Total Loss is: 28.462461471557617\n",
            "MSE Loss is: 0.008176067844033241, h Loss is: 28.42047691345215, L1 loss: 1.1560653448104858, Total Loss is: 28.428653717041016\n",
            "New h_val is : tf.Tensor(0.90581465, shape=(), dtype=float32)\n",
            "Epoch: {} 14\n",
            "MSE Loss is: 0.008563035167753696, h Loss is: 31.38154411315918, L1 loss: 1.1553773880004883, Total Loss is: 31.390106201171875\n",
            "MSE Loss is: 0.00846574455499649, h Loss is: 31.39197540283203, L1 loss: 1.1542657613754272, Total Loss is: 31.400440216064453\n",
            "MSE Loss is: 0.008062392473220825, h Loss is: 31.345256805419922, L1 loss: 1.153762698173523, Total Loss is: 31.35331916809082\n",
            "MSE Loss is: 0.008896313607692719, h Loss is: 31.265806198120117, L1 loss: 1.1540025472640991, Total Loss is: 31.274702072143555\n",
            "MSE Loss is: 0.008347049355506897, h Loss is: 31.166019439697266, L1 loss: 1.154807448387146, Total Loss is: 31.174365997314453\n",
            "MSE Loss is: 0.008469445630908012, h Loss is: 31.094697952270508, L1 loss: 1.155650019645691, Total Loss is: 31.103166580200195\n",
            "MSE Loss is: 0.008467917330563068, h Loss is: 31.05000114440918, L1 loss: 1.1556395292282104, Total Loss is: 31.058469772338867\n",
            "MSE Loss is: 0.008249673061072826, h Loss is: 31.007104873657227, L1 loss: 1.1552382707595825, Total Loss is: 31.01535415649414\n",
            "MSE Loss is: 0.008152898401021957, h Loss is: 30.93396759033203, L1 loss: 1.1549264192581177, Total Loss is: 30.942119598388672\n",
            "MSE Loss is: 0.008374078199267387, h Loss is: 30.86824607849121, L1 loss: 1.1544911861419678, Total Loss is: 30.876619338989258\n",
            "MSE Loss is: 0.00827327836304903, h Loss is: 30.78078842163086, L1 loss: 1.1540929079055786, Total Loss is: 30.7890625\n",
            "MSE Loss is: 0.008116796612739563, h Loss is: 30.711336135864258, L1 loss: 1.1542633771896362, Total Loss is: 30.719453811645508\n",
            "MSE Loss is: 0.008171016350388527, h Loss is: 30.663719177246094, L1 loss: 1.1549240350723267, Total Loss is: 30.671890258789062\n",
            "MSE Loss is: 0.008168524131178856, h Loss is: 30.616779327392578, L1 loss: 1.1559494733810425, Total Loss is: 30.624948501586914\n",
            "MSE Loss is: 0.008015182800590992, h Loss is: 30.543872833251953, L1 loss: 1.1564196348190308, Total Loss is: 30.55188751220703\n",
            "MSE Loss is: 0.008422564715147018, h Loss is: 30.51805877685547, L1 loss: 1.155791997909546, Total Loss is: 30.52648162841797\n",
            "MSE Loss is: 0.008503256365656853, h Loss is: 30.505374908447266, L1 loss: 1.1551893949508667, Total Loss is: 30.513877868652344\n",
            "MSE Loss is: 0.008238205686211586, h Loss is: 30.431682586669922, L1 loss: 1.1554702520370483, Total Loss is: 30.43992042541504\n",
            "MSE Loss is: 0.008033020421862602, h Loss is: 30.338693618774414, L1 loss: 1.1561205387115479, Total Loss is: 30.34672737121582\n",
            "MSE Loss is: 0.008584186434745789, h Loss is: 30.286785125732422, L1 loss: 1.1562620401382446, Total Loss is: 30.29537010192871\n",
            "MSE Loss is: 0.008464750833809376, h Loss is: 30.2650146484375, L1 loss: 1.1562227010726929, Total Loss is: 30.273479461669922\n",
            "MSE Loss is: 0.008488335646688938, h Loss is: 30.275623321533203, L1 loss: 1.1561497449874878, Total Loss is: 30.28411102294922\n",
            "MSE Loss is: 0.008105559274554253, h Loss is: 30.277345657348633, L1 loss: 1.1564394235610962, Total Loss is: 30.285451889038086\n",
            "MSE Loss is: 0.008362612687051296, h Loss is: 30.227561950683594, L1 loss: 1.1566333770751953, Total Loss is: 30.235923767089844\n",
            "MSE Loss is: 0.008172755129635334, h Loss is: 30.134796142578125, L1 loss: 1.1567137241363525, Total Loss is: 30.142969131469727\n",
            "MSE Loss is: 0.00851738452911377, h Loss is: 30.054428100585938, L1 loss: 1.1563533544540405, Total Loss is: 30.062946319580078\n",
            "MSE Loss is: 0.007878435775637627, h Loss is: 29.98273277282715, L1 loss: 1.156435251235962, Total Loss is: 29.990612030029297\n",
            "MSE Loss is: 0.008601121604442596, h Loss is: 29.946598052978516, L1 loss: 1.1565943956375122, Total Loss is: 29.955198287963867\n",
            "MSE Loss is: 0.008413167670369148, h Loss is: 29.92034149169922, L1 loss: 1.1571165323257446, Total Loss is: 29.928754806518555\n",
            "MSE Loss is: 0.00838828831911087, h Loss is: 29.866836547851562, L1 loss: 1.157554030418396, Total Loss is: 29.875225067138672\n",
            "MSE Loss is: 0.008457845076918602, h Loss is: 29.81382179260254, L1 loss: 1.1571358442306519, Total Loss is: 29.82227897644043\n",
            "MSE Loss is: 0.00808558240532875, h Loss is: 29.712955474853516, L1 loss: 1.1554802656173706, Total Loss is: 29.721040725708008\n",
            "MSE Loss is: 0.008470778353512287, h Loss is: 29.58938980102539, L1 loss: 1.1548572778701782, Total Loss is: 29.59786033630371\n",
            "MSE Loss is: 0.008289771154522896, h Loss is: 29.48380470275879, L1 loss: 1.1554034948349, Total Loss is: 29.492094039916992\n",
            "MSE Loss is: 0.008064815774559975, h Loss is: 29.4669132232666, L1 loss: 1.155483603477478, Total Loss is: 29.474977493286133\n",
            "MSE Loss is: 0.008123968727886677, h Loss is: 29.506336212158203, L1 loss: 1.154006004333496, Total Loss is: 29.51445960998535\n",
            "MSE Loss is: 0.008098543621599674, h Loss is: 29.474388122558594, L1 loss: 1.1517250537872314, Total Loss is: 29.482486724853516\n",
            "MSE Loss is: 0.008201497606933117, h Loss is: 29.378629684448242, L1 loss: 1.150639533996582, Total Loss is: 29.386831283569336\n",
            "MSE Loss is: 0.008601732552051544, h Loss is: 29.277347564697266, L1 loss: 1.1515449285507202, Total Loss is: 29.28594970703125\n",
            "MSE Loss is: 0.008337884210050106, h Loss is: 29.197195053100586, L1 loss: 1.1529136896133423, Total Loss is: 29.20553207397461\n",
            "MSE Loss is: 0.007935754954814911, h Loss is: 29.149099349975586, L1 loss: 1.1542361974716187, Total Loss is: 29.15703582763672\n",
            "MSE Loss is: 0.007916335016489029, h Loss is: 29.143037796020508, L1 loss: 1.1538289785385132, Total Loss is: 29.15095329284668\n",
            "MSE Loss is: 0.007889430038630962, h Loss is: 29.130796432495117, L1 loss: 1.1522024869918823, Total Loss is: 29.13868522644043\n",
            "MSE Loss is: 0.008210400119423866, h Loss is: 29.1009578704834, L1 loss: 1.1505898237228394, Total Loss is: 29.109169006347656\n",
            "MSE Loss is: 0.00805473793298006, h Loss is: 29.07695770263672, L1 loss: 1.1499320268630981, Total Loss is: 29.085012435913086\n",
            "MSE Loss is: 0.007899463176727295, h Loss is: 28.991924285888672, L1 loss: 1.1516456604003906, Total Loss is: 28.99982452392578\n",
            "MSE Loss is: 0.008184408769011497, h Loss is: 28.92916488647461, L1 loss: 1.1541274785995483, Total Loss is: 28.937349319458008\n",
            "MSE Loss is: 0.008263412863016129, h Loss is: 28.89165496826172, L1 loss: 1.1556835174560547, Total Loss is: 28.899917602539062\n",
            "MSE Loss is: 0.008157876320183277, h Loss is: 28.880245208740234, L1 loss: 1.1549677848815918, Total Loss is: 28.888402938842773\n",
            "New h_val is : tf.Tensor(0.8367357, shape=(), dtype=float32)\n",
            "Epoch: {} 15\n",
            "MSE Loss is: 0.008549013175070286, h Loss is: 31.66598892211914, L1 loss: 1.1537593603134155, Total Loss is: 31.674537658691406\n",
            "MSE Loss is: 0.008461941964924335, h Loss is: 31.661720275878906, L1 loss: 1.152353286743164, Total Loss is: 31.670181274414062\n",
            "MSE Loss is: 0.008061372675001621, h Loss is: 31.592803955078125, L1 loss: 1.1521729230880737, Total Loss is: 31.60086441040039\n",
            "MSE Loss is: 0.008884161710739136, h Loss is: 31.50659942626953, L1 loss: 1.1529626846313477, Total Loss is: 31.515483856201172\n",
            "MSE Loss is: 0.008333971723914146, h Loss is: 31.424022674560547, L1 loss: 1.154118537902832, Total Loss is: 31.432355880737305\n",
            "MSE Loss is: 0.008465787395834923, h Loss is: 31.383831024169922, L1 loss: 1.1548200845718384, Total Loss is: 31.392297744750977\n",
            "MSE Loss is: 0.008454709313809872, h Loss is: 31.36005210876465, L1 loss: 1.1544275283813477, Total Loss is: 31.368507385253906\n",
            "MSE Loss is: 0.008240058086812496, h Loss is: 31.312837600708008, L1 loss: 1.1539280414581299, Total Loss is: 31.321077346801758\n",
            "MSE Loss is: 0.008139673620462418, h Loss is: 31.217182159423828, L1 loss: 1.1539353132247925, Total Loss is: 31.225322723388672\n",
            "MSE Loss is: 0.00836002267897129, h Loss is: 31.13607406616211, L1 loss: 1.1539453268051147, Total Loss is: 31.144433975219727\n",
            "MSE Loss is: 0.008266480639576912, h Loss is: 31.053157806396484, L1 loss: 1.153855323791504, Total Loss is: 31.061424255371094\n",
            "MSE Loss is: 0.00810350850224495, h Loss is: 31.007200241088867, L1 loss: 1.1540318727493286, Total Loss is: 31.015304565429688\n",
            "MSE Loss is: 0.008159814402461052, h Loss is: 30.983444213867188, L1 loss: 1.154746413230896, Total Loss is: 30.99160385131836\n",
            "MSE Loss is: 0.008159598335623741, h Loss is: 30.94310760498047, L1 loss: 1.1557775735855103, Total Loss is: 30.95126724243164\n",
            "MSE Loss is: 0.007999170571565628, h Loss is: 30.85739517211914, L1 loss: 1.1563130617141724, Total Loss is: 30.865394592285156\n",
            "MSE Loss is: 0.00841599516570568, h Loss is: 30.820995330810547, L1 loss: 1.1556131839752197, Total Loss is: 30.829410552978516\n",
            "MSE Loss is: 0.008484713733196259, h Loss is: 30.80990219116211, L1 loss: 1.1550239324569702, Total Loss is: 30.81838607788086\n",
            "MSE Loss is: 0.008230604231357574, h Loss is: 30.74747085571289, L1 loss: 1.1554323434829712, Total Loss is: 30.755701065063477\n",
            "MSE Loss is: 0.008019376546144485, h Loss is: 30.670866012573242, L1 loss: 1.1563488245010376, Total Loss is: 30.678884506225586\n",
            "MSE Loss is: 0.008571824990212917, h Loss is: 30.63513946533203, L1 loss: 1.1566236019134521, Total Loss is: 30.64371109008789\n",
            "MSE Loss is: 0.008460050448775291, h Loss is: 30.62026023864746, L1 loss: 1.1565437316894531, Total Loss is: 30.628721237182617\n",
            "MSE Loss is: 0.008475369773805141, h Loss is: 30.628589630126953, L1 loss: 1.1563323736190796, Total Loss is: 30.637065887451172\n",
            "MSE Loss is: 0.008092500269412994, h Loss is: 30.624292373657227, L1 loss: 1.156537413597107, Total Loss is: 30.63238525390625\n",
            "MSE Loss is: 0.008350767195224762, h Loss is: 30.572528839111328, L1 loss: 1.1567212343215942, Total Loss is: 30.58087921142578\n",
            "MSE Loss is: 0.008154621347784996, h Loss is: 30.487964630126953, L1 loss: 1.1569015979766846, Total Loss is: 30.496118545532227\n",
            "MSE Loss is: 0.008507619611918926, h Loss is: 30.425884246826172, L1 loss: 1.1567877531051636, Total Loss is: 30.434391021728516\n",
            "MSE Loss is: 0.007864177227020264, h Loss is: 30.36970329284668, L1 loss: 1.1570948362350464, Total Loss is: 30.377567291259766\n",
            "MSE Loss is: 0.00858684629201889, h Loss is: 30.339326858520508, L1 loss: 1.1572405099868774, Total Loss is: 30.34791374206543\n",
            "MSE Loss is: 0.008403797633945942, h Loss is: 30.308259963989258, L1 loss: 1.1575534343719482, Total Loss is: 30.31666374206543\n",
            "MSE Loss is: 0.008381333202123642, h Loss is: 30.246543884277344, L1 loss: 1.157796859741211, Total Loss is: 30.254924774169922\n",
            "MSE Loss is: 0.008436281234025955, h Loss is: 30.194116592407227, L1 loss: 1.15719473361969, Total Loss is: 30.202552795410156\n",
            "MSE Loss is: 0.00806907843798399, h Loss is: 30.102134704589844, L1 loss: 1.155652403831482, Total Loss is: 30.110204696655273\n",
            "MSE Loss is: 0.008469474501907825, h Loss is: 29.990259170532227, L1 loss: 1.155312418937683, Total Loss is: 29.998727798461914\n",
            "MSE Loss is: 0.008265871554613113, h Loss is: 29.894672393798828, L1 loss: 1.1560922861099243, Total Loss is: 29.902938842773438\n",
            "MSE Loss is: 0.008067790418863297, h Loss is: 29.885290145874023, L1 loss: 1.1560181379318237, Total Loss is: 29.89335823059082\n",
            "MSE Loss is: 0.008120590820908546, h Loss is: 29.926551818847656, L1 loss: 1.1536864042282104, Total Loss is: 29.934673309326172\n",
            "MSE Loss is: 0.00808568112552166, h Loss is: 29.884614944458008, L1 loss: 1.151222825050354, Total Loss is: 29.8927001953125\n",
            "MSE Loss is: 0.008212927728891373, h Loss is: 29.781450271606445, L1 loss: 1.1505756378173828, Total Loss is: 29.789663314819336\n",
            "MSE Loss is: 0.00859962310642004, h Loss is: 29.688701629638672, L1 loss: 1.1519335508346558, Total Loss is: 29.697301864624023\n",
            "MSE Loss is: 0.008324440568685532, h Loss is: 29.63080406188965, L1 loss: 1.1535500288009644, Total Loss is: 29.639127731323242\n",
            "MSE Loss is: 0.007927430793642998, h Loss is: 29.60205841064453, L1 loss: 1.154697299003601, Total Loss is: 29.6099853515625\n",
            "MSE Loss is: 0.007912158034741879, h Loss is: 29.601457595825195, L1 loss: 1.153564691543579, Total Loss is: 29.6093692779541\n",
            "MSE Loss is: 0.007873407565057278, h Loss is: 29.579429626464844, L1 loss: 1.1514214277267456, Total Loss is: 29.587303161621094\n",
            "MSE Loss is: 0.008200605399906635, h Loss is: 29.53866958618164, L1 loss: 1.1500195264816284, Total Loss is: 29.5468692779541\n",
            "MSE Loss is: 0.008052130229771137, h Loss is: 29.51924705505371, L1 loss: 1.149842619895935, Total Loss is: 29.527299880981445\n",
            "MSE Loss is: 0.00788587424904108, h Loss is: 29.44676399230957, L1 loss: 1.1522077322006226, Total Loss is: 29.454648971557617\n",
            "MSE Loss is: 0.008179357275366783, h Loss is: 29.402315139770508, L1 loss: 1.1545743942260742, Total Loss is: 29.410493850708008\n",
            "MSE Loss is: 0.008267861790955067, h Loss is: 29.377471923828125, L1 loss: 1.1555002927780151, Total Loss is: 29.385740280151367\n",
            "MSE Loss is: 0.008137940429151058, h Loss is: 29.36840057373047, L1 loss: 1.1541780233383179, Total Loss is: 29.37653923034668\n",
            "New h_val is : tf.Tensor(0.77845335, shape=(), dtype=float32)\n",
            "Epoch: {} 16\n",
            "MSE Loss is: 0.00853786338120699, h Loss is: 32.0184440612793, L1 loss: 1.1527996063232422, Total Loss is: 32.026981353759766\n",
            "MSE Loss is: 0.008462144061923027, h Loss is: 32.01234436035156, L1 loss: 1.1518528461456299, Total Loss is: 32.02080535888672\n",
            "MSE Loss is: 0.008060311898589134, h Loss is: 31.945837020874023, L1 loss: 1.1523442268371582, Total Loss is: 31.95389747619629\n",
            "MSE Loss is: 0.008875660598278046, h Loss is: 31.869449615478516, L1 loss: 1.1534308195114136, Total Loss is: 31.878324508666992\n",
            "MSE Loss is: 0.008326839655637741, h Loss is: 31.800128936767578, L1 loss: 1.154349446296692, Total Loss is: 31.808456420898438\n",
            "MSE Loss is: 0.008465444669127464, h Loss is: 31.770854949951172, L1 loss: 1.1546611785888672, Total Loss is: 31.779319763183594\n",
            "MSE Loss is: 0.008446861058473587, h Loss is: 31.74859619140625, L1 loss: 1.1539958715438843, Total Loss is: 31.757043838500977\n",
            "MSE Loss is: 0.008231032639741898, h Loss is: 31.69431495666504, L1 loss: 1.1534826755523682, Total Loss is: 31.702545166015625\n",
            "MSE Loss is: 0.008136220276355743, h Loss is: 31.592010498046875, L1 loss: 1.1537399291992188, Total Loss is: 31.600147247314453\n",
            "MSE Loss is: 0.008350471034646034, h Loss is: 31.517274856567383, L1 loss: 1.153976321220398, Total Loss is: 31.525625228881836\n",
            "MSE Loss is: 0.008261190727353096, h Loss is: 31.44894790649414, L1 loss: 1.1539446115493774, Total Loss is: 31.45720863342285\n",
            "MSE Loss is: 0.008089802227914333, h Loss is: 31.417131423950195, L1 loss: 1.1541141271591187, Total Loss is: 31.425220489501953\n",
            "MSE Loss is: 0.008158087730407715, h Loss is: 31.39714813232422, L1 loss: 1.154810905456543, Total Loss is: 31.405305862426758\n",
            "MSE Loss is: 0.008149401284754276, h Loss is: 31.349632263183594, L1 loss: 1.1556848287582397, Total Loss is: 31.3577823638916\n",
            "MSE Loss is: 0.007985662668943405, h Loss is: 31.25531005859375, L1 loss: 1.1559488773345947, Total Loss is: 31.263296127319336\n",
            "MSE Loss is: 0.008418217301368713, h Loss is: 31.22794532775879, L1 loss: 1.1550928354263306, Total Loss is: 31.236364364624023\n",
            "MSE Loss is: 0.008477052673697472, h Loss is: 31.2368221282959, L1 loss: 1.154658317565918, Total Loss is: 31.245298385620117\n",
            "MSE Loss is: 0.008216869086027145, h Loss is: 31.186779022216797, L1 loss: 1.1555016040802002, Total Loss is: 31.194995880126953\n",
            "MSE Loss is: 0.008011738769710064, h Loss is: 31.111196517944336, L1 loss: 1.1567493677139282, Total Loss is: 31.11920738220215\n",
            "MSE Loss is: 0.008565191179513931, h Loss is: 31.074132919311523, L1 loss: 1.1569300889968872, Total Loss is: 31.082698822021484\n",
            "MSE Loss is: 0.008453021757304668, h Loss is: 31.06175994873047, L1 loss: 1.156434416770935, Total Loss is: 31.070213317871094\n",
            "MSE Loss is: 0.00846724770963192, h Loss is: 31.080360412597656, L1 loss: 1.1558414697647095, Total Loss is: 31.08882713317871\n",
            "MSE Loss is: 0.008085427805781364, h Loss is: 31.088523864746094, L1 loss: 1.1560440063476562, Total Loss is: 31.096609115600586\n",
            "MSE Loss is: 0.008342419750988483, h Loss is: 31.043481826782227, L1 loss: 1.1565927267074585, Total Loss is: 31.05182456970215\n",
            "MSE Loss is: 0.008136789314448833, h Loss is: 30.96004867553711, L1 loss: 1.1573132276535034, Total Loss is: 30.968185424804688\n",
            "MSE Loss is: 0.008501752279698849, h Loss is: 30.90106773376465, L1 loss: 1.1573944091796875, Total Loss is: 30.909568786621094\n",
            "MSE Loss is: 0.007851995527744293, h Loss is: 30.850555419921875, L1 loss: 1.1575292348861694, Total Loss is: 30.858407974243164\n",
            "MSE Loss is: 0.008576810359954834, h Loss is: 30.82964324951172, L1 loss: 1.1572365760803223, Total Loss is: 30.838220596313477\n",
            "MSE Loss is: 0.008395949378609657, h Loss is: 30.807390213012695, L1 loss: 1.1572521924972534, Total Loss is: 30.815786361694336\n",
            "MSE Loss is: 0.008375059813261032, h Loss is: 30.74932289123535, L1 loss: 1.1575908660888672, Total Loss is: 30.75769805908203\n",
            "MSE Loss is: 0.008423179388046265, h Loss is: 30.698482513427734, L1 loss: 1.1573152542114258, Total Loss is: 30.706905364990234\n",
            "MSE Loss is: 0.008052491582930088, h Loss is: 30.605802536010742, L1 loss: 1.1562368869781494, Total Loss is: 30.613855361938477\n",
            "MSE Loss is: 0.008460326120257378, h Loss is: 30.494770050048828, L1 loss: 1.1560999155044556, Total Loss is: 30.503231048583984\n",
            "MSE Loss is: 0.008247138932347298, h Loss is: 30.406543731689453, L1 loss: 1.156700611114502, Total Loss is: 30.414791107177734\n",
            "MSE Loss is: 0.00806607585400343, h Loss is: 30.412193298339844, L1 loss: 1.1565179824829102, Total Loss is: 30.420259475708008\n",
            "MSE Loss is: 0.008110718801617622, h Loss is: 30.465377807617188, L1 loss: 1.154004693031311, Total Loss is: 30.473487854003906\n",
            "MSE Loss is: 0.008078948594629765, h Loss is: 30.417518615722656, L1 loss: 1.1517000198364258, Total Loss is: 30.42559814453125\n",
            "MSE Loss is: 0.008218254894018173, h Loss is: 30.303485870361328, L1 loss: 1.1518667936325073, Total Loss is: 30.311704635620117\n",
            "MSE Loss is: 0.008593758568167686, h Loss is: 30.213146209716797, L1 loss: 1.1537353992462158, Total Loss is: 30.22174072265625\n",
            "MSE Loss is: 0.008318759500980377, h Loss is: 30.173986434936523, L1 loss: 1.1553086042404175, Total Loss is: 30.18230438232422\n",
            "MSE Loss is: 0.007923118770122528, h Loss is: 30.165372848510742, L1 loss: 1.1559711694717407, Total Loss is: 30.173295974731445\n",
            "MSE Loss is: 0.007899932563304901, h Loss is: 30.173519134521484, L1 loss: 1.1540658473968506, Total Loss is: 30.181419372558594\n",
            "MSE Loss is: 0.007861176505684853, h Loss is: 30.144901275634766, L1 loss: 1.151786208152771, Total Loss is: 30.15276336669922\n",
            "MSE Loss is: 0.008196977898478508, h Loss is: 30.09514617919922, L1 loss: 1.1510257720947266, Total Loss is: 30.103343963623047\n",
            "MSE Loss is: 0.008039931766688824, h Loss is: 30.080747604370117, L1 loss: 1.151391625404358, Total Loss is: 30.088787078857422\n",
            "MSE Loss is: 0.007866566069424152, h Loss is: 30.019142150878906, L1 loss: 1.1539591550827026, Total Loss is: 30.027008056640625\n",
            "MSE Loss is: 0.008182834833860397, h Loss is: 29.990516662597656, L1 loss: 1.1558618545532227, Total Loss is: 29.998699188232422\n",
            "MSE Loss is: 0.008261024951934814, h Loss is: 29.97626495361328, L1 loss: 1.1561089754104614, Total Loss is: 29.984525680541992\n",
            "MSE Loss is: 0.008115500211715698, h Loss is: 29.96974754333496, L1 loss: 1.1543930768966675, Total Loss is: 29.977863311767578\n",
            "New h_val is : tf.Tensor(0.73055935, shape=(), dtype=float32)\n",
            "Epoch: {} 17\n",
            "MSE Loss is: 0.008535178378224373, h Loss is: 32.53718185424805, L1 loss: 1.1530760526657104, Total Loss is: 32.54571533203125\n",
            "MSE Loss is: 0.008461125195026398, h Loss is: 32.53295135498047, L1 loss: 1.1527832746505737, Total Loss is: 32.541412353515625\n",
            "MSE Loss is: 0.00804945919662714, h Loss is: 32.469966888427734, L1 loss: 1.1539497375488281, Total Loss is: 32.4780158996582\n",
            "MSE Loss is: 0.008873321115970612, h Loss is: 32.40077209472656, L1 loss: 1.1550829410552979, Total Loss is: 32.409645080566406\n",
            "MSE Loss is: 0.008325121365487576, h Loss is: 32.34000778198242, L1 loss: 1.1555880308151245, Total Loss is: 32.348331451416016\n",
            "MSE Loss is: 0.00846016313880682, h Loss is: 32.31882858276367, L1 loss: 1.1553213596343994, Total Loss is: 32.32728958129883\n",
            "MSE Loss is: 0.00844454113394022, h Loss is: 32.29915237426758, L1 loss: 1.1544443368911743, Total Loss is: 32.30759811401367\n",
            "MSE Loss is: 0.00822686031460762, h Loss is: 32.241554260253906, L1 loss: 1.1542013883590698, Total Loss is: 32.24978256225586\n",
            "MSE Loss is: 0.00813555158674717, h Loss is: 32.13569259643555, L1 loss: 1.1550233364105225, Total Loss is: 32.143829345703125\n",
            "MSE Loss is: 0.008343726396560669, h Loss is: 32.067081451416016, L1 loss: 1.1553999185562134, Total Loss is: 32.07542419433594\n",
            "MSE Loss is: 0.008260578848421574, h Loss is: 32.00878143310547, L1 loss: 1.1553388833999634, Total Loss is: 32.01704025268555\n",
            "MSE Loss is: 0.008081400766968727, h Loss is: 31.985637664794922, L1 loss: 1.155267596244812, Total Loss is: 31.99371910095215\n",
            "MSE Loss is: 0.008158015087246895, h Loss is: 31.967449188232422, L1 loss: 1.1554619073867798, Total Loss is: 31.97560691833496\n",
            "MSE Loss is: 0.008134565316140652, h Loss is: 31.916187286376953, L1 loss: 1.1561387777328491, Total Loss is: 31.9243221282959\n",
            "MSE Loss is: 0.00798435416072607, h Loss is: 31.819604873657227, L1 loss: 1.1568740606307983, Total Loss is: 31.82758903503418\n",
            "MSE Loss is: 0.008418269455432892, h Loss is: 31.80514144897461, L1 loss: 1.1564503908157349, Total Loss is: 31.813560485839844\n",
            "MSE Loss is: 0.008475223556160927, h Loss is: 31.830699920654297, L1 loss: 1.1563078165054321, Total Loss is: 31.839174270629883\n",
            "MSE Loss is: 0.008208302780985832, h Loss is: 31.783899307250977, L1 loss: 1.1575113534927368, Total Loss is: 31.7921085357666\n",
            "MSE Loss is: 0.008009308949112892, h Loss is: 31.703100204467773, L1 loss: 1.1585453748703003, Total Loss is: 31.711109161376953\n",
            "MSE Loss is: 0.008558177389204502, h Loss is: 31.66828727722168, L1 loss: 1.1581878662109375, Total Loss is: 31.67684555053711\n",
            "MSE Loss is: 0.008449457585811615, h Loss is: 31.6689453125, L1 loss: 1.1571977138519287, Total Loss is: 31.67739486694336\n",
            "MSE Loss is: 0.008463541977107525, h Loss is: 31.705324172973633, L1 loss: 1.1566740274429321, Total Loss is: 31.713787078857422\n",
            "MSE Loss is: 0.008081446401774883, h Loss is: 31.72260093688965, L1 loss: 1.1572299003601074, Total Loss is: 31.730682373046875\n",
            "MSE Loss is: 0.008338090032339096, h Loss is: 31.6729736328125, L1 loss: 1.1582388877868652, Total Loss is: 31.681312561035156\n",
            "MSE Loss is: 0.008126487955451012, h Loss is: 31.582578659057617, L1 loss: 1.15923011302948, Total Loss is: 31.59070587158203\n",
            "MSE Loss is: 0.008496977388858795, h Loss is: 31.53052520751953, L1 loss: 1.1589006185531616, Total Loss is: 31.53902244567871\n",
            "MSE Loss is: 0.007841691374778748, h Loss is: 31.497591018676758, L1 loss: 1.1586788892745972, Total Loss is: 31.50543212890625\n",
            "MSE Loss is: 0.008570635691285133, h Loss is: 31.495040893554688, L1 loss: 1.1585115194320679, Total Loss is: 31.503610610961914\n",
            "MSE Loss is: 0.008390392176806927, h Loss is: 31.47847557067871, L1 loss: 1.1590648889541626, Total Loss is: 31.486865997314453\n",
            "MSE Loss is: 0.008369586430490017, h Loss is: 31.411983489990234, L1 loss: 1.1601394414901733, Total Loss is: 31.420352935791016\n",
            "MSE Loss is: 0.008418424054980278, h Loss is: 31.3540096282959, L1 loss: 1.160151720046997, Total Loss is: 31.362428665161133\n",
            "MSE Loss is: 0.008042760193347931, h Loss is: 31.26350212097168, L1 loss: 1.1587433815002441, Total Loss is: 31.27154541015625\n",
            "MSE Loss is: 0.00845147855579853, h Loss is: 31.165054321289062, L1 loss: 1.1585508584976196, Total Loss is: 31.173505783081055\n",
            "MSE Loss is: 0.008234919048845768, h Loss is: 31.09394645690918, L1 loss: 1.1591256856918335, Total Loss is: 31.10218048095703\n",
            "MSE Loss is: 0.00805521197617054, h Loss is: 31.1129150390625, L1 loss: 1.1585997343063354, Total Loss is: 31.120969772338867\n",
            "MSE Loss is: 0.008106665685772896, h Loss is: 31.16641616821289, L1 loss: 1.1562367677688599, Total Loss is: 31.174522399902344\n",
            "MSE Loss is: 0.008070974610745907, h Loss is: 31.10170555114746, L1 loss: 1.1546958684921265, Total Loss is: 31.109777450561523\n",
            "MSE Loss is: 0.008218486793339252, h Loss is: 30.978307723999023, L1 loss: 1.1550688743591309, Total Loss is: 30.986526489257812\n",
            "MSE Loss is: 0.008587393909692764, h Loss is: 30.90362548828125, L1 loss: 1.1567187309265137, Total Loss is: 30.912212371826172\n",
            "MSE Loss is: 0.008315591141581535, h Loss is: 30.894880294799805, L1 loss: 1.1577872037887573, Total Loss is: 30.903196334838867\n",
            "MSE Loss is: 0.007915491238236427, h Loss is: 30.90472412109375, L1 loss: 1.1579668521881104, Total Loss is: 30.912639617919922\n",
            "MSE Loss is: 0.00789040420204401, h Loss is: 30.908218383789062, L1 loss: 1.156178593635559, Total Loss is: 30.916109085083008\n",
            "MSE Loss is: 0.007855230942368507, h Loss is: 30.861181259155273, L1 loss: 1.1544075012207031, Total Loss is: 30.869035720825195\n",
            "MSE Loss is: 0.008193740621209145, h Loss is: 30.80426597595215, L1 loss: 1.154022216796875, Total Loss is: 30.81245994567871\n",
            "MSE Loss is: 0.008027452975511551, h Loss is: 30.809032440185547, L1 loss: 1.1544935703277588, Total Loss is: 30.817060470581055\n",
            "MSE Loss is: 0.007856596261262894, h Loss is: 30.770023345947266, L1 loss: 1.1566756963729858, Total Loss is: 30.77787971496582\n",
            "MSE Loss is: 0.008183589205145836, h Loss is: 30.755550384521484, L1 loss: 1.157883644104004, Total Loss is: 30.763734817504883\n",
            "MSE Loss is: 0.008248166181147099, h Loss is: 30.739166259765625, L1 loss: 1.1577328443527222, Total Loss is: 30.747413635253906\n",
            "MSE Loss is: 0.008102919906377792, h Loss is: 30.724430084228516, L1 loss: 1.1562526226043701, Total Loss is: 30.732532501220703\n",
            "New h_val is : tf.Tensor(0.69137096, shape=(), dtype=float32)\n",
            "Epoch: {} 18\n",
            "MSE Loss is: 0.008535114116966724, h Loss is: 33.253150939941406, L1 loss: 1.1554335355758667, Total Loss is: 33.26168441772461\n",
            "MSE Loss is: 0.008455454371869564, h Loss is: 33.26349639892578, L1 loss: 1.1553200483322144, Total Loss is: 33.27195358276367\n",
            "MSE Loss is: 0.008040986955165863, h Loss is: 33.2161979675293, L1 loss: 1.1563948392868042, Total Loss is: 33.224239349365234\n",
            "MSE Loss is: 0.008871343918144703, h Loss is: 33.15421676635742, L1 loss: 1.1572388410568237, Total Loss is: 33.163089752197266\n",
            "MSE Loss is: 0.008321648463606834, h Loss is: 33.09083557128906, L1 loss: 1.157457947731018, Total Loss is: 33.09915542602539\n",
            "MSE Loss is: 0.00845417007803917, h Loss is: 33.06720733642578, L1 loss: 1.1571060419082642, Total Loss is: 33.075660705566406\n",
            "MSE Loss is: 0.008442841470241547, h Loss is: 33.049835205078125, L1 loss: 1.1562923192977905, Total Loss is: 33.05827713012695\n",
            "MSE Loss is: 0.008223867043852806, h Loss is: 32.997589111328125, L1 loss: 1.1561903953552246, Total Loss is: 33.00581359863281\n",
            "MSE Loss is: 0.008131780661642551, h Loss is: 32.896114349365234, L1 loss: 1.1573933362960815, Total Loss is: 32.90424728393555\n",
            "MSE Loss is: 0.008339710533618927, h Loss is: 32.83308029174805, L1 loss: 1.1579992771148682, Total Loss is: 32.8414192199707\n",
            "MSE Loss is: 0.008262209594249725, h Loss is: 32.77665328979492, L1 loss: 1.1580175161361694, Total Loss is: 32.784915924072266\n",
            "MSE Loss is: 0.008077310398221016, h Loss is: 32.75477600097656, L1 loss: 1.1578532457351685, Total Loss is: 32.76285171508789\n",
            "MSE Loss is: 0.008154099807143211, h Loss is: 32.73862075805664, L1 loss: 1.1579060554504395, Total Loss is: 32.74677658081055\n",
            "MSE Loss is: 0.008121178485453129, h Loss is: 32.69063949584961, L1 loss: 1.158528208732605, Total Loss is: 32.698760986328125\n",
            "MSE Loss is: 0.00798814557492733, h Loss is: 32.59787368774414, L1 loss: 1.1592812538146973, Total Loss is: 32.60586166381836\n",
            "MSE Loss is: 0.008410874754190445, h Loss is: 32.595306396484375, L1 loss: 1.159103274345398, Total Loss is: 32.60371780395508\n",
            "MSE Loss is: 0.008478104136884212, h Loss is: 32.630027770996094, L1 loss: 1.1592482328414917, Total Loss is: 32.63850402832031\n",
            "MSE Loss is: 0.008207323029637337, h Loss is: 32.57954025268555, L1 loss: 1.1605161428451538, Total Loss is: 32.58774948120117\n",
            "MSE Loss is: 0.008004466071724892, h Loss is: 32.49477005004883, L1 loss: 1.1613165140151978, Total Loss is: 32.50277328491211\n",
            "MSE Loss is: 0.008555915206670761, h Loss is: 32.471290588378906, L1 loss: 1.1605738401412964, Total Loss is: 32.4798469543457\n",
            "MSE Loss is: 0.008450407534837723, h Loss is: 32.491825103759766, L1 loss: 1.159462571144104, Total Loss is: 32.500274658203125\n",
            "MSE Loss is: 0.008456941694021225, h Loss is: 32.542781829833984, L1 loss: 1.159265398979187, Total Loss is: 32.551239013671875\n",
            "MSE Loss is: 0.008082510903477669, h Loss is: 32.558380126953125, L1 loss: 1.160324215888977, Total Loss is: 32.566463470458984\n",
            "MSE Loss is: 0.008335288614034653, h Loss is: 32.49726486206055, L1 loss: 1.1615053415298462, Total Loss is: 32.50559997558594\n",
            "MSE Loss is: 0.008121144026517868, h Loss is: 32.40529251098633, L1 loss: 1.1620272397994995, Total Loss is: 32.413414001464844\n",
            "MSE Loss is: 0.008496014401316643, h Loss is: 32.37289047241211, L1 loss: 1.1611289978027344, Total Loss is: 32.381385803222656\n",
            "MSE Loss is: 0.007836158387362957, h Loss is: 32.36415481567383, L1 loss: 1.160767674446106, Total Loss is: 32.37199020385742\n",
            "MSE Loss is: 0.008564852178096771, h Loss is: 32.37236785888672, L1 loss: 1.1608818769454956, Total Loss is: 32.38093185424805\n",
            "MSE Loss is: 0.00838797353208065, h Loss is: 32.346923828125, L1 loss: 1.1617845296859741, Total Loss is: 32.35531234741211\n",
            "MSE Loss is: 0.008366941474378109, h Loss is: 32.2652587890625, L1 loss: 1.1627851724624634, Total Loss is: 32.273624420166016\n",
            "MSE Loss is: 0.008415399119257927, h Loss is: 32.20949172973633, L1 loss: 1.1624081134796143, Total Loss is: 32.2179069519043\n",
            "MSE Loss is: 0.008040733635425568, h Loss is: 32.13688659667969, L1 loss: 1.1609443426132202, Total Loss is: 32.144927978515625\n",
            "MSE Loss is: 0.008450949564576149, h Loss is: 32.05743408203125, L1 loss: 1.1607468128204346, Total Loss is: 32.06588363647461\n",
            "MSE Loss is: 0.008228975348174572, h Loss is: 31.993484497070312, L1 loss: 1.1616299152374268, Total Loss is: 32.001712799072266\n",
            "MSE Loss is: 0.008053049445152283, h Loss is: 32.009376525878906, L1 loss: 1.1613836288452148, Total Loss is: 32.01742935180664\n",
            "MSE Loss is: 0.008103025145828724, h Loss is: 32.05641555786133, L1 loss: 1.159021258354187, Total Loss is: 32.064517974853516\n",
            "MSE Loss is: 0.00806566420942545, h Loss is: 31.984899520874023, L1 loss: 1.1572449207305908, Total Loss is: 31.992965698242188\n",
            "MSE Loss is: 0.008226963691413403, h Loss is: 31.870262145996094, L1 loss: 1.1575212478637695, Total Loss is: 31.878488540649414\n",
            "MSE Loss is: 0.008581804111599922, h Loss is: 31.820064544677734, L1 loss: 1.1591033935546875, Total Loss is: 31.828645706176758\n",
            "MSE Loss is: 0.008313681930303574, h Loss is: 31.83213233947754, L1 loss: 1.1601468324661255, Total Loss is: 31.84044647216797\n",
            "MSE Loss is: 0.0079121682792902, h Loss is: 31.841190338134766, L1 loss: 1.160317301750183, Total Loss is: 31.849102020263672\n",
            "MSE Loss is: 0.00788315199315548, h Loss is: 31.830093383789062, L1 loss: 1.15855872631073, Total Loss is: 31.837976455688477\n",
            "MSE Loss is: 0.007852884009480476, h Loss is: 31.774614334106445, L1 loss: 1.1569139957427979, Total Loss is: 31.782466888427734\n",
            "MSE Loss is: 0.00819215178489685, h Loss is: 31.731159210205078, L1 loss: 1.1566705703735352, Total Loss is: 31.739351272583008\n",
            "MSE Loss is: 0.008022740483283997, h Loss is: 31.766599655151367, L1 loss: 1.156998634338379, Total Loss is: 31.774621963500977\n",
            "MSE Loss is: 0.007852736860513687, h Loss is: 31.74097442626953, L1 loss: 1.1590962409973145, Total Loss is: 31.74882698059082\n",
            "MSE Loss is: 0.008186697959899902, h Loss is: 31.7205867767334, L1 loss: 1.160238265991211, Total Loss is: 31.72877311706543\n",
            "MSE Loss is: 0.008240275084972382, h Loss is: 31.691715240478516, L1 loss: 1.1601208448410034, Total Loss is: 31.699954986572266\n",
            "MSE Loss is: 0.008098176680505276, h Loss is: 31.678749084472656, L1 loss: 1.1587653160095215, Total Loss is: 31.686847686767578\n",
            "New h_val is : tf.Tensor(0.6602011, shape=(), dtype=float32)\n",
            "Epoch: {} 19\n",
            "MSE Loss is: 0.008537016808986664, h Loss is: 34.23316955566406, L1 loss: 1.1579822301864624, Total Loss is: 34.24170684814453\n",
            "MSE Loss is: 0.008454595692455769, h Loss is: 34.269874572753906, L1 loss: 1.1578556299209595, Total Loss is: 34.27832794189453\n",
            "MSE Loss is: 0.008035724051296711, h Loss is: 34.22976303100586, L1 loss: 1.1588484048843384, Total Loss is: 34.23780059814453\n",
            "MSE Loss is: 0.008872587233781815, h Loss is: 34.15625762939453, L1 loss: 1.1597923040390015, Total Loss is: 34.165130615234375\n",
            "MSE Loss is: 0.008321810513734818, h Loss is: 34.08102035522461, L1 loss: 1.1601879596710205, Total Loss is: 34.0893440246582\n",
            "MSE Loss is: 0.00844978541135788, h Loss is: 34.064735412597656, L1 loss: 1.1598337888717651, Total Loss is: 34.073184967041016\n",
            "MSE Loss is: 0.008445371873676777, h Loss is: 34.067447662353516, L1 loss: 1.1587966680526733, Total Loss is: 34.07589340209961\n",
            "MSE Loss is: 0.008224127814173698, h Loss is: 34.028018951416016, L1 loss: 1.1585108041763306, Total Loss is: 34.0362434387207\n",
            "MSE Loss is: 0.008126793429255486, h Loss is: 33.92113494873047, L1 loss: 1.1597709655761719, Total Loss is: 33.92926025390625\n",
            "MSE Loss is: 0.008340373635292053, h Loss is: 33.848392486572266, L1 loss: 1.1606762409210205, Total Loss is: 33.85673141479492\n",
            "MSE Loss is: 0.008265096694231033, h Loss is: 33.78858184814453, L1 loss: 1.1610288619995117, Total Loss is: 33.79684829711914\n",
            "MSE Loss is: 0.008075851947069168, h Loss is: 33.77811050415039, L1 loss: 1.1606720685958862, Total Loss is: 33.78618621826172\n",
            "MSE Loss is: 0.008153058588504791, h Loss is: 33.77849578857422, L1 loss: 1.1602383852005005, Total Loss is: 33.78664779663086\n",
            "MSE Loss is: 0.008113032206892967, h Loss is: 33.738346099853516, L1 loss: 1.1605039834976196, Total Loss is: 33.7464599609375\n",
            "MSE Loss is: 0.007992069236934185, h Loss is: 33.639991760253906, L1 loss: 1.1615103483200073, Total Loss is: 33.64798355102539\n",
            "MSE Loss is: 0.00840554665774107, h Loss is: 33.63710021972656, L1 loss: 1.161782145500183, Total Loss is: 33.645503997802734\n",
            "MSE Loss is: 0.008479353040456772, h Loss is: 33.67852020263672, L1 loss: 1.1621856689453125, Total Loss is: 33.6870002746582\n",
            "MSE Loss is: 0.008209224790334702, h Loss is: 33.63379669189453, L1 loss: 1.1632392406463623, Total Loss is: 33.642005920410156\n",
            "MSE Loss is: 0.008000298403203487, h Loss is: 33.55743408203125, L1 loss: 1.1635445356369019, Total Loss is: 33.565433502197266\n",
            "MSE Loss is: 0.008556526154279709, h Loss is: 33.54894256591797, L1 loss: 1.1624778509140015, Total Loss is: 33.557498931884766\n",
            "MSE Loss is: 0.008451602421700954, h Loss is: 33.58091735839844, L1 loss: 1.1617923974990845, Total Loss is: 33.58937072753906\n",
            "MSE Loss is: 0.008451826870441437, h Loss is: 33.634334564208984, L1 loss: 1.1622713804244995, Total Loss is: 33.64278793334961\n",
            "MSE Loss is: 0.008084820583462715, h Loss is: 33.64549255371094, L1 loss: 1.1636054515838623, Total Loss is: 33.6535758972168\n",
            "MSE Loss is: 0.008331005461513996, h Loss is: 33.58306884765625, L1 loss: 1.1644012928009033, Total Loss is: 33.591400146484375\n",
            "MSE Loss is: 0.008119536563754082, h Loss is: 33.50331115722656, L1 loss: 1.164320945739746, Total Loss is: 33.51142883300781\n",
            "MSE Loss is: 0.008496810682117939, h Loss is: 33.49443435668945, L1 loss: 1.1633598804473877, Total Loss is: 33.5029296875\n",
            "MSE Loss is: 0.007833672687411308, h Loss is: 33.49898910522461, L1 loss: 1.1635160446166992, Total Loss is: 33.5068244934082\n",
            "MSE Loss is: 0.008561910130083561, h Loss is: 33.503108978271484, L1 loss: 1.1641498804092407, Total Loss is: 33.51166915893555\n",
            "MSE Loss is: 0.008386483415961266, h Loss is: 33.465049743652344, L1 loss: 1.1651184558868408, Total Loss is: 33.47343444824219\n",
            "MSE Loss is: 0.008366089314222336, h Loss is: 33.38042449951172, L1 loss: 1.1656773090362549, Total Loss is: 33.388790130615234\n",
            "MSE Loss is: 0.00841340608894825, h Loss is: 33.3432731628418, L1 loss: 1.1648811101913452, Total Loss is: 33.351688385009766\n",
            "MSE Loss is: 0.008039271458983421, h Loss is: 33.291751861572266, L1 loss: 1.1633033752441406, Total Loss is: 33.29978942871094\n",
            "MSE Loss is: 0.008455426432192326, h Loss is: 33.21779251098633, L1 loss: 1.1633968353271484, Total Loss is: 33.22624969482422\n",
            "MSE Loss is: 0.00822677742689848, h Loss is: 33.143890380859375, L1 loss: 1.1646803617477417, Total Loss is: 33.15211868286133\n",
            "MSE Loss is: 0.008061607368290424, h Loss is: 33.15393829345703, L1 loss: 1.1645128726959229, Total Loss is: 33.1619987487793\n",
            "MSE Loss is: 0.008098404854536057, h Loss is: 33.20879364013672, L1 loss: 1.1617974042892456, Total Loss is: 33.21689224243164\n",
            "MSE Loss is: 0.008067346177995205, h Loss is: 33.14708709716797, L1 loss: 1.159814476966858, Total Loss is: 33.155155181884766\n",
            "MSE Loss is: 0.00823802500963211, h Loss is: 33.04434585571289, L1 loss: 1.1603200435638428, Total Loss is: 33.05258560180664\n",
            "MSE Loss is: 0.008578971959650517, h Loss is: 33.005863189697266, L1 loss: 1.1621724367141724, Total Loss is: 33.014442443847656\n",
            "MSE Loss is: 0.008317113853991032, h Loss is: 33.021934509277344, L1 loss: 1.1630959510803223, Total Loss is: 33.030250549316406\n",
            "MSE Loss is: 0.007911295630037785, h Loss is: 33.025821685791016, L1 loss: 1.1631650924682617, Total Loss is: 33.03373336791992\n",
            "MSE Loss is: 0.007876172661781311, h Loss is: 33.01255798339844, L1 loss: 1.161401629447937, Total Loss is: 33.02043533325195\n",
            "MSE Loss is: 0.007854038849473, h Loss is: 32.965667724609375, L1 loss: 1.1599782705307007, Total Loss is: 32.9735221862793\n",
            "MSE Loss is: 0.008188998326659203, h Loss is: 32.9410400390625, L1 loss: 1.1598032712936401, Total Loss is: 32.9492301940918\n",
            "MSE Loss is: 0.008019017055630684, h Loss is: 32.99563980102539, L1 loss: 1.160131812095642, Total Loss is: 33.003658294677734\n",
            "MSE Loss is: 0.007849805057048798, h Loss is: 32.96620559692383, L1 loss: 1.1621249914169312, Total Loss is: 32.974056243896484\n",
            "MSE Loss is: 0.008190437220036983, h Loss is: 32.9347038269043, L1 loss: 1.1631988286972046, Total Loss is: 32.942893981933594\n",
            "MSE Loss is: 0.008232295513153076, h Loss is: 32.90514373779297, L1 loss: 1.1630479097366333, Total Loss is: 32.91337585449219\n",
            "MSE Loss is: 0.008095404133200645, h Loss is: 32.91104507446289, L1 loss: 1.1617225408554077, Total Loss is: 32.91913986206055\n",
            "New h_val is : tf.Tensor(0.6364474, shape=(), dtype=float32)\n",
            "Epoch: {} 20\n",
            "MSE Loss is: 0.008540281094610691, h Loss is: 35.54700469970703, L1 loss: 1.160951018333435, Total Loss is: 35.555545806884766\n",
            "MSE Loss is: 0.008454126305878162, h Loss is: 35.59702682495117, L1 loss: 1.160733938217163, Total Loss is: 35.6054801940918\n",
            "MSE Loss is: 0.008031133562326431, h Loss is: 35.543914794921875, L1 loss: 1.1617084741592407, Total Loss is: 35.551944732666016\n",
            "MSE Loss is: 0.008876794017851353, h Loss is: 35.45311737060547, L1 loss: 1.1628221273422241, Total Loss is: 35.46199417114258\n",
            "MSE Loss is: 0.008321000263094902, h Loss is: 35.38028335571289, L1 loss: 1.1635044813156128, Total Loss is: 35.38860321044922\n",
            "MSE Loss is: 0.008448269218206406, h Loss is: 35.39009475708008, L1 loss: 1.1628860235214233, Total Loss is: 35.39854431152344\n",
            "MSE Loss is: 0.008450550958514214, h Loss is: 35.41592788696289, L1 loss: 1.161480188369751, Total Loss is: 35.42437744140625\n",
            "MSE Loss is: 0.008224203251302242, h Loss is: 35.37361145019531, L1 loss: 1.161051630973816, Total Loss is: 35.3818359375\n",
            "MSE Loss is: 0.008125722408294678, h Loss is: 35.24370574951172, L1 loss: 1.1625133752822876, Total Loss is: 35.2518310546875\n",
            "MSE Loss is: 0.008343535475432873, h Loss is: 35.1602897644043, L1 loss: 1.1641793251037598, Total Loss is: 35.16863250732422\n",
            "MSE Loss is: 0.008266463875770569, h Loss is: 35.112342834472656, L1 loss: 1.1646026372909546, Total Loss is: 35.120609283447266\n",
            "MSE Loss is: 0.008077452890574932, h Loss is: 35.1281852722168, L1 loss: 1.163558840751648, Total Loss is: 35.136260986328125\n",
            "MSE Loss is: 0.00815373845398426, h Loss is: 35.14447021484375, L1 loss: 1.1625744104385376, Total Loss is: 35.15262222290039\n",
            "MSE Loss is: 0.008106245659291744, h Loss is: 35.09674835205078, L1 loss: 1.1627132892608643, Total Loss is: 35.104854583740234\n",
            "MSE Loss is: 0.007998616434633732, h Loss is: 34.979164123535156, L1 loss: 1.1642249822616577, Total Loss is: 34.98716354370117\n",
            "MSE Loss is: 0.008403290063142776, h Loss is: 34.978694915771484, L1 loss: 1.1650265455245972, Total Loss is: 34.987098693847656\n",
            "MSE Loss is: 0.00848097912967205, h Loss is: 35.042362213134766, L1 loss: 1.165285348892212, Total Loss is: 35.05084228515625\n",
            "MSE Loss is: 0.008212189190089703, h Loss is: 35.01453399658203, L1 loss: 1.165664553642273, Total Loss is: 35.02274703979492\n",
            "MSE Loss is: 0.007997555658221245, h Loss is: 34.94310760498047, L1 loss: 1.1655340194702148, Total Loss is: 34.951107025146484\n",
            "MSE Loss is: 0.008558882400393486, h Loss is: 34.936248779296875, L1 loss: 1.1647653579711914, Total Loss is: 34.94480895996094\n",
            "MSE Loss is: 0.008451968431472778, h Loss is: 34.96993637084961, L1 loss: 1.1648393869400024, Total Loss is: 34.978389739990234\n",
            "MSE Loss is: 0.008450085297226906, h Loss is: 35.02946853637695, L1 loss: 1.165756106376648, Total Loss is: 35.03791809082031\n",
            "MSE Loss is: 0.008086377754807472, h Loss is: 35.049110412597656, L1 loss: 1.1667410135269165, Total Loss is: 35.05719757080078\n",
            "MSE Loss is: 0.008326748386025429, h Loss is: 34.99486541748047, L1 loss: 1.166800618171692, Total Loss is: 35.00319290161133\n",
            "MSE Loss is: 0.008120949380099773, h Loss is: 34.924678802490234, L1 loss: 1.1664204597473145, Total Loss is: 34.93280029296875\n",
            "MSE Loss is: 0.008495407178997993, h Loss is: 34.927711486816406, L1 loss: 1.1658966541290283, Total Loss is: 34.93620681762695\n",
            "MSE Loss is: 0.007835263386368752, h Loss is: 34.93550491333008, L1 loss: 1.1667492389678955, Total Loss is: 34.94334030151367\n",
            "MSE Loss is: 0.008561483584344387, h Loss is: 34.93669128417969, L1 loss: 1.1675344705581665, Total Loss is: 34.94525146484375\n",
            "MSE Loss is: 0.008385440334677696, h Loss is: 34.897247314453125, L1 loss: 1.168031096458435, Total Loss is: 34.90563201904297\n",
            "MSE Loss is: 0.00836675614118576, h Loss is: 34.81964111328125, L1 loss: 1.1680668592453003, Total Loss is: 34.828006744384766\n",
            "MSE Loss is: 0.008411097340285778, h Loss is: 34.800331115722656, L1 loss: 1.1672003269195557, Total Loss is: 34.80874252319336\n",
            "MSE Loss is: 0.008036399260163307, h Loss is: 34.757789611816406, L1 loss: 1.1660493612289429, Total Loss is: 34.76582717895508\n",
            "MSE Loss is: 0.008461127057671547, h Loss is: 34.6776123046875, L1 loss: 1.1667732000350952, Total Loss is: 34.686073303222656\n",
            "MSE Loss is: 0.008224235847592354, h Loss is: 34.59362030029297, L1 loss: 1.1678800582885742, Total Loss is: 34.601844787597656\n",
            "MSE Loss is: 0.008073889650404453, h Loss is: 34.60966873168945, L1 loss: 1.1672823429107666, Total Loss is: 34.61774444580078\n",
            "MSE Loss is: 0.00809599831700325, h Loss is: 34.68339157104492, L1 loss: 1.1642955541610718, Total Loss is: 34.69148635864258\n",
            "MSE Loss is: 0.008073216304183006, h Loss is: 34.62979507446289, L1 loss: 1.1626986265182495, Total Loss is: 34.63786697387695\n",
            "MSE Loss is: 0.008248443715274334, h Loss is: 34.52709197998047, L1 loss: 1.1635892391204834, Total Loss is: 34.53533935546875\n",
            "MSE Loss is: 0.008579500019550323, h Loss is: 34.49089813232422, L1 loss: 1.1654754877090454, Total Loss is: 34.49947738647461\n",
            "MSE Loss is: 0.008324439637362957, h Loss is: 34.512062072753906, L1 loss: 1.166178584098816, Total Loss is: 34.5203857421875\n",
            "MSE Loss is: 0.007910588756203651, h Loss is: 34.52021026611328, L1 loss: 1.1659702062606812, Total Loss is: 34.52812194824219\n",
            "MSE Loss is: 0.007870640605688095, h Loss is: 34.513301849365234, L1 loss: 1.1643251180648804, Total Loss is: 34.52117156982422\n",
            "MSE Loss is: 0.007857260294258595, h Loss is: 34.474246978759766, L1 loss: 1.162986397743225, Total Loss is: 34.48210525512695\n",
            "MSE Loss is: 0.008185632526874542, h Loss is: 34.45999526977539, L1 loss: 1.162882685661316, Total Loss is: 34.46818161010742\n",
            "MSE Loss is: 0.00801326334476471, h Loss is: 34.52629089355469, L1 loss: 1.1632192134857178, Total Loss is: 34.534305572509766\n",
            "MSE Loss is: 0.007847972214221954, h Loss is: 34.4926872253418, L1 loss: 1.1652430295944214, Total Loss is: 34.50053405761719\n",
            "MSE Loss is: 0.008191276341676712, h Loss is: 34.457435607910156, L1 loss: 1.1663824319839478, Total Loss is: 34.46562576293945\n",
            "MSE Loss is: 0.008222649805247784, h Loss is: 34.43461990356445, L1 loss: 1.1661049127578735, Total Loss is: 34.44284439086914\n",
            "MSE Loss is: 0.00809466652572155, h Loss is: 34.459686279296875, L1 loss: 1.1646223068237305, Total Loss is: 34.46778106689453\n",
            "New h_val is : tf.Tensor(0.6187949, shape=(), dtype=float32)\n",
            "Epoch: {} 21\n",
            "MSE Loss is: 0.008541438728570938, h Loss is: 37.21845626831055, L1 loss: 1.1637643575668335, Total Loss is: 37.22699737548828\n",
            "MSE Loss is: 0.008451497182250023, h Loss is: 37.273441314697266, L1 loss: 1.1636478900909424, Total Loss is: 37.28189468383789\n",
            "MSE Loss is: 0.00802887324243784, h Loss is: 37.20473861694336, L1 loss: 1.16489839553833, Total Loss is: 37.2127685546875\n",
            "MSE Loss is: 0.008877348154783249, h Loss is: 37.103126525878906, L1 loss: 1.1665706634521484, Total Loss is: 37.112003326416016\n",
            "MSE Loss is: 0.008317936211824417, h Loss is: 37.04106140136719, L1 loss: 1.1671440601348877, Total Loss is: 37.04937744140625\n",
            "MSE Loss is: 0.008448597975075245, h Loss is: 37.078399658203125, L1 loss: 1.165894865989685, Total Loss is: 37.086849212646484\n",
            "MSE Loss is: 0.008451751433312893, h Loss is: 37.1188850402832, L1 loss: 1.1640125513076782, Total Loss is: 37.12733840942383\n",
            "MSE Loss is: 0.008223211392760277, h Loss is: 37.06355667114258, L1 loss: 1.1639339923858643, Total Loss is: 37.071781158447266\n",
            "MSE Loss is: 0.008125681430101395, h Loss is: 36.909149169921875, L1 loss: 1.1662755012512207, Total Loss is: 36.917274475097656\n",
            "MSE Loss is: 0.008345568552613258, h Loss is: 36.82372283935547, L1 loss: 1.1682665348052979, Total Loss is: 36.832069396972656\n",
            "MSE Loss is: 0.00826617144048214, h Loss is: 36.79613494873047, L1 loss: 1.1682236194610596, Total Loss is: 36.80440139770508\n",
            "MSE Loss is: 0.008079741150140762, h Loss is: 36.837135314941406, L1 loss: 1.1663073301315308, Total Loss is: 36.84521484375\n",
            "MSE Loss is: 0.008153585717082024, h Loss is: 36.85900115966797, L1 loss: 1.165034294128418, Total Loss is: 36.86715316772461\n",
            "MSE Loss is: 0.008100376464426517, h Loss is: 36.79441452026367, L1 loss: 1.1658614873886108, Total Loss is: 36.802513122558594\n",
            "MSE Loss is: 0.008002596907317638, h Loss is: 36.65837097167969, L1 loss: 1.1682289838790894, Total Loss is: 36.66637420654297\n",
            "MSE Loss is: 0.008403276093304157, h Loss is: 36.67082977294922, L1 loss: 1.1689525842666626, Total Loss is: 36.67923355102539\n",
            "MSE Loss is: 0.008482065051794052, h Loss is: 36.765045166015625, L1 loss: 1.1684178113937378, Total Loss is: 36.773529052734375\n",
            "MSE Loss is: 0.008214222267270088, h Loss is: 36.75006103515625, L1 loss: 1.1678916215896606, Total Loss is: 36.75827407836914\n",
            "MSE Loss is: 0.007998146116733551, h Loss is: 36.67213439941406, L1 loss: 1.1678122282028198, Total Loss is: 36.68013381958008\n",
            "MSE Loss is: 0.008559025824069977, h Loss is: 36.660240173339844, L1 loss: 1.167736291885376, Total Loss is: 36.668800354003906\n",
            "MSE Loss is: 0.00845273956656456, h Loss is: 36.69936752319336, L1 loss: 1.1683769226074219, Total Loss is: 36.707820892333984\n",
            "MSE Loss is: 0.008451379835605621, h Loss is: 36.774593353271484, L1 loss: 1.1690638065338135, Total Loss is: 36.783042907714844\n",
            "MSE Loss is: 0.008084072731435299, h Loss is: 36.80788040161133, L1 loss: 1.1693700551986694, Total Loss is: 36.81596374511719\n",
            "MSE Loss is: 0.008325276896357536, h Loss is: 36.757564544677734, L1 loss: 1.1689971685409546, Total Loss is: 36.76588821411133\n",
            "MSE Loss is: 0.008122436702251434, h Loss is: 36.68809509277344, L1 loss: 1.1688512563705444, Total Loss is: 36.69621658325195\n",
            "MSE Loss is: 0.00849076732993126, h Loss is: 36.6981201171875, L1 loss: 1.168934941291809, Total Loss is: 36.70661163330078\n",
            "MSE Loss is: 0.0078398697078228, h Loss is: 36.71105194091797, L1 loss: 1.1701130867004395, Total Loss is: 36.71889114379883\n",
            "MSE Loss is: 0.008560672402381897, h Loss is: 36.7154426574707, L1 loss: 1.170570731163025, Total Loss is: 36.724002838134766\n",
            "MSE Loss is: 0.008385445922613144, h Loss is: 36.67854309082031, L1 loss: 1.170594334602356, Total Loss is: 36.686927795410156\n",
            "MSE Loss is: 0.008369721472263336, h Loss is: 36.60558319091797, L1 loss: 1.1706255674362183, Total Loss is: 36.61395263671875\n",
            "MSE Loss is: 0.008406877517700195, h Loss is: 36.597869873046875, L1 loss: 1.1700893640518188, Total Loss is: 36.60627746582031\n",
            "MSE Loss is: 0.008033137768507004, h Loss is: 36.55839920043945, L1 loss: 1.1692817211151123, Total Loss is: 36.56643295288086\n",
            "MSE Loss is: 0.008464301005005836, h Loss is: 36.47124481201172, L1 loss: 1.1701828241348267, Total Loss is: 36.47970962524414\n",
            "MSE Loss is: 0.008219292387366295, h Loss is: 36.381649017333984, L1 loss: 1.170964241027832, Total Loss is: 36.389869689941406\n",
            "MSE Loss is: 0.008083667606115341, h Loss is: 36.40895462036133, L1 loss: 1.1700891256332397, Total Loss is: 36.41703796386719\n",
            "MSE Loss is: 0.008092696778476238, h Loss is: 36.5013427734375, L1 loss: 1.1672717332839966, Total Loss is: 36.50943374633789\n",
            "MSE Loss is: 0.00808030180633068, h Loss is: 36.448890686035156, L1 loss: 1.1659740209579468, Total Loss is: 36.45697021484375\n",
            "MSE Loss is: 0.00825367122888565, h Loss is: 36.34026336669922, L1 loss: 1.1669062376022339, Total Loss is: 36.34851837158203\n",
            "MSE Loss is: 0.008582096546888351, h Loss is: 36.30712127685547, L1 loss: 1.168664813041687, Total Loss is: 36.315704345703125\n",
            "MSE Loss is: 0.008333306759595871, h Loss is: 36.33854675292969, L1 loss: 1.1693382263183594, Total Loss is: 36.34688186645508\n",
            "MSE Loss is: 0.007908567786216736, h Loss is: 36.35422897338867, L1 loss: 1.1690953969955444, Total Loss is: 36.36213684082031\n",
            "MSE Loss is: 0.007867204025387764, h Loss is: 36.35194778442383, L1 loss: 1.1675357818603516, Total Loss is: 36.35981369018555\n",
            "MSE Loss is: 0.007861564867198467, h Loss is: 36.31595993041992, L1 loss: 1.166171908378601, Total Loss is: 36.323822021484375\n",
            "MSE Loss is: 0.008181732147932053, h Loss is: 36.309288024902344, L1 loss: 1.1660135984420776, Total Loss is: 36.31747055053711\n",
            "MSE Loss is: 0.008008291944861412, h Loss is: 36.388912200927734, L1 loss: 1.1663599014282227, Total Loss is: 36.39691925048828\n",
            "MSE Loss is: 0.007848591543734074, h Loss is: 36.353515625, L1 loss: 1.168617606163025, Total Loss is: 36.36136245727539\n",
            "MSE Loss is: 0.008187098428606987, h Loss is: 36.31578063964844, L1 loss: 1.1701911687850952, Total Loss is: 36.32396697998047\n",
            "MSE Loss is: 0.008214566856622696, h Loss is: 36.29888153076172, L1 loss: 1.1697362661361694, Total Loss is: 36.30709457397461\n",
            "MSE Loss is: 0.0080953948199749, h Loss is: 36.341217041015625, L1 loss: 1.167656421661377, Total Loss is: 36.34931182861328\n",
            "New h_val is : tf.Tensor(0.60606956, shape=(), dtype=float32)\n",
            "Epoch: {} 22\n",
            "MSE Loss is: 0.008538307622075081, h Loss is: 39.26666259765625, L1 loss: 1.166521430015564, Total Loss is: 39.27519989013672\n",
            "MSE Loss is: 0.008449790067970753, h Loss is: 39.325897216796875, L1 loss: 1.1667684316635132, Total Loss is: 39.334346771240234\n",
            "MSE Loss is: 0.008028330281376839, h Loss is: 39.24177932739258, L1 loss: 1.168700098991394, Total Loss is: 39.24980926513672\n",
            "MSE Loss is: 0.008873328566551208, h Loss is: 39.13117218017578, L1 loss: 1.1704940795898438, Total Loss is: 39.140045166015625\n",
            "MSE Loss is: 0.00831538811326027, h Loss is: 39.08145523071289, L1 loss: 1.1705563068389893, Total Loss is: 39.08977127075195\n",
            "MSE Loss is: 0.008448034524917603, h Loss is: 39.145050048828125, L1 loss: 1.1689079999923706, Total Loss is: 39.153499603271484\n",
            "MSE Loss is: 0.008449569344520569, h Loss is: 39.195411682128906, L1 loss: 1.1670453548431396, Total Loss is: 39.203861236572266\n",
            "MSE Loss is: 0.008221504278481007, h Loss is: 39.12260437011719, L1 loss: 1.1675735712051392, Total Loss is: 39.13082504272461\n",
            "MSE Loss is: 0.008124340325593948, h Loss is: 38.94386672973633, L1 loss: 1.1704189777374268, Total Loss is: 38.95199203491211\n",
            "MSE Loss is: 0.008346203714609146, h Loss is: 38.86172103881836, L1 loss: 1.1721049547195435, Total Loss is: 38.87006759643555\n",
            "MSE Loss is: 0.008264273405075073, h Loss is: 38.857566833496094, L1 loss: 1.1714832782745361, Total Loss is: 38.86582946777344\n",
            "MSE Loss is: 0.008081581443548203, h Loss is: 38.92011642456055, L1 loss: 1.1691516637802124, Total Loss is: 38.928199768066406\n",
            "MSE Loss is: 0.008153010159730911, h Loss is: 38.939613342285156, L1 loss: 1.1681716442108154, Total Loss is: 38.9477653503418\n",
            "MSE Loss is: 0.008095169439911842, h Loss is: 38.853729248046875, L1 loss: 1.169836401939392, Total Loss is: 38.86182403564453\n",
            "MSE Loss is: 0.008005145005881786, h Loss is: 38.70261001586914, L1 loss: 1.1726348400115967, Total Loss is: 38.71061706542969\n",
            "MSE Loss is: 0.008403955027461052, h Loss is: 38.73600387573242, L1 loss: 1.173050045967102, Total Loss is: 38.744407653808594\n",
            "MSE Loss is: 0.008481839671730995, h Loss is: 38.86370086669922, L1 loss: 1.1717357635498047, Total Loss is: 38.8721809387207\n",
            "MSE Loss is: 0.008216921240091324, h Loss is: 38.854209899902344, L1 loss: 1.1709529161453247, Total Loss is: 38.8624267578125\n",
            "MSE Loss is: 0.007999403402209282, h Loss is: 38.760353088378906, L1 loss: 1.1712982654571533, Total Loss is: 38.76835250854492\n",
            "MSE Loss is: 0.008557556197047234, h Loss is: 38.74217224121094, L1 loss: 1.1717264652252197, Total Loss is: 38.750728607177734\n",
            "MSE Loss is: 0.008455315604805946, h Loss is: 38.793907165527344, L1 loss: 1.1723051071166992, Total Loss is: 38.802364349365234\n",
            "MSE Loss is: 0.008452286943793297, h Loss is: 38.892051696777344, L1 loss: 1.1725059747695923, Total Loss is: 38.90050506591797\n",
            "MSE Loss is: 0.008080977946519852, h Loss is: 38.938270568847656, L1 loss: 1.1721447706222534, Total Loss is: 38.94635009765625\n",
            "MSE Loss is: 0.008326316252350807, h Loss is: 38.88396453857422, L1 loss: 1.1716430187225342, Total Loss is: 38.89229202270508\n",
            "MSE Loss is: 0.008121548220515251, h Loss is: 38.80883026123047, L1 loss: 1.1719481945037842, Total Loss is: 38.816951751708984\n",
            "MSE Loss is: 0.008486981503665447, h Loss is: 38.82695007324219, L1 loss: 1.1724811792373657, Total Loss is: 38.8354377746582\n",
            "MSE Loss is: 0.007843626663088799, h Loss is: 38.85037612915039, L1 loss: 1.1736043691635132, Total Loss is: 38.858219146728516\n",
            "MSE Loss is: 0.008558714762330055, h Loss is: 38.86130905151367, L1 loss: 1.173585295677185, Total Loss is: 38.869869232177734\n",
            "MSE Loss is: 0.008386600762605667, h Loss is: 38.824649810791016, L1 loss: 1.1735285520553589, Total Loss is: 38.83303451538086\n",
            "MSE Loss is: 0.008372871205210686, h Loss is: 38.75086212158203, L1 loss: 1.1735527515411377, Total Loss is: 38.75923538208008\n",
            "MSE Loss is: 0.00840277224779129, h Loss is: 38.75153350830078, L1 loss: 1.1733099222183228, Total Loss is: 38.75993728637695\n",
            "MSE Loss is: 0.008030254393815994, h Loss is: 38.7149772644043, L1 loss: 1.17287278175354, Total Loss is: 38.72300720214844\n",
            "MSE Loss is: 0.008463792502880096, h Loss is: 38.622642517089844, L1 loss: 1.1734914779663086, Total Loss is: 38.631107330322266\n",
            "MSE Loss is: 0.008214732632040977, h Loss is: 38.52885437011719, L1 loss: 1.174211025238037, Total Loss is: 38.53706741333008\n",
            "MSE Loss is: 0.008087344467639923, h Loss is: 38.56715393066406, L1 loss: 1.1732122898101807, Total Loss is: 38.57524108886719\n",
            "MSE Loss is: 0.00808888953179121, h Loss is: 38.6759033203125, L1 loss: 1.1705387830734253, Total Loss is: 38.683990478515625\n",
            "MSE Loss is: 0.00808628648519516, h Loss is: 38.62091827392578, L1 loss: 1.1694549322128296, Total Loss is: 38.629005432128906\n",
            "MSE Loss is: 0.008252410218119621, h Loss is: 38.505088806152344, L1 loss: 1.1702959537506104, Total Loss is: 38.51333999633789\n",
            "MSE Loss is: 0.008586124517023563, h Loss is: 38.47723388671875, L1 loss: 1.1721792221069336, Total Loss is: 38.48582077026367\n",
            "MSE Loss is: 0.008340064436197281, h Loss is: 38.52086639404297, L1 loss: 1.1729278564453125, Total Loss is: 38.529205322265625\n",
            "MSE Loss is: 0.007905272766947746, h Loss is: 38.543033599853516, L1 loss: 1.1727222204208374, Total Loss is: 38.55093765258789\n",
            "MSE Loss is: 0.00786666851490736, h Loss is: 38.54255676269531, L1 loss: 1.171068787574768, Total Loss is: 38.55042266845703\n",
            "MSE Loss is: 0.00786452554166317, h Loss is: 38.507835388183594, L1 loss: 1.169488787651062, Total Loss is: 38.51570129394531\n",
            "MSE Loss is: 0.008177939802408218, h Loss is: 38.509273529052734, L1 loss: 1.169268250465393, Total Loss is: 38.517452239990234\n",
            "MSE Loss is: 0.008006192743778229, h Loss is: 38.60398864746094, L1 loss: 1.169769287109375, Total Loss is: 38.611995697021484\n",
            "MSE Loss is: 0.00785035826265812, h Loss is: 38.566226959228516, L1 loss: 1.1724538803100586, Total Loss is: 38.57407760620117\n",
            "MSE Loss is: 0.008180985227227211, h Loss is: 38.52470016479492, L1 loss: 1.174074649810791, Total Loss is: 38.53288269042969\n",
            "MSE Loss is: 0.008209725841879845, h Loss is: 38.51319885253906, L1 loss: 1.1735118627548218, Total Loss is: 38.52140808105469\n",
            "MSE Loss is: 0.00809556245803833, h Loss is: 38.57319259643555, L1 loss: 1.1713836193084717, Total Loss is: 38.5812873840332\n",
            "New h_val is : tf.Tensor(0.59727144, shape=(), dtype=float32)\n",
            "Epoch: {} 23\n",
            "MSE Loss is: 0.008533780463039875, h Loss is: 41.71072769165039, L1 loss: 1.170261025428772, Total Loss is: 41.719261169433594\n",
            "MSE Loss is: 0.008449980989098549, h Loss is: 41.772552490234375, L1 loss: 1.1709483861923218, Total Loss is: 41.781002044677734\n",
            "MSE Loss is: 0.008028066717088223, h Loss is: 41.67083740234375, L1 loss: 1.1732794046401978, Total Loss is: 41.67886734008789\n",
            "MSE Loss is: 0.008869124576449394, h Loss is: 41.55210876464844, L1 loss: 1.1749612092971802, Total Loss is: 41.560977935791016\n",
            "MSE Loss is: 0.008313599042594433, h Loss is: 41.51732635498047, L1 loss: 1.1742562055587769, Total Loss is: 41.525638580322266\n",
            "MSE Loss is: 0.008447033353149891, h Loss is: 41.606990814208984, L1 loss: 1.1721054315567017, Total Loss is: 41.61543655395508\n",
            "MSE Loss is: 0.008447440341114998, h Loss is: 41.66228485107422, L1 loss: 1.1705856323242188, Total Loss is: 41.67073059082031\n",
            "MSE Loss is: 0.008218847215175629, h Loss is: 41.566932678222656, L1 loss: 1.171830177307129, Total Loss is: 41.57515335083008\n",
            "MSE Loss is: 0.008123522624373436, h Loss is: 41.364376068115234, L1 loss: 1.174867868423462, Total Loss is: 41.372501373291016\n",
            "MSE Loss is: 0.008345908485352993, h Loss is: 41.291114807128906, L1 loss: 1.176080584526062, Total Loss is: 41.299461364746094\n",
            "MSE Loss is: 0.008261473849415779, h Loss is: 41.31303024291992, L1 loss: 1.1747736930847168, Total Loss is: 41.321292877197266\n",
            "MSE Loss is: 0.008083684369921684, h Loss is: 41.39225387573242, L1 loss: 1.1723802089691162, Total Loss is: 41.40033721923828\n",
            "MSE Loss is: 0.008151843212544918, h Loss is: 41.40135192871094, L1 loss: 1.1718701124191284, Total Loss is: 41.40950393676758\n",
            "MSE Loss is: 0.00809065904468298, h Loss is: 41.29169845581055, L1 loss: 1.1740076541900635, Total Loss is: 41.29978942871094\n",
            "MSE Loss is: 0.008008585311472416, h Loss is: 41.13094711303711, L1 loss: 1.1768455505371094, Total Loss is: 41.138954162597656\n",
            "MSE Loss is: 0.008403636515140533, h Loss is: 41.19333267211914, L1 loss: 1.1768306493759155, Total Loss is: 41.20173645019531\n",
            "MSE Loss is: 0.008482996374368668, h Loss is: 41.35445022583008, L1 loss: 1.1750907897949219, Total Loss is: 41.36293411254883\n",
            "MSE Loss is: 0.008220002055168152, h Loss is: 41.34087371826172, L1 loss: 1.174385905265808, Total Loss is: 41.34909439086914\n",
            "MSE Loss is: 0.008000739850103855, h Loss is: 41.22337341308594, L1 loss: 1.175179362297058, Total Loss is: 41.23137283325195\n",
            "MSE Loss is: 0.008557318709790707, h Loss is: 41.20225524902344, L1 loss: 1.1759365797042847, Total Loss is: 41.210811614990234\n",
            "MSE Loss is: 0.00845817569643259, h Loss is: 41.276126861572266, L1 loss: 1.1763259172439575, Total Loss is: 41.284584045410156\n",
            "MSE Loss is: 0.008453039452433586, h Loss is: 41.40183639526367, L1 loss: 1.1758946180343628, Total Loss is: 41.4102897644043\n",
            "MSE Loss is: 0.008079473860561848, h Loss is: 41.45545959472656, L1 loss: 1.1751922369003296, Total Loss is: 41.463539123535156\n",
            "MSE Loss is: 0.008327864110469818, h Loss is: 41.38853073120117, L1 loss: 1.1747491359710693, Total Loss is: 41.39685821533203\n",
            "MSE Loss is: 0.008120350539684296, h Loss is: 41.30569076538086, L1 loss: 1.1755139827728271, Total Loss is: 41.313812255859375\n",
            "MSE Loss is: 0.008485179394483566, h Loss is: 41.3380126953125, L1 loss: 1.176344871520996, Total Loss is: 41.34649658203125\n",
            "MSE Loss is: 0.007845957763493061, h Loss is: 41.37760543823242, L1 loss: 1.1773115396499634, Total Loss is: 41.38545227050781\n",
            "MSE Loss is: 0.008556931279599667, h Loss is: 41.39390563964844, L1 loss: 1.177072286605835, Total Loss is: 41.402462005615234\n",
            "MSE Loss is: 0.008388014510273933, h Loss is: 41.35148620605469, L1 loss: 1.1768550872802734, Total Loss is: 41.3598747253418\n",
            "MSE Loss is: 0.008375782519578934, h Loss is: 41.272918701171875, L1 loss: 1.1771106719970703, Total Loss is: 41.28129577636719\n",
            "MSE Loss is: 0.008400315418839455, h Loss is: 41.283843994140625, L1 loss: 1.1771434545516968, Total Loss is: 41.29224395751953\n",
            "MSE Loss is: 0.008027791976928711, h Loss is: 41.25355911254883, L1 loss: 1.176552653312683, Total Loss is: 41.2615852355957\n",
            "MSE Loss is: 0.008461681194603443, h Loss is: 41.15602493286133, L1 loss: 1.1771210432052612, Total Loss is: 41.164485931396484\n",
            "MSE Loss is: 0.008211901411414146, h Loss is: 41.05506134033203, L1 loss: 1.1777600049972534, Total Loss is: 41.06327438354492\n",
            "MSE Loss is: 0.008086562156677246, h Loss is: 41.10255813598633, L1 loss: 1.176940679550171, Total Loss is: 41.11064529418945\n",
            "MSE Loss is: 0.008086118847131729, h Loss is: 41.228580474853516, L1 loss: 1.1741307973861694, Total Loss is: 41.23666763305664\n",
            "MSE Loss is: 0.008090062066912651, h Loss is: 41.17156219482422, L1 loss: 1.1729516983032227, Total Loss is: 41.17965316772461\n",
            "MSE Loss is: 0.008247438818216324, h Loss is: 41.04796600341797, L1 loss: 1.1738232374191284, Total Loss is: 41.05621337890625\n",
            "MSE Loss is: 0.008590912446379662, h Loss is: 41.02461624145508, L1 loss: 1.1758112907409668, Total Loss is: 41.033206939697266\n",
            "MSE Loss is: 0.008343253284692764, h Loss is: 41.07992935180664, L1 loss: 1.1767747402191162, Total Loss is: 41.08827209472656\n",
            "MSE Loss is: 0.00790227111428976, h Loss is: 41.10831069946289, L1 loss: 1.1765490770339966, Total Loss is: 41.116214752197266\n",
            "MSE Loss is: 0.007867906242609024, h Loss is: 41.10986328125, L1 loss: 1.1747947931289673, Total Loss is: 41.117733001708984\n",
            "MSE Loss is: 0.007865353487432003, h Loss is: 41.076107025146484, L1 loss: 1.173190712928772, Total Loss is: 41.0839729309082\n",
            "MSE Loss is: 0.008175447583198547, h Loss is: 41.0849609375, L1 loss: 1.173141360282898, Total Loss is: 41.093135833740234\n",
            "MSE Loss is: 0.008005631156265736, h Loss is: 41.19447326660156, L1 loss: 1.1739057302474976, Total Loss is: 41.20248031616211\n",
            "MSE Loss is: 0.007852381095290184, h Loss is: 41.15330123901367, L1 loss: 1.1766867637634277, Total Loss is: 41.16115188598633\n",
            "MSE Loss is: 0.008175594732165337, h Loss is: 41.10834884643555, L1 loss: 1.178335428237915, Total Loss is: 41.11652374267578\n",
            "MSE Loss is: 0.008207028731703758, h Loss is: 41.103492736816406, L1 loss: 1.1776174306869507, Total Loss is: 41.111698150634766\n",
            "MSE Loss is: 0.008094936609268188, h Loss is: 41.18124008178711, L1 loss: 1.1754664182662964, Total Loss is: 41.189334869384766\n",
            "New h_val is : tf.Tensor(0.5916095, shape=(), dtype=float32)\n",
            "Epoch: {} 24\n",
            "MSE Loss is: 0.008530054241418839, h Loss is: 44.575748443603516, L1 loss: 1.174498438835144, Total Loss is: 44.58427810668945\n",
            "MSE Loss is: 0.008450927212834358, h Loss is: 44.637672424316406, L1 loss: 1.1754114627838135, Total Loss is: 44.646121978759766\n",
            "MSE Loss is: 0.00802796334028244, h Loss is: 44.51784896850586, L1 loss: 1.177787184715271, Total Loss is: 44.525875091552734\n",
            "MSE Loss is: 0.008866612799465656, h Loss is: 44.393428802490234, L1 loss: 1.1792404651641846, Total Loss is: 44.40229415893555\n",
            "MSE Loss is: 0.008311950601637363, h Loss is: 44.37553405761719, L1 loss: 1.1781752109527588, Total Loss is: 44.383846282958984\n",
            "MSE Loss is: 0.008446766994893551, h Loss is: 44.48908233642578, L1 loss: 1.1759047508239746, Total Loss is: 44.497528076171875\n",
            "MSE Loss is: 0.008446132764220238, h Loss is: 44.543704986572266, L1 loss: 1.1746704578399658, Total Loss is: 44.55215072631836\n",
            "MSE Loss is: 0.008215857669711113, h Loss is: 44.42274475097656, L1 loss: 1.1762644052505493, Total Loss is: 44.43096160888672\n",
            "MSE Loss is: 0.008124135434627533, h Loss is: 44.1991081237793, L1 loss: 1.179348111152649, Total Loss is: 44.20723342895508\n",
            "MSE Loss is: 0.008344816043972969, h Loss is: 44.14004898071289, L1 loss: 1.180090308189392, Total Loss is: 44.14839553833008\n",
            "MSE Loss is: 0.008258999325335026, h Loss is: 44.18772888183594, L1 loss: 1.1784924268722534, Total Loss is: 44.195987701416016\n",
            "MSE Loss is: 0.008085975423455238, h Loss is: 44.2768440246582, L1 loss: 1.1761503219604492, Total Loss is: 44.28493118286133\n",
            "MSE Loss is: 0.008149906992912292, h Loss is: 44.269630432128906, L1 loss: 1.1760157346725464, Total Loss is: 44.27777862548828\n",
            "MSE Loss is: 0.008087221533060074, h Loss is: 44.13774490356445, L1 loss: 1.178409457206726, Total Loss is: 44.14583206176758\n",
            "MSE Loss is: 0.008012130856513977, h Loss is: 43.97417068481445, L1 loss: 1.1811296939849854, Total Loss is: 43.982181549072266\n",
            "MSE Loss is: 0.008402369916439056, h Loss is: 44.070064544677734, L1 loss: 1.18045175075531, Total Loss is: 44.078468322753906\n",
            "MSE Loss is: 0.008485830388963223, h Loss is: 44.26055145263672, L1 loss: 1.1784838438034058, Total Loss is: 44.269039154052734\n",
            "MSE Loss is: 0.008222177624702454, h Loss is: 44.233848571777344, L1 loss: 1.1779683828353882, Total Loss is: 44.242069244384766\n",
            "MSE Loss is: 0.008002892136573792, h Loss is: 44.08995819091797, L1 loss: 1.1791337728500366, Total Loss is: 44.09796142578125\n",
            "MSE Loss is: 0.008558211848139763, h Loss is: 44.07311248779297, L1 loss: 1.1800426244735718, Total Loss is: 44.081668853759766\n",
            "MSE Loss is: 0.008460418321192265, h Loss is: 44.17690658569336, L1 loss: 1.1802314519882202, Total Loss is: 44.185367584228516\n",
            "MSE Loss is: 0.008454461582005024, h Loss is: 44.32966613769531, L1 loss: 1.1793521642684937, Total Loss is: 44.33811950683594\n",
            "MSE Loss is: 0.008078631944954395, h Loss is: 44.383235931396484, L1 loss: 1.1784553527832031, Total Loss is: 44.39131546020508\n",
            "MSE Loss is: 0.008329544216394424, h Loss is: 44.29841995239258, L1 loss: 1.1783310174942017, Total Loss is: 44.3067512512207\n",
            "MSE Loss is: 0.008119530975818634, h Loss is: 44.21123123168945, L1 loss: 1.1794724464416504, Total Loss is: 44.2193489074707\n",
            "MSE Loss is: 0.008484634570777416, h Loss is: 44.264869689941406, L1 loss: 1.1803237199783325, Total Loss is: 44.273353576660156\n",
            "MSE Loss is: 0.00784803181886673, h Loss is: 44.32200241088867, L1 loss: 1.1809691190719604, Total Loss is: 44.32984924316406\n",
            "MSE Loss is: 0.008555421605706215, h Loss is: 44.33833312988281, L1 loss: 1.1805782318115234, Total Loss is: 44.34688949584961\n",
            "MSE Loss is: 0.008389631286263466, h Loss is: 44.28525161743164, L1 loss: 1.1803983449935913, Total Loss is: 44.29364013671875\n",
            "MSE Loss is: 0.008378340862691402, h Loss is: 44.202754974365234, L1 loss: 1.1809123754501343, Total Loss is: 44.21113204956055\n",
            "MSE Loss is: 0.00839967466890812, h Loss is: 44.22889709472656, L1 loss: 1.181082010269165, Total Loss is: 44.23729705810547\n",
            "MSE Loss is: 0.00802611093968153, h Loss is: 44.20602798461914, L1 loss: 1.1804043054580688, Total Loss is: 44.214054107666016\n",
            "MSE Loss is: 0.008459443226456642, h Loss is: 44.09929275512695, L1 loss: 1.1807854175567627, Total Loss is: 44.10775375366211\n",
            "MSE Loss is: 0.00821100827306509, h Loss is: 43.986961364746094, L1 loss: 1.18147873878479, Total Loss is: 43.99517059326172\n",
            "MSE Loss is: 0.008083917200565338, h Loss is: 44.04492950439453, L1 loss: 1.180906891822815, Total Loss is: 44.05301284790039\n",
            "MSE Loss is: 0.008085547015070915, h Loss is: 44.19271469116211, L1 loss: 1.178123116493225, Total Loss is: 44.200801849365234\n",
            "MSE Loss is: 0.008091912604868412, h Loss is: 44.134212493896484, L1 loss: 1.1767570972442627, Total Loss is: 44.142303466796875\n",
            "MSE Loss is: 0.00824181828647852, h Loss is: 43.99911880493164, L1 loss: 1.177589774131775, Total Loss is: 44.007362365722656\n",
            "MSE Loss is: 0.00859576091170311, h Loss is: 43.97718048095703, L1 loss: 1.1799497604370117, Total Loss is: 43.985774993896484\n",
            "MSE Loss is: 0.008343582972884178, h Loss is: 44.04537582397461, L1 loss: 1.1809751987457275, Total Loss is: 44.05371856689453\n",
            "MSE Loss is: 0.007900729775428772, h Loss is: 44.08315658569336, L1 loss: 1.1805728673934937, Total Loss is: 44.09105682373047\n",
            "MSE Loss is: 0.007869623601436615, h Loss is: 44.087764739990234, L1 loss: 1.1786831617355347, Total Loss is: 44.09563446044922\n",
            "MSE Loss is: 0.00786498561501503, h Loss is: 44.052513122558594, L1 loss: 1.177214503288269, Total Loss is: 44.06037902832031\n",
            "MSE Loss is: 0.0081748366355896, h Loss is: 44.06571578979492, L1 loss: 1.1773992776870728, Total Loss is: 44.073890686035156\n",
            "MSE Loss is: 0.008005238138139248, h Loss is: 44.19047927856445, L1 loss: 1.1782373189926147, Total Loss is: 44.198486328125\n",
            "MSE Loss is: 0.007854793220758438, h Loss is: 44.14771270751953, L1 loss: 1.1810022592544556, Total Loss is: 44.15556716918945\n",
            "MSE Loss is: 0.008171587251126766, h Loss is: 44.10129928588867, L1 loss: 1.182490348815918, Total Loss is: 44.10947036743164\n",
            "MSE Loss is: 0.008205585181713104, h Loss is: 44.10245132446289, L1 loss: 1.1816285848617554, Total Loss is: 44.11065673828125\n",
            "MSE Loss is: 0.00809429120272398, h Loss is: 44.19538879394531, L1 loss: 1.1795227527618408, Total Loss is: 44.20348358154297\n",
            "New h_val is : tf.Tensor(0.58846474, shape=(), dtype=float32)\n",
            "saving model to: /content//CausalNN_model_final_1711511032.h5\n",
            "53/53 [==============================] - 0s 2ms/step\n",
            "The conv layer 1 weights before training : [[ 0.01729116 -0.03241783  0.20739552  0.21393666  0.05369946  0.34967968\n",
            "  -0.14644605 -0.3412853  -0.11558445 -0.22822307  0.21469983  0.0880048\n",
            "  -0.1930318   0.18624505 -0.17902574 -0.3153036  -0.22727013 -0.03919902\n",
            "   0.06509387 -0.07369781 -0.10506889 -0.03960952  0.17076865  0.15640828]]\n",
            "The conv layer 1 weights after training : [[-0.00767072  0.10339227  0.01499491  0.07321265  0.08972184  0.12996092\n",
            "  -0.09790443  0.03833694  0.12816866  0.11469433 -0.00738433  0.07222594\n",
            "  -0.01964228  0.10576643 -0.00821146  0.03433074  0.04368964  0.13232726\n",
            "  -0.10179738  0.04801381  0.00985407 -0.22343029 -0.07728923  0.03971552]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdgckClHP1y_",
        "outputId": "6240cd8b-3e0c-457f-f29b-8d8535d3335d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckpp6cuerupo"
      },
      "outputs": [],
      "source": [
        "mat_df_2d_s = pd.DataFrame(mat)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat_f_df = pd.DataFrame(mat).T"
      ],
      "metadata": {
        "id": "UAa0WohUJ_t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "9CtUItJErupo",
        "outputId": "320bb153-8c64-4494-a839-606bee6ce839"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3\n",
              "0   0.060424 -0.086885  0.158718 -0.023992\n",
              "1  -0.071343  0.219383 -0.102552 -0.049103\n",
              "2   0.197360  0.230671  0.013068 -0.011465\n",
              "3  -0.518587  0.195263  0.023268 -0.004621\n",
              "4   0.416361  0.019698  0.006211  0.048413\n",
              "5  -0.010432  0.209990 -0.004963 -0.034856\n",
              "6  -0.019452  0.071430  0.007873 -0.011133\n",
              "7   0.013019 -0.285973 -0.074198 -0.009662\n",
              "8   0.215037 -0.135168  0.307494 -0.130542\n",
              "9  -0.031971  0.131829  0.021005 -0.069707\n",
              "10  0.066766  0.036119  0.077588 -0.034936\n",
              "11  0.059482 -0.076978 -0.145271  0.079954\n",
              "12  0.516758  0.105059 -0.557891  0.437681\n",
              "13 -0.023034  0.223007 -0.045904 -0.031027\n",
              "14 -0.080299  0.048158  0.119814 -0.015027\n",
              "15  0.010720 -0.129315 -0.027521 -0.114521\n",
              "16  0.567747  1.062261 -0.187627  0.349131\n",
              "17  0.026067  0.249058  0.072498 -0.149108\n",
              "18  0.132662  0.036266  0.123289 -0.078585\n",
              "19  0.016741  0.075880 -0.806988  0.555153\n",
              "20  0.000000 -0.173380  0.080703 -0.061715\n",
              "21 -0.095194  0.000000  0.037806 -0.136843\n",
              "22  0.069021  0.172888  0.000000  0.835213\n",
              "23 -0.108998 -0.878886  2.633786  0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b12001e8-080c-4116-835a-01c9d75117e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.060424</td>\n",
              "      <td>-0.086885</td>\n",
              "      <td>0.158718</td>\n",
              "      <td>-0.023992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.071343</td>\n",
              "      <td>0.219383</td>\n",
              "      <td>-0.102552</td>\n",
              "      <td>-0.049103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.197360</td>\n",
              "      <td>0.230671</td>\n",
              "      <td>0.013068</td>\n",
              "      <td>-0.011465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.518587</td>\n",
              "      <td>0.195263</td>\n",
              "      <td>0.023268</td>\n",
              "      <td>-0.004621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.416361</td>\n",
              "      <td>0.019698</td>\n",
              "      <td>0.006211</td>\n",
              "      <td>0.048413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.010432</td>\n",
              "      <td>0.209990</td>\n",
              "      <td>-0.004963</td>\n",
              "      <td>-0.034856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.019452</td>\n",
              "      <td>0.071430</td>\n",
              "      <td>0.007873</td>\n",
              "      <td>-0.011133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.013019</td>\n",
              "      <td>-0.285973</td>\n",
              "      <td>-0.074198</td>\n",
              "      <td>-0.009662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.215037</td>\n",
              "      <td>-0.135168</td>\n",
              "      <td>0.307494</td>\n",
              "      <td>-0.130542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.031971</td>\n",
              "      <td>0.131829</td>\n",
              "      <td>0.021005</td>\n",
              "      <td>-0.069707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.066766</td>\n",
              "      <td>0.036119</td>\n",
              "      <td>0.077588</td>\n",
              "      <td>-0.034936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.059482</td>\n",
              "      <td>-0.076978</td>\n",
              "      <td>-0.145271</td>\n",
              "      <td>0.079954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.516758</td>\n",
              "      <td>0.105059</td>\n",
              "      <td>-0.557891</td>\n",
              "      <td>0.437681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-0.023034</td>\n",
              "      <td>0.223007</td>\n",
              "      <td>-0.045904</td>\n",
              "      <td>-0.031027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-0.080299</td>\n",
              "      <td>0.048158</td>\n",
              "      <td>0.119814</td>\n",
              "      <td>-0.015027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.010720</td>\n",
              "      <td>-0.129315</td>\n",
              "      <td>-0.027521</td>\n",
              "      <td>-0.114521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.567747</td>\n",
              "      <td>1.062261</td>\n",
              "      <td>-0.187627</td>\n",
              "      <td>0.349131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.026067</td>\n",
              "      <td>0.249058</td>\n",
              "      <td>0.072498</td>\n",
              "      <td>-0.149108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.132662</td>\n",
              "      <td>0.036266</td>\n",
              "      <td>0.123289</td>\n",
              "      <td>-0.078585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.016741</td>\n",
              "      <td>0.075880</td>\n",
              "      <td>-0.806988</td>\n",
              "      <td>0.555153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.173380</td>\n",
              "      <td>0.080703</td>\n",
              "      <td>-0.061715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>-0.095194</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037806</td>\n",
              "      <td>-0.136843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.069021</td>\n",
              "      <td>0.172888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.835213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>-0.108998</td>\n",
              "      <td>-0.878886</td>\n",
              "      <td>2.633786</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b12001e8-080c-4116-835a-01c9d75117e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b12001e8-080c-4116-835a-01c9d75117e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b12001e8-080c-4116-835a-01c9d75117e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e5cd19c1-8ccd-4fce-a368-e3ee8d8d7756\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e5cd19c1-8ccd-4fce-a368-e3ee8d8d7756')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e5cd19c1-8ccd-4fce-a368-e3ee8d8d7756 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"mat_df_2d_s\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          0.21503712236881256,\n          0.5677467584609985,\n          0.060424309223890305\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          -0.1351684182882309,\n          1.0622609853744507,\n          -0.08688480406999588\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          0.30749425292015076,\n          -0.18762744963169098,\n          0.15871800482273102\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          -0.13054174184799194,\n          0.3491307199001312,\n          -0.02399151213467121\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "mat_df_2d_s.T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat_f_df.iloc[20:,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "qrIvGlpIKGpn",
        "outputId": "a3563c2e-31d4-4f14-8962-0be1209e8284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3\n",
              "20  0.000000 -0.173380  0.080703 -0.061715\n",
              "21 -0.095194  0.000000  0.037806 -0.136843\n",
              "22  0.069021  0.172888  0.000000  0.835213\n",
              "23 -0.108998 -0.878886  2.633786  0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a655d8e7-ddff-448d-b084-b3e9d991851b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.173380</td>\n",
              "      <td>0.080703</td>\n",
              "      <td>-0.061715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>-0.095194</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037806</td>\n",
              "      <td>-0.136843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.069021</td>\n",
              "      <td>0.172888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.835213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>-0.108998</td>\n",
              "      <td>-0.878886</td>\n",
              "      <td>2.633786</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a655d8e7-ddff-448d-b084-b3e9d991851b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a655d8e7-ddff-448d-b084-b3e9d991851b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a655d8e7-ddff-448d-b084-b3e9d991851b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f145f777-b284-4d4f-8917-f358fea3a390\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f145f777-b284-4d4f-8917-f358fea3a390')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f145f777-b284-4d4f-8917-f358fea3a390 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"mat_f_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -0.09519411623477936,\n          -0.1089979037642479,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0,\n          -0.8788855075836182,\n          -0.17337976396083832\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.03780581057071686,\n          2.633786201477051,\n          0.08070340752601624\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -0.13684332370758057,\n          0.0,\n          -0.06171455979347229\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Full Causal Graph"
      ],
      "metadata": {
        "id": "rK-co1IcGV7q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvIvNNEjrupo"
      },
      "outputs": [],
      "source": [
        "matrix_2d_2d_s = mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCrZpZYQrupo"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "G_2d_s = nx.DiGraph()\n",
        "\n",
        "nodes_2d_s = [\"S1(t-5)\", \"S2(t-5)\", \"S3(t-5)\",  \"S4(t-5)\",\n",
        "         \"S1(t-4)\", \"S2(t-4)\", \"S3(t-4)\",  \"S4(t-4)\",\n",
        "         \"S1(t-3)\", \"S2(t-3)\", \"S3(t-3)\",  \"S4(t-3)\",\n",
        "         \"S1(t-2)\", \"S2(t-2)\", \"S3(t-2)\",  \"S4(t-2)\",\n",
        "         \"S1(t-1)\", \"S2(t-1)\", \"S3(t-1)\",  \"S4(t-1)\",\n",
        "         \"S1(t)\", \"S2(t)\", \"S3(t)\",  \"S4(t)\"]\n",
        "nodes_r_2d_s=[\"S1(t)\", \"S2(t)\", \"S3(t)\",  \"S4(t)\"]\n",
        "pred_graph_f = np.zeros((4,24))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nzqj5wyrupo"
      },
      "outputs": [],
      "source": [
        "for i in range (0, 24):\n",
        "  G_2d_s.add_node(nodes_2d_s[i],pos=(int(i/4)+1,(i%4)+1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsJrb53Krupp"
      },
      "outputs": [],
      "source": [
        "for i in range(0, 24):\n",
        "  for j in range (0, 4):\n",
        "    if matrix_2d_2d_s[j,i] > 0.3:\n",
        "      print(i,j, matrix_2d_2d_s[j,i])\n",
        "      G_2d_s.add_edge(nodes_2d_s[i], nodes_r_2d_s[j], weight=i)\n",
        "      pred_graph_f[j,i]=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtzcncqBrupp"
      },
      "outputs": [],
      "source": [
        "pos_2d_s=nx.get_node_attributes(G_2d_s,'pos')\n",
        "#pos_2d_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QoGvVgS6SbW"
      },
      "outputs": [],
      "source": [
        "weights_2d_s = nx.get_edge_attributes(G_2d_s,'weight').values()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset V2 Full\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "nx.draw(G_2d_s, pos_2d_s, cmap = plt.get_cmap('jet'), edge_cmap= plt.cm.tab20, edge_color=weights_2d_s, with_labels = True, connectionstyle='arc3, rad = 0.3')\n",
        "#nx.draw_networkx(G, with_labels = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "id": "QKqkGrR-nJTB",
        "outputId": "7f7932cb-cb77-49c1-f5d1-0e4e6c4d606f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cdt.metrics.SHD(true_full_graph, pred_graph_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWBPKyEhfReZ",
        "outputId": "282e2d10-c029-441b-8f4b-679d5dff5917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.0"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_values = true_full_graph\n",
        "predictions = pred_graph_f\n",
        "\n",
        "N = true_values.shape[1]*true_values.shape[0]\n",
        "accuracy = (true_values == predictions).sum() / N\n",
        "TP = ((predictions == 1) & (true_values == 1)).sum()\n",
        "FP = ((predictions == 1) & (true_values == 0)).sum()\n",
        "TN = ((predictions == 0) & (true_values == 0)).sum()\n",
        "FN = ((predictions == 0) & (true_values == 1)).sum()\n",
        "precision = TP / (TP+FP)\n",
        "recall = TP / (TP + FN)\n",
        "FDR = FP / (FP + TP)\n",
        "F1 = 2 * (precision * recall) / (precision + recall)\n",
        "print('Accuracy: {}, Precision: {}, Recall: {}, FDR: {}, F1 Score: {}'.format(accuracy, precision, recall, FDR,F1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeXtHJDEfJzy",
        "outputId": "8949f78b-4a11-4679-da86-780f659afe5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9270833333333334, Precision: 0.75, Recall: 0.3333333333333333, FDR: 0.25, F1 Score: 0.46153846153846156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijo5Wyjm6qRR"
      },
      "source": [
        "#Summary Causal Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfX8KQwJ6qRR"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "G_2d_s1 = nx.DiGraph()\n",
        "\n",
        "nodes_2d_s1 = [\"S1\", \"S2\", \"S3\",  \"S4\"]\n",
        "nodes_r_2d_s1= [\"S1\", \"S2\", \"S3\",  \"S4\"]\n",
        "edges_2d_s1 = []\n",
        "pred_graph_s1 = np.zeros((4,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79j7uDTN6qRR"
      },
      "outputs": [],
      "source": [
        "for i in range (0, 4):\n",
        "  G_2d_s1.add_node(nodes_2d_s1[i],pos=(int(i/2)+1,(i%2)+1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyYUYXSb6qRS"
      },
      "outputs": [],
      "source": [
        "for i in range(0, 24):\n",
        "  for j in range (0, 4):\n",
        "    if matrix_2d_2d_s[j,i] > 0.3:\n",
        "      print(i,j)\n",
        "      col = np.round(matrix_2d_2d_s[j,i], 2)\n",
        "      G_2d_s1.add_edge(nodes_2d_s1[i%4], nodes_r_2d_s1[j], weight=1)\n",
        "      pred_graph_s1[i%4, j]=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQRq97oL6qRS",
        "outputId": "8e547d2c-e274-4c51-d025-fcb737c9458c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'S1': (1, 1), 'S2': (1, 2), 'S3': (2, 1), 'S4': (2, 2)}"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "pos_2d_s1=nx.get_node_attributes(G_2d_s1,'pos')\n",
        "pos_2d_s1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "938WuKdz6qRS"
      },
      "outputs": [],
      "source": [
        "weights_2d_s1 = nx.get_edge_attributes(G_2d_s1,'weight').values()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset V2 Summary\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "nx.draw(G_2d_s1, pos_2d_s1, cmap = plt.get_cmap('jet'), edge_cmap= plt.cm.tab20, edge_color=weights_2d_s1, with_labels = True, connectionstyle='arc3, rad = 0.3')\n",
        "#nx.draw_networkx(G, with_labels = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "KDmP5aDGnXMR",
        "outputId": "8dda3f04-6784-4cb4-ff4a-33192647dd42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cdt.metrics.SHD(true_graph, pred_graph_s1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_1qPVtYFV73",
        "outputId": "6e41f09d-8235-4037-9230-4623e886247e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_values = true_graph\n",
        "predictions = pred_graph_s1\n",
        "\n",
        "N = true_values.shape[1]*true_values.shape[0]\n",
        "accuracy = (true_values == predictions).sum() / N\n",
        "TP = ((predictions == 1) & (true_values == 1)).sum()\n",
        "FP = ((predictions == 1) & (true_values == 0)).sum()\n",
        "TN = ((predictions == 0) & (true_values == 0)).sum()\n",
        "FN = ((predictions == 0) & (true_values == 1)).sum()\n",
        "precision = TP / (TP+FP)\n",
        "recall = TP / (TP + FN)\n",
        "FDR = FP / (FP + TP)\n",
        "F1 = 2 * (precision * recall) / (precision + recall)\n",
        "print('Accuracy: {}, Precision: {}, Recall: {}, FDR: {}, F1 Score: {}'.format(accuracy, precision, recall, FDR,F1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTy-ZiS66Sbr",
        "outputId": "07499d2a-eb6c-4306-d355-a08c40c1e46b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.75, Precision: 0.75, Recall: 0.5, FDR: 0.25, F1 Score: 0.6\n"
          ]
        }
      ]
    }
  ]
}
